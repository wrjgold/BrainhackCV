{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qopdZdDOiUwd",
        "outputId": "b7531c1b-184e-4415-be0d-d1212190bdb0"
      },
      "id": "qopdZdDOiUwd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 31 12:59:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZhlvMsZico4",
        "outputId": "bbb9fa72-b33a-4a93-9c03-390588d9b2d5"
      },
      "id": "3ZhlvMsZico4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2kkdl2zi5s-",
        "outputId": "a5432795-1c41-4008-cb91-784dbf8f39c0"
      },
      "id": "d2kkdl2zi5s-",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D208lJdc7-t",
        "outputId": "792e1bac-27c1-4497-8251-b7560c52c8e5"
      },
      "id": "3D208lJdc7-t",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"drive/MyDrive/Brainhack/Train.zip\" -d \"train_images\"\n",
        "\n",
        "!unzip \"drive/MyDrive/Brainhack/train_labels.zip\" -d \"train_labels\"\n",
        "\n",
        "!unzip \"drive/MyDrive/Brainhack/Validation.zip\" -d \"val_images\"\n",
        "\n",
        "!unzip \"drive/MyDrive/Brainhack/val_labels.zip\" -d \"val_labels\"\n",
        "\n",
        "!unzip \"drive/MyDrive/Brainhack/Test.zip\" -d \"test_images\"\n",
        "\n",
        "!unzip \"drive/MyDrive/Brainhack/suspects.zip\" -d \"suspects\""
      ],
      "metadata": {
        "id": "oyYhrPHpmeel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb3d0f7-7ad4-41f6-86e2-6168de70b022"
      },
      "id": "oyYhrPHpmeel",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " extracting: train_labels/image_0460.txt  \n",
            " extracting: train_labels/image_0479.txt  \n",
            " extracting: train_labels/image_0465.txt  \n",
            " extracting: train_labels/image_0475.txt  \n",
            " extracting: train_labels/image_0477.txt  \n",
            " extracting: train_labels/image_0474.txt  \n",
            " extracting: train_labels/image_0457.txt  \n",
            " extracting: train_labels/image_0473.txt  \n",
            " extracting: train_labels/image_0472.txt  \n",
            " extracting: train_labels/image_0466.txt  \n",
            " extracting: train_labels/image_0481.txt  \n",
            " extracting: train_labels/image_0471.txt  \n",
            " extracting: train_labels/image_0469.txt  \n",
            " extracting: train_labels/image_0484.txt  \n",
            " extracting: train_labels/image_0482.txt  \n",
            " extracting: train_labels/image_0459.txt  \n",
            " extracting: train_labels/image_0476.txt  \n",
            " extracting: train_labels/image_0468.txt  \n",
            " extracting: train_labels/image_0489.txt  \n",
            " extracting: train_labels/image_0505.txt  \n",
            " extracting: train_labels/image_0494.txt  \n",
            " extracting: train_labels/image_0495.txt  \n",
            " extracting: train_labels/image_0491.txt  \n",
            " extracting: train_labels/image_0508.txt  \n",
            " extracting: train_labels/image_0500.txt  \n",
            " extracting: train_labels/image_0511.txt  \n",
            " extracting: train_labels/image_0499.txt  \n",
            " extracting: train_labels/image_0487.txt  \n",
            " extracting: train_labels/image_0498.txt  \n",
            " extracting: train_labels/image_0502.txt  \n",
            " extracting: train_labels/image_0509.txt  \n",
            " extracting: train_labels/image_0492.txt  \n",
            " extracting: train_labels/image_0504.txt  \n",
            " extracting: train_labels/image_0497.txt  \n",
            " extracting: train_labels/image_0507.txt  \n",
            " extracting: train_labels/image_0506.txt  \n",
            " extracting: train_labels/image_0490.txt  \n",
            " extracting: train_labels/image_0513.txt  \n",
            " extracting: train_labels/image_0486.txt  \n",
            " extracting: train_labels/image_0493.txt  \n",
            " extracting: train_labels/image_0503.txt  \n",
            " extracting: train_labels/image_0512.txt  \n",
            " extracting: train_labels/image_0501.txt  \n",
            " extracting: train_labels/image_0488.txt  \n",
            " extracting: train_labels/image_0496.txt  \n",
            " extracting: train_labels/image_0510.txt  \n",
            " extracting: train_labels/image_0543.txt  \n",
            " extracting: train_labels/image_0534.txt  \n",
            " extracting: train_labels/image_0528.txt  \n",
            " extracting: train_labels/image_0537.txt  \n",
            " extracting: train_labels/image_0529.txt  \n",
            " extracting: train_labels/image_0526.txt  \n",
            " extracting: train_labels/image_0527.txt  \n",
            " extracting: train_labels/image_0539.txt  \n",
            " extracting: train_labels/image_0519.txt  \n",
            " extracting: train_labels/image_0521.txt  \n",
            " extracting: train_labels/image_0532.txt  \n",
            " extracting: train_labels/image_0515.txt  \n",
            " extracting: train_labels/image_0538.txt  \n",
            " extracting: train_labels/image_0540.txt  \n",
            " extracting: train_labels/image_0520.txt  \n",
            " extracting: train_labels/image_0530.txt  \n",
            " extracting: train_labels/image_0535.txt  \n",
            " extracting: train_labels/image_0525.txt  \n",
            " extracting: train_labels/image_0517.txt  \n",
            " extracting: train_labels/image_0542.txt  \n",
            " extracting: train_labels/image_0516.txt  \n",
            " extracting: train_labels/image_0544.txt  \n",
            " extracting: train_labels/image_0514.txt  \n",
            " extracting: train_labels/image_0541.txt  \n",
            " extracting: train_labels/image_0536.txt  \n",
            " extracting: train_labels/image_0524.txt  \n",
            " extracting: train_labels/image_0531.txt  \n",
            " extracting: train_labels/image_0533.txt  \n",
            " extracting: train_labels/image_0518.txt  \n",
            " extracting: train_labels/image_0522.txt  \n",
            " extracting: train_labels/image_0523.txt  \n",
            " extracting: train_labels/image_0546.txt  \n",
            " extracting: train_labels/image_0563.txt  \n",
            " extracting: train_labels/image_0550.txt  \n",
            " extracting: train_labels/image_0570.txt  \n",
            " extracting: train_labels/image_0558.txt  \n",
            " extracting: train_labels/image_0571.txt  \n",
            " extracting: train_labels/image_0549.txt  \n",
            " extracting: train_labels/image_0562.txt  \n",
            " extracting: train_labels/image_0547.txt  \n",
            " extracting: train_labels/image_0560.txt  \n",
            " extracting: train_labels/image_0555.txt  \n",
            " extracting: train_labels/image_0548.txt  \n",
            " extracting: train_labels/image_0556.txt  \n",
            " extracting: train_labels/image_0566.txt  \n",
            " extracting: train_labels/image_0557.txt  \n",
            " extracting: train_labels/image_0565.txt  \n",
            " extracting: train_labels/image_0561.txt  \n",
            " extracting: train_labels/image_0552.txt  \n",
            " extracting: train_labels/image_0551.txt  \n",
            " extracting: train_labels/image_0569.txt  \n",
            " extracting: train_labels/image_0568.txt  \n",
            " extracting: train_labels/image_0559.txt  \n",
            " extracting: train_labels/image_0553.txt  \n",
            " extracting: train_labels/image_0545.txt  \n",
            " extracting: train_labels/image_0567.txt  \n",
            " extracting: train_labels/image_0554.txt  \n",
            " extracting: train_labels/image_0564.txt  \n",
            " extracting: train_labels/image_0580.txt  \n",
            " extracting: train_labels/image_0572.txt  \n",
            " extracting: train_labels/image_0585.txt  \n",
            " extracting: train_labels/image_0576.txt  \n",
            " extracting: train_labels/image_0592.txt  \n",
            " extracting: train_labels/image_0589.txt  \n",
            " extracting: train_labels/image_0587.txt  \n",
            " extracting: train_labels/image_0598.txt  \n",
            " extracting: train_labels/image_0586.txt  \n",
            " extracting: train_labels/image_0578.txt  \n",
            " extracting: train_labels/image_0582.txt  \n",
            " extracting: train_labels/image_0594.txt  \n",
            " extracting: train_labels/image_0579.txt  \n",
            " extracting: train_labels/image_0593.txt  \n",
            " extracting: train_labels/image_0591.txt  \n",
            " extracting: train_labels/image_0577.txt  \n",
            " extracting: train_labels/image_0573.txt  \n",
            " extracting: train_labels/image_0597.txt  \n",
            " extracting: train_labels/image_0590.txt  \n",
            " extracting: train_labels/image_0596.txt  \n",
            " extracting: train_labels/image_0583.txt  \n",
            " extracting: train_labels/image_0581.txt  \n",
            " extracting: train_labels/image_0574.txt  \n",
            " extracting: train_labels/image_0575.txt  \n",
            " extracting: train_labels/image_0588.txt  \n",
            " extracting: train_labels/image_0595.txt  \n",
            " extracting: train_labels/image_0584.txt  \n",
            " extracting: train_labels/image_0608.txt  \n",
            " extracting: train_labels/image_0603.txt  \n",
            " extracting: train_labels/image_0626.txt  \n",
            " extracting: train_labels/image_0604.txt  \n",
            " extracting: train_labels/image_0613.txt  \n",
            " extracting: train_labels/image_0628.txt  \n",
            " extracting: train_labels/image_0627.txt  \n",
            " extracting: train_labels/image_0606.txt  \n",
            " extracting: train_labels/image_0615.txt  \n",
            " extracting: train_labels/image_0605.txt  \n",
            " extracting: train_labels/image_0623.txt  \n",
            " extracting: train_labels/image_0619.txt  \n",
            " extracting: train_labels/image_0616.txt  \n",
            " extracting: train_labels/image_0614.txt  \n",
            " extracting: train_labels/image_0601.txt  \n",
            " extracting: train_labels/image_0609.txt  \n",
            " extracting: train_labels/image_0624.txt  \n",
            " extracting: train_labels/image_0599.txt  \n",
            " extracting: train_labels/image_0620.txt  \n",
            " extracting: train_labels/image_0611.txt  \n",
            " extracting: train_labels/image_0607.txt  \n",
            " extracting: train_labels/image_0610.txt  \n",
            " extracting: train_labels/image_0622.txt  \n",
            " extracting: train_labels/image_0600.txt  \n",
            " extracting: train_labels/image_0621.txt  \n",
            " extracting: train_labels/image_0612.txt  \n",
            " extracting: train_labels/image_0602.txt  \n",
            " extracting: train_labels/image_0625.txt  \n",
            " extracting: train_labels/image_0618.txt  \n",
            " extracting: train_labels/image_0617.txt  \n",
            " extracting: train_labels/image_0629.txt  \n",
            " extracting: train_labels/image_0632.txt  \n",
            " extracting: train_labels/image_0653.txt  \n",
            " extracting: train_labels/image_0645.txt  \n",
            " extracting: train_labels/image_0634.txt  \n",
            " extracting: train_labels/image_0633.txt  \n",
            " extracting: train_labels/image_0654.txt  \n",
            " extracting: train_labels/image_0630.txt  \n",
            " extracting: train_labels/image_0638.txt  \n",
            " extracting: train_labels/image_0643.txt  \n",
            " extracting: train_labels/image_0640.txt  \n",
            " extracting: train_labels/image_0648.txt  \n",
            " extracting: train_labels/image_0642.txt  \n",
            " extracting: train_labels/image_0641.txt  \n",
            " extracting: train_labels/image_0649.txt  \n",
            " extracting: train_labels/image_0639.txt  \n",
            " extracting: train_labels/image_0635.txt  \n",
            " extracting: train_labels/image_0651.txt  \n",
            " extracting: train_labels/image_0646.txt  \n",
            " extracting: train_labels/image_0644.txt  \n",
            " extracting: train_labels/image_0637.txt  \n",
            " extracting: train_labels/image_0636.txt  \n",
            " extracting: train_labels/image_0631.txt  \n",
            " extracting: train_labels/image_0650.txt  \n",
            " extracting: train_labels/image_0652.txt  \n",
            " extracting: train_labels/image_0647.txt  \n",
            " extracting: train_labels/image_0655.txt  \n",
            " extracting: train_labels/image_0659.txt  \n",
            " extracting: train_labels/image_0682.txt  \n",
            " extracting: train_labels/image_0670.txt  \n",
            " extracting: train_labels/image_0679.txt  \n",
            " extracting: train_labels/image_0663.txt  \n",
            " extracting: train_labels/image_0664.txt  \n",
            " extracting: train_labels/image_0680.txt  \n",
            " extracting: train_labels/image_0660.txt  \n",
            "Archive:  drive/MyDrive/Brainhack/Validation.zip\n",
            " extracting: val_images/image_0637.png  \n",
            " extracting: val_images/image_0632.png  \n",
            " extracting: val_images/image_0705.png  \n",
            " extracting: val_images/image_0700.png  \n",
            " extracting: val_images/image_0638.png  \n",
            " extracting: val_images/image_0660.png  \n",
            " extracting: val_images/image_0661.png  \n",
            " extracting: val_images/image_0693.png  \n",
            " extracting: val_images/image_0634.png  \n",
            " extracting: val_images/image_0636.png  \n",
            " extracting: val_images/image_0704.png  \n",
            " extracting: val_images/image_0654.png  \n",
            " extracting: val_images/image_0669.png  \n",
            " extracting: val_images/image_0671.png  \n",
            " extracting: val_images/image_0653.png  \n",
            " extracting: val_images/image_0678.png  \n",
            " extracting: val_images/image_0690.png  \n",
            " extracting: val_images/image_0675.png  \n",
            " extracting: val_images/image_0650.png  \n",
            " extracting: val_images/image_0706.png  \n",
            " extracting: val_images/image_0662.png  \n",
            " extracting: val_images/image_0668.png  \n",
            " extracting: val_images/image_0676.png  \n",
            " extracting: val_images/image_0677.png  \n",
            " extracting: val_images/image_0664.png  \n",
            " extracting: val_images/image_0688.png  \n",
            " extracting: val_images/image_0670.png  \n",
            " extracting: val_images/image_0667.png  \n",
            " extracting: val_images/image_0703.png  \n",
            " extracting: val_images/image_0692.png  \n",
            " extracting: val_images/image_0658.png  \n",
            " extracting: val_images/image_0707.png  \n",
            " extracting: val_images/image_0655.png  \n",
            " extracting: val_images/image_0689.png  \n",
            " extracting: val_images/image_0656.png  \n",
            " extracting: val_images/image_0685.png  \n",
            " extracting: val_images/image_0659.png  \n",
            " extracting: val_images/image_0644.png  \n",
            " extracting: val_images/image_0698.png  \n",
            " extracting: val_images/image_0641.png  \n",
            " extracting: val_images/image_0672.png  \n",
            " extracting: val_images/image_0681.png  \n",
            " extracting: val_images/image_0696.png  \n",
            " extracting: val_images/image_0643.png  \n",
            " extracting: val_images/image_0694.png  \n",
            " extracting: val_images/image_0652.png  \n",
            " extracting: val_images/image_0674.png  \n",
            " extracting: val_images/image_0640.png  \n",
            " extracting: val_images/image_0631.png  \n",
            " extracting: val_images/image_0639.png  \n",
            " extracting: val_images/image_0657.png  \n",
            " extracting: val_images/image_0680.png  \n",
            " extracting: val_images/image_0666.png  \n",
            " extracting: val_images/image_0686.png  \n",
            " extracting: val_images/image_0684.png  \n",
            " extracting: val_images/image_0683.png  \n",
            " extracting: val_images/image_0649.png  \n",
            " extracting: val_images/image_0697.png  \n",
            " extracting: val_images/image_0648.png  \n",
            " extracting: val_images/image_0645.png  \n",
            " extracting: val_images/image_0663.png  \n",
            " extracting: val_images/image_0701.png  \n",
            " extracting: val_images/image_0642.png  \n",
            " extracting: val_images/image_0647.png  \n",
            " extracting: val_images/image_0687.png  \n",
            " extracting: val_images/image_0665.png  \n",
            " extracting: val_images/image_0673.png  \n",
            " extracting: val_images/image_0630.png  \n",
            " extracting: val_images/image_0679.png  \n",
            " extracting: val_images/image_0635.png  \n",
            " extracting: val_images/image_0633.png  \n",
            " extracting: val_images/image_0646.png  \n",
            " extracting: val_images/image_0691.png  \n",
            " extracting: val_images/image_0702.png  \n",
            " extracting: val_images/image_0695.png  \n",
            " extracting: val_images/image_0682.png  \n",
            " extracting: val_images/image_0651.png  \n",
            " extracting: val_images/image_0699.png  \n",
            " extracting: val_images/image_0717.png  \n",
            " extracting: val_images/image_0709.png  \n",
            " extracting: val_images/image_0780.png  \n",
            " extracting: val_images/image_0721.png  \n",
            " extracting: val_images/image_0716.png  \n",
            " extracting: val_images/image_0726.png  \n",
            " extracting: val_images/image_0764.png  \n",
            " extracting: val_images/image_0751.png  \n",
            " extracting: val_images/image_0762.png  \n",
            " extracting: val_images/image_0772.png  \n",
            " extracting: val_images/image_0740.png  \n",
            " extracting: val_images/image_0770.png  \n",
            " extracting: val_images/image_0712.png  \n",
            " extracting: val_images/image_0749.png  \n",
            " extracting: val_images/image_0739.png  \n",
            " extracting: val_images/image_0755.png  \n",
            " extracting: val_images/image_0752.png  \n",
            " extracting: val_images/image_0738.png  \n",
            " extracting: val_images/image_0766.png  \n",
            " extracting: val_images/image_0776.png  \n",
            " extracting: val_images/image_0715.png  \n",
            " extracting: val_images/image_0742.png  \n",
            " extracting: val_images/image_0741.png  \n",
            " extracting: val_images/image_0756.png  \n",
            " extracting: val_images/image_0773.png  \n",
            " extracting: val_images/image_0753.png  \n",
            " extracting: val_images/image_0724.png  \n",
            " extracting: val_images/image_0746.png  \n",
            " extracting: val_images/image_0728.png  \n",
            " extracting: val_images/image_0748.png  \n",
            " extracting: val_images/image_0714.png  \n",
            " extracting: val_images/image_0737.png  \n",
            " extracting: val_images/image_0769.png  \n",
            " extracting: val_images/image_0732.png  \n",
            " extracting: val_images/image_0779.png  \n",
            " extracting: val_images/image_0710.png  \n",
            " extracting: val_images/image_0761.png  \n",
            " extracting: val_images/image_0750.png  \n",
            " extracting: val_images/image_0729.png  \n",
            " extracting: val_images/image_0727.png  \n",
            " extracting: val_images/image_0735.png  \n",
            " extracting: val_images/image_0736.png  \n",
            " extracting: val_images/image_0771.png  \n",
            " extracting: val_images/image_0744.png  \n",
            " extracting: val_images/image_0775.png  \n",
            " extracting: val_images/image_0731.png  \n",
            " extracting: val_images/image_0719.png  \n",
            " extracting: val_images/image_0711.png  \n",
            " extracting: val_images/image_0763.png  \n",
            " extracting: val_images/image_0713.png  \n",
            " extracting: val_images/image_0759.png  \n",
            " extracting: val_images/image_0734.png  \n",
            " extracting: val_images/image_0718.png  \n",
            " extracting: val_images/image_0725.png  \n",
            " extracting: val_images/image_0722.png  \n",
            " extracting: val_images/image_0754.png  \n",
            " extracting: val_images/image_0723.png  \n",
            " extracting: val_images/image_0747.png  \n",
            " extracting: val_images/image_0733.png  \n",
            " extracting: val_images/image_0758.png  \n",
            " extracting: val_images/image_0745.png  \n",
            " extracting: val_images/image_0774.png  \n",
            " extracting: val_images/image_0730.png  \n",
            " extracting: val_images/image_0767.png  \n",
            " extracting: val_images/image_0708.png  \n",
            " extracting: val_images/image_0765.png  \n",
            " extracting: val_images/image_0743.png  \n",
            " extracting: val_images/image_0777.png  \n",
            " extracting: val_images/image_0768.png  \n",
            " extracting: val_images/image_0720.png  \n",
            " extracting: val_images/image_0757.png  \n",
            " extracting: val_images/image_0778.png  \n",
            " extracting: val_images/image_0760.png  \n",
            " extracting: val_images/image_0789.png  \n",
            " extracting: val_images/image_0791.png  \n",
            " extracting: val_images/image_0788.png  \n",
            " extracting: val_images/image_0781.png  \n",
            " extracting: val_images/image_0797.png  \n",
            " extracting: val_images/image_0792.png  \n",
            " extracting: val_images/image_0786.png  \n",
            " extracting: val_images/image_0784.png  \n",
            " extracting: val_images/image_0790.png  \n",
            " extracting: val_images/image_0787.png  \n",
            " extracting: val_images/image_0799.png  \n",
            " extracting: val_images/image_0783.png  \n",
            " extracting: val_images/image_0796.png  \n",
            " extracting: val_images/image_0798.png  \n",
            " extracting: val_images/image_0795.png  \n",
            " extracting: val_images/image_0785.png  \n",
            " extracting: val_images/image_0782.png  \n",
            " extracting: val_images/image_0794.png  \n",
            " extracting: val_images/image_0793.png  \n",
            " extracting: val_images/image_0006.png  \n",
            " extracting: val_images/image_0010.png  \n",
            " extracting: val_images/image_0013.png  \n",
            " extracting: val_images/image_0012.png  \n",
            " extracting: val_images/image_0014.png  \n",
            " extracting: val_images/image_0009.png  \n",
            " extracting: val_images/image_0019.png  \n",
            " extracting: val_images/image_0016.png  \n",
            " extracting: val_images/image_0001.png  \n",
            " extracting: val_images/image_0003.png  \n",
            " extracting: val_images/image_0017.png  \n",
            " extracting: val_images/image_0008.png  \n",
            " extracting: val_images/image_0002.png  \n",
            " extracting: val_images/image_0018.png  \n",
            " extracting: val_images/image_0020.png  \n",
            " extracting: val_images/image_0007.png  \n",
            " extracting: val_images/image_0011.png  \n",
            " extracting: val_images/image_0005.png  \n",
            " extracting: val_images/image_0000.png  \n",
            " extracting: val_images/image_0004.png  \n",
            " extracting: val_images/image_0015.png  \n",
            " extracting: val_images/image_0070.png  \n",
            " extracting: val_images/image_0045.png  \n",
            " extracting: val_images/image_0057.png  \n",
            " extracting: val_images/image_0035.png  \n",
            " extracting: val_images/image_0078.png  \n",
            " extracting: val_images/image_0058.png  \n",
            " extracting: val_images/image_0080.png  \n",
            " extracting: val_images/image_0022.png  \n",
            " extracting: val_images/image_0065.png  \n",
            " extracting: val_images/image_0066.png  \n",
            " extracting: val_images/image_0047.png  \n",
            " extracting: val_images/image_0074.png  \n",
            " extracting: val_images/image_0042.png  \n",
            " extracting: val_images/image_0037.png  \n",
            " extracting: val_images/image_0083.png  \n",
            " extracting: val_images/image_0026.png  \n",
            " extracting: val_images/image_0072.png  \n",
            " extracting: val_images/image_0044.png  \n",
            " extracting: val_images/image_0090.png  \n",
            " extracting: val_images/image_0033.png  \n",
            " extracting: val_images/image_0085.png  \n",
            " extracting: val_images/image_0050.png  \n",
            " extracting: val_images/image_0082.png  \n",
            " extracting: val_images/image_0051.png  \n",
            " extracting: val_images/image_0071.png  \n",
            " extracting: val_images/image_0025.png  \n",
            " extracting: val_images/image_0073.png  \n",
            " extracting: val_images/image_0063.png  \n",
            " extracting: val_images/image_0087.png  \n",
            " extracting: val_images/image_0032.png  \n",
            " extracting: val_images/image_0049.png  \n",
            " extracting: val_images/image_0041.png  \n",
            " extracting: val_images/image_0061.png  \n",
            " extracting: val_images/image_0093.png  \n",
            " extracting: val_images/image_0031.png  \n",
            " extracting: val_images/image_0028.png  \n",
            " extracting: val_images/image_0094.png  \n",
            " extracting: val_images/image_0067.png  \n",
            " extracting: val_images/image_0059.png  \n",
            " extracting: val_images/image_0043.png  \n",
            " extracting: val_images/image_0056.png  \n",
            " extracting: val_images/image_0088.png  \n",
            " extracting: val_images/image_0086.png  \n",
            " extracting: val_images/image_0064.png  \n",
            " extracting: val_images/image_0048.png  \n",
            " extracting: val_images/image_0030.png  \n",
            " extracting: val_images/image_0054.png  \n",
            " extracting: val_images/image_0040.png  \n",
            " extracting: val_images/image_0077.png  \n",
            " extracting: val_images/image_0079.png  \n",
            " extracting: val_images/image_0060.png  \n",
            " extracting: val_images/image_0068.png  \n",
            " extracting: val_images/image_0021.png  \n",
            " extracting: val_images/image_0055.png  \n",
            " extracting: val_images/image_0039.png  \n",
            " extracting: val_images/image_0027.png  \n",
            " extracting: val_images/image_0023.png  \n",
            " extracting: val_images/image_0062.png  \n",
            " extracting: val_images/image_0089.png  \n",
            " extracting: val_images/image_0036.png  \n",
            " extracting: val_images/image_0091.png  \n",
            " extracting: val_images/image_0069.png  \n",
            " extracting: val_images/image_0081.png  \n",
            " extracting: val_images/image_0092.png  \n",
            " extracting: val_images/image_0075.png  \n",
            " extracting: val_images/image_0034.png  \n",
            " extracting: val_images/image_0053.png  \n",
            " extracting: val_images/image_0029.png  \n",
            " extracting: val_images/image_0084.png  \n",
            " extracting: val_images/image_0046.png  \n",
            " extracting: val_images/image_0052.png  \n",
            " extracting: val_images/image_0038.png  \n",
            " extracting: val_images/image_0024.png  \n",
            " extracting: val_images/image_0076.png  \n",
            " extracting: val_images/image_0095.png  \n",
            " extracting: val_images/image_0132.png  \n",
            " extracting: val_images/image_0128.png  \n",
            " extracting: val_images/image_0161.png  \n",
            " extracting: val_images/image_0120.png  \n",
            " extracting: val_images/image_0126.png  \n",
            " extracting: val_images/image_0139.png  \n",
            " extracting: val_images/image_0119.png  \n",
            " extracting: val_images/image_0140.png  \n",
            " extracting: val_images/image_0135.png  \n",
            " extracting: val_images/image_0142.png  \n",
            " extracting: val_images/image_0102.png  \n",
            " extracting: val_images/image_0125.png  \n",
            " extracting: val_images/image_0147.png  \n",
            " extracting: val_images/image_0104.png  \n",
            " extracting: val_images/image_0170.png  \n",
            " extracting: val_images/image_0127.png  \n",
            " extracting: val_images/image_0121.png  \n",
            " extracting: val_images/image_0116.png  \n",
            " extracting: val_images/image_0130.png  \n",
            " extracting: val_images/image_0115.png  \n",
            " extracting: val_images/image_0163.png  \n",
            " extracting: val_images/image_0106.png  \n",
            " extracting: val_images/image_0150.png  \n",
            " extracting: val_images/image_0167.png  \n",
            " extracting: val_images/image_0100.png  \n",
            " extracting: val_images/image_0110.png  \n",
            " extracting: val_images/image_0169.png  \n",
            " extracting: val_images/image_0157.png  \n",
            " extracting: val_images/image_0122.png  \n",
            " extracting: val_images/image_0160.png  \n",
            " extracting: val_images/image_0101.png  \n",
            " extracting: val_images/image_0155.png  \n",
            " extracting: val_images/image_0111.png  \n",
            " extracting: val_images/image_0137.png  \n",
            " extracting: val_images/image_0124.png  \n",
            " extracting: val_images/image_0164.png  \n",
            " extracting: val_images/image_0107.png  \n",
            " extracting: val_images/image_0145.png  \n",
            " extracting: val_images/image_0159.png  \n",
            " extracting: val_images/image_0162.png  \n",
            " extracting: val_images/image_0151.png  \n",
            " extracting: val_images/image_0099.png  \n",
            " extracting: val_images/image_0117.png  \n",
            " extracting: val_images/image_0156.png  \n",
            " extracting: val_images/image_0148.png  \n",
            " extracting: val_images/image_0134.png  \n",
            " extracting: val_images/image_0138.png  \n",
            " extracting: val_images/image_0158.png  \n",
            " extracting: val_images/image_0133.png  \n",
            " extracting: val_images/image_0109.png  \n",
            " extracting: val_images/image_0149.png  \n",
            " extracting: val_images/image_0098.png  \n",
            " extracting: val_images/image_0114.png  \n",
            " extracting: val_images/image_0123.png  \n",
            " extracting: val_images/image_0103.png  \n",
            " extracting: val_images/image_0165.png  \n",
            " extracting: val_images/image_0152.png  \n",
            " extracting: val_images/image_0154.png  \n",
            " extracting: val_images/image_0105.png  \n",
            " extracting: val_images/image_0166.png  \n",
            " extracting: val_images/image_0153.png  \n",
            " extracting: val_images/image_0113.png  \n",
            " extracting: val_images/image_0118.png  \n",
            " extracting: val_images/image_0096.png  \n",
            " extracting: val_images/image_0131.png  \n",
            " extracting: val_images/image_0097.png  \n",
            " extracting: val_images/image_0108.png  \n",
            " extracting: val_images/image_0136.png  \n",
            " extracting: val_images/image_0129.png  \n",
            " extracting: val_images/image_0144.png  \n",
            " extracting: val_images/image_0112.png  \n",
            " extracting: val_images/image_0143.png  \n",
            " extracting: val_images/image_0168.png  \n",
            " extracting: val_images/image_0146.png  \n",
            " extracting: val_images/image_0141.png  \n",
            " extracting: val_images/image_0192.png  \n",
            " extracting: val_images/image_0248.png  \n",
            " extracting: val_images/image_0182.png  \n",
            " extracting: val_images/image_0229.png  \n",
            " extracting: val_images/image_0247.png  \n",
            " extracting: val_images/image_0238.png  \n",
            " extracting: val_images/image_0190.png  \n",
            " extracting: val_images/image_0201.png  \n",
            " extracting: val_images/image_0227.png  \n",
            " extracting: val_images/image_0203.png  \n",
            " extracting: val_images/image_0197.png  \n",
            " extracting: val_images/image_0212.png  \n",
            " extracting: val_images/image_0178.png  \n",
            " extracting: val_images/image_0219.png  \n",
            " extracting: val_images/image_0200.png  \n",
            " extracting: val_images/image_0198.png  \n",
            " extracting: val_images/image_0235.png  \n",
            " extracting: val_images/image_0217.png  \n",
            " extracting: val_images/image_0180.png  \n",
            " extracting: val_images/image_0218.png  \n",
            " extracting: val_images/image_0240.png  \n",
            " extracting: val_images/image_0223.png  \n",
            " extracting: val_images/image_0225.png  \n",
            " extracting: val_images/image_0175.png  \n",
            " extracting: val_images/image_0205.png  \n",
            " extracting: val_images/image_0242.png  \n",
            " extracting: val_images/image_0211.png  \n",
            " extracting: val_images/image_0215.png  \n",
            " extracting: val_images/image_0213.png  \n",
            " extracting: val_images/image_0196.png  \n",
            " extracting: val_images/image_0172.png  \n",
            " extracting: val_images/image_0202.png  \n",
            " extracting: val_images/image_0234.png  \n",
            " extracting: val_images/image_0208.png  \n",
            " extracting: val_images/image_0231.png  \n",
            " extracting: val_images/image_0224.png  \n",
            " extracting: val_images/image_0184.png  \n",
            " extracting: val_images/image_0204.png  \n",
            " extracting: val_images/image_0188.png  \n",
            " extracting: val_images/image_0236.png  \n",
            " extracting: val_images/image_0246.png  \n",
            " extracting: val_images/image_0221.png  \n",
            " extracting: val_images/image_0241.png  \n",
            " extracting: val_images/image_0232.png  \n",
            " extracting: val_images/image_0233.png  \n",
            " extracting: val_images/image_0194.png  \n",
            " extracting: val_images/image_0239.png  \n",
            " extracting: val_images/image_0207.png  \n",
            " extracting: val_images/image_0228.png  \n",
            " extracting: val_images/image_0216.png  \n",
            " extracting: val_images/image_0176.png  \n",
            " extracting: val_images/image_0237.png  \n",
            " extracting: val_images/image_0210.png  \n",
            " extracting: val_images/image_0177.png  \n",
            " extracting: val_images/image_0230.png  \n",
            " extracting: val_images/image_0199.png  \n",
            " extracting: val_images/image_0244.png  \n",
            " extracting: val_images/image_0171.png  \n",
            " extracting: val_images/image_0179.png  \n",
            " extracting: val_images/image_0185.png  \n",
            " extracting: val_images/image_0174.png  \n",
            " extracting: val_images/image_0183.png  \n",
            " extracting: val_images/image_0195.png  \n",
            " extracting: val_images/image_0226.png  \n",
            " extracting: val_images/image_0245.png  \n",
            " extracting: val_images/image_0189.png  \n",
            " extracting: val_images/image_0206.png  \n",
            " extracting: val_images/image_0209.png  \n",
            " extracting: val_images/image_0193.png  \n",
            " extracting: val_images/image_0214.png  \n",
            " extracting: val_images/image_0191.png  \n",
            " extracting: val_images/image_0187.png  \n",
            " extracting: val_images/image_0243.png  \n",
            " extracting: val_images/image_0181.png  \n",
            " extracting: val_images/image_0173.png  \n",
            " extracting: val_images/image_0186.png  \n",
            " extracting: val_images/image_0220.png  \n",
            " extracting: val_images/image_0222.png  \n",
            " extracting: val_images/image_0256.png  \n",
            " extracting: val_images/image_0307.png  \n",
            " extracting: val_images/image_0262.png  \n",
            " extracting: val_images/image_0269.png  \n",
            " extracting: val_images/image_0258.png  \n",
            " extracting: val_images/image_0274.png  \n",
            " extracting: val_images/image_0310.png  \n",
            " extracting: val_images/image_0254.png  \n",
            " extracting: val_images/image_0299.png  \n",
            " extracting: val_images/image_0326.png  \n",
            " extracting: val_images/image_0259.png  \n",
            " extracting: val_images/image_0298.png  \n",
            " extracting: val_images/image_0280.png  \n",
            " extracting: val_images/image_0288.png  \n",
            " extracting: val_images/image_0266.png  \n",
            " extracting: val_images/image_0249.png  \n",
            " extracting: val_images/image_0301.png  \n",
            " extracting: val_images/image_0305.png  \n",
            " extracting: val_images/image_0279.png  \n",
            " extracting: val_images/image_0253.png  \n",
            " extracting: val_images/image_0325.png  \n",
            " extracting: val_images/image_0322.png  \n",
            " extracting: val_images/image_0264.png  \n",
            " extracting: val_images/image_0291.png  \n",
            " extracting: val_images/image_0251.png  \n",
            " extracting: val_images/image_0315.png  \n",
            " extracting: val_images/image_0260.png  \n",
            " extracting: val_images/image_0294.png  \n",
            " extracting: val_images/image_0304.png  \n",
            " extracting: val_images/image_0324.png  \n",
            " extracting: val_images/image_0306.png  \n",
            " extracting: val_images/image_0313.png  \n",
            " extracting: val_images/image_0297.png  \n",
            " extracting: val_images/image_0255.png  \n",
            " extracting: val_images/image_0309.png  \n",
            " extracting: val_images/image_0257.png  \n",
            " extracting: val_images/image_0320.png  \n",
            " extracting: val_images/image_0314.png  \n",
            " extracting: val_images/image_0290.png  \n",
            " extracting: val_images/image_0282.png  \n",
            " extracting: val_images/image_0276.png  \n",
            " extracting: val_images/image_0271.png  \n",
            " extracting: val_images/image_0287.png  \n",
            " extracting: val_images/image_0273.png  \n",
            " extracting: val_images/image_0267.png  \n",
            " extracting: val_images/image_0316.png  \n",
            " extracting: val_images/image_0293.png  \n",
            " extracting: val_images/image_0268.png  \n",
            " extracting: val_images/image_0285.png  \n",
            " extracting: val_images/image_0284.png  \n",
            " extracting: val_images/image_0312.png  \n",
            " extracting: val_images/image_0321.png  \n",
            " extracting: val_images/image_0286.png  \n",
            " extracting: val_images/image_0252.png  \n",
            " extracting: val_images/image_0318.png  \n",
            " extracting: val_images/image_0295.png  \n",
            " extracting: val_images/image_0277.png  \n",
            " extracting: val_images/image_0308.png  \n",
            " extracting: val_images/image_0302.png  \n",
            " extracting: val_images/image_0311.png  \n",
            " extracting: val_images/image_0263.png  \n",
            " extracting: val_images/image_0265.png  \n",
            " extracting: val_images/image_0261.png  \n",
            " extracting: val_images/image_0319.png  \n",
            " extracting: val_images/image_0272.png  \n",
            " extracting: val_images/image_0289.png  \n",
            " extracting: val_images/image_0270.png  \n",
            " extracting: val_images/image_0275.png  \n",
            " extracting: val_images/image_0300.png  \n",
            " extracting: val_images/image_0292.png  \n",
            " extracting: val_images/image_0283.png  \n",
            " extracting: val_images/image_0296.png  \n",
            " extracting: val_images/image_0281.png  \n",
            " extracting: val_images/image_0323.png  \n",
            " extracting: val_images/image_0303.png  \n",
            " extracting: val_images/image_0317.png  \n",
            " extracting: val_images/image_0250.png  \n",
            " extracting: val_images/image_0278.png  \n",
            " extracting: val_images/image_0377.png  \n",
            " extracting: val_images/image_0382.png  \n",
            " extracting: val_images/image_0328.png  \n",
            " extracting: val_images/image_0391.png  \n",
            " extracting: val_images/image_0343.png  \n",
            " extracting: val_images/image_0340.png  \n",
            " extracting: val_images/image_0392.png  \n",
            " extracting: val_images/image_0361.png  \n",
            " extracting: val_images/image_0395.png  \n",
            " extracting: val_images/image_0353.png  \n",
            " extracting: val_images/image_0401.png  \n",
            " extracting: val_images/image_0386.png  \n",
            " extracting: val_images/image_0372.png  \n",
            " extracting: val_images/image_0329.png  \n",
            " extracting: val_images/image_0380.png  \n",
            " extracting: val_images/image_0399.png  \n",
            " extracting: val_images/image_0375.png  \n",
            " extracting: val_images/image_0368.png  \n",
            " extracting: val_images/image_0381.png  \n",
            " extracting: val_images/image_0344.png  \n",
            " extracting: val_images/image_0402.png  \n",
            " extracting: val_images/image_0333.png  \n",
            " extracting: val_images/image_0351.png  \n",
            " extracting: val_images/image_0387.png  \n",
            " extracting: val_images/image_0346.png  \n",
            " extracting: val_images/image_0345.png  \n",
            " extracting: val_images/image_0365.png  \n",
            " extracting: val_images/image_0354.png  \n",
            " extracting: val_images/image_0388.png  \n",
            " extracting: val_images/image_0348.png  \n",
            " extracting: val_images/image_0350.png  \n",
            " extracting: val_images/image_0335.png  \n",
            " extracting: val_images/image_0364.png  \n",
            " extracting: val_images/image_0378.png  \n",
            " extracting: val_images/image_0358.png  \n",
            " extracting: val_images/image_0370.png  \n",
            " extracting: val_images/image_0349.png  \n",
            " extracting: val_images/image_0347.png  \n",
            " extracting: val_images/image_0383.png  \n",
            " extracting: val_images/image_0393.png  \n",
            " extracting: val_images/image_0338.png  \n",
            " extracting: val_images/image_0373.png  \n",
            " extracting: val_images/image_0404.png  \n",
            " extracting: val_images/image_0352.png  \n",
            " extracting: val_images/image_0342.png  \n",
            " extracting: val_images/image_0379.png  \n",
            " extracting: val_images/image_0334.png  \n",
            " extracting: val_images/image_0376.png  \n",
            " extracting: val_images/image_0359.png  \n",
            " extracting: val_images/image_0374.png  \n",
            " extracting: val_images/image_0357.png  \n",
            " extracting: val_images/image_0394.png  \n",
            " extracting: val_images/image_0332.png  \n",
            " extracting: val_images/image_0355.png  \n",
            " extracting: val_images/image_0389.png  \n",
            " extracting: val_images/image_0390.png  \n",
            " extracting: val_images/image_0371.png  \n",
            " extracting: val_images/image_0330.png  \n",
            " extracting: val_images/image_0367.png  \n",
            " extracting: val_images/image_0341.png  \n",
            " extracting: val_images/image_0331.png  \n",
            " extracting: val_images/image_0396.png  \n",
            " extracting: val_images/image_0384.png  \n",
            " extracting: val_images/image_0400.png  \n",
            " extracting: val_images/image_0337.png  \n",
            " extracting: val_images/image_0363.png  \n",
            " extracting: val_images/image_0360.png  \n",
            " extracting: val_images/image_0356.png  \n",
            " extracting: val_images/image_0369.png  \n",
            " extracting: val_images/image_0336.png  \n",
            " extracting: val_images/image_0339.png  \n",
            " extracting: val_images/image_0397.png  \n",
            " extracting: val_images/image_0327.png  \n",
            " extracting: val_images/image_0385.png  \n",
            " extracting: val_images/image_0403.png  \n",
            " extracting: val_images/image_0398.png  \n",
            " extracting: val_images/image_0366.png  \n",
            " extracting: val_images/image_0362.png  \n",
            " extracting: val_images/image_0442.png  \n",
            " extracting: val_images/image_0427.png  \n",
            " extracting: val_images/image_0440.png  \n",
            " extracting: val_images/image_0447.png  \n",
            " extracting: val_images/image_0444.png  \n",
            " extracting: val_images/image_0414.png  \n",
            " extracting: val_images/image_0436.png  \n",
            " extracting: val_images/image_0467.png  \n",
            " extracting: val_images/image_0438.png  \n",
            " extracting: val_images/image_0456.png  \n",
            " extracting: val_images/image_0450.png  \n",
            " extracting: val_images/image_0432.png  \n",
            " extracting: val_images/image_0413.png  \n",
            " extracting: val_images/image_0408.png  \n",
            " extracting: val_images/image_0473.png  \n",
            " extracting: val_images/image_0430.png  \n",
            " extracting: val_images/image_0434.png  \n",
            " extracting: val_images/image_0465.png  \n",
            " extracting: val_images/image_0419.png  \n",
            " extracting: val_images/image_0457.png  \n",
            " extracting: val_images/image_0466.png  \n",
            " extracting: val_images/image_0429.png  \n",
            " extracting: val_images/image_0459.png  \n",
            " extracting: val_images/image_0451.png  \n",
            " extracting: val_images/image_0418.png  \n",
            " extracting: val_images/image_0411.png  \n",
            " extracting: val_images/image_0435.png  \n",
            " extracting: val_images/image_0424.png  \n",
            " extracting: val_images/image_0453.png  \n",
            " extracting: val_images/image_0437.png  \n",
            " extracting: val_images/image_0439.png  \n",
            " extracting: val_images/image_0425.png  \n",
            " extracting: val_images/image_0464.png  \n",
            " extracting: val_images/image_0471.png  \n",
            " extracting: val_images/image_0406.png  \n",
            " extracting: val_images/image_0461.png  \n",
            " extracting: val_images/image_0468.png  \n",
            " extracting: val_images/image_0409.png  \n",
            " extracting: val_images/image_0446.png  \n",
            " extracting: val_images/image_0445.png  \n",
            " extracting: val_images/image_0455.png  \n",
            " extracting: val_images/image_0426.png  \n",
            " extracting: val_images/image_0462.png  \n",
            " extracting: val_images/image_0416.png  \n",
            " extracting: val_images/image_0421.png  \n",
            " extracting: val_images/image_0472.png  \n",
            " extracting: val_images/image_0460.png  \n",
            " extracting: val_images/image_0428.png  \n",
            " extracting: val_images/image_0463.png  \n",
            " extracting: val_images/image_0422.png  \n",
            " extracting: val_images/image_0458.png  \n",
            " extracting: val_images/image_0441.png  \n",
            " extracting: val_images/image_0415.png  \n",
            " extracting: val_images/image_0454.png  \n",
            " extracting: val_images/image_0469.png  \n",
            " extracting: val_images/image_0452.png  \n",
            " extracting: val_images/image_0407.png  \n",
            " extracting: val_images/image_0433.png  \n",
            " extracting: val_images/image_0431.png  \n",
            " extracting: val_images/image_0443.png  \n",
            " extracting: val_images/image_0470.png  \n",
            " extracting: val_images/image_0405.png  \n",
            " extracting: val_images/image_0448.png  \n",
            " extracting: val_images/image_0410.png  \n",
            " extracting: val_images/image_0420.png  \n",
            " extracting: val_images/image_0412.png  \n",
            " extracting: val_images/image_0449.png  \n",
            " extracting: val_images/image_0423.png  \n",
            " extracting: val_images/image_0417.png  \n",
            " extracting: val_images/image_0494.png  \n",
            " extracting: val_images/image_0528.png  \n",
            " extracting: val_images/image_0491.png  \n",
            " extracting: val_images/image_0479.png  \n",
            " extracting: val_images/image_0504.png  \n",
            " extracting: val_images/image_0526.png  \n",
            " extracting: val_images/image_0507.png  \n",
            " extracting: val_images/image_0545.png  \n",
            " extracting: val_images/image_0502.png  \n",
            " extracting: val_images/image_0485.png  \n",
            " extracting: val_images/image_0524.png  \n",
            " extracting: val_images/image_0477.png  \n",
            " extracting: val_images/image_0481.png  \n",
            " extracting: val_images/image_0492.png  \n",
            " extracting: val_images/image_0487.png  \n",
            " extracting: val_images/image_0482.png  \n",
            " extracting: val_images/image_0498.png  \n",
            " extracting: val_images/image_0499.png  \n",
            " extracting: val_images/image_0547.png  \n",
            " extracting: val_images/image_0501.png  \n",
            " extracting: val_images/image_0476.png  \n",
            " extracting: val_images/image_0532.png  \n",
            " extracting: val_images/image_0535.png  \n",
            " extracting: val_images/image_0522.png  \n",
            " extracting: val_images/image_0544.png  \n",
            " extracting: val_images/image_0478.png  \n",
            " extracting: val_images/image_0536.png  \n",
            " extracting: val_images/image_0546.png  \n",
            " extracting: val_images/image_0483.png  \n",
            " extracting: val_images/image_0538.png  \n",
            " extracting: val_images/image_0518.png  \n",
            " extracting: val_images/image_0531.png  \n",
            " extracting: val_images/image_0533.png  \n",
            " extracting: val_images/image_0511.png  \n",
            " extracting: val_images/image_0480.png  \n",
            " extracting: val_images/image_0517.png  \n",
            " extracting: val_images/image_0506.png  \n",
            " extracting: val_images/image_0541.png  \n",
            " extracting: val_images/image_0542.png  \n",
            " extracting: val_images/image_0514.png  \n",
            " extracting: val_images/image_0512.png  \n",
            " extracting: val_images/image_0550.png  \n",
            " extracting: val_images/image_0523.png  \n",
            " extracting: val_images/image_0513.png  \n",
            " extracting: val_images/image_0519.png  \n",
            " extracting: val_images/image_0510.png  \n",
            " extracting: val_images/image_0527.png  \n",
            " extracting: val_images/image_0474.png  \n",
            " extracting: val_images/image_0500.png  \n",
            " extracting: val_images/image_0537.png  \n",
            " extracting: val_images/image_0490.png  \n",
            " extracting: val_images/image_0489.png  \n",
            " extracting: val_images/image_0515.png  \n",
            " extracting: val_images/image_0495.png  \n",
            " extracting: val_images/image_0503.png  \n",
            " extracting: val_images/image_0548.png  \n",
            " extracting: val_images/image_0529.png  \n",
            " extracting: val_images/image_0521.png  \n",
            " extracting: val_images/image_0505.png  \n",
            " extracting: val_images/image_0543.png  \n",
            " extracting: val_images/image_0534.png  \n",
            " extracting: val_images/image_0475.png  \n",
            " extracting: val_images/image_0508.png  \n",
            " extracting: val_images/image_0539.png  \n",
            " extracting: val_images/image_0497.png  \n",
            " extracting: val_images/image_0486.png  \n",
            " extracting: val_images/image_0549.png  \n",
            " extracting: val_images/image_0540.png  \n",
            " extracting: val_images/image_0509.png  \n",
            " extracting: val_images/image_0496.png  \n",
            " extracting: val_images/image_0493.png  \n",
            " extracting: val_images/image_0516.png  \n",
            " extracting: val_images/image_0520.png  \n",
            " extracting: val_images/image_0488.png  \n",
            " extracting: val_images/image_0525.png  \n",
            " extracting: val_images/image_0530.png  \n",
            " extracting: val_images/image_0484.png  \n",
            " extracting: val_images/image_0591.png  \n",
            " extracting: val_images/image_0577.png  \n",
            " extracting: val_images/image_0599.png  \n",
            " extracting: val_images/image_0605.png  \n",
            " extracting: val_images/image_0589.png  \n",
            " extracting: val_images/image_0610.png  \n",
            " extracting: val_images/image_0556.png  \n",
            " extracting: val_images/image_0572.png  \n",
            " extracting: val_images/image_0576.png  \n",
            " extracting: val_images/image_0604.png  \n",
            " extracting: val_images/image_0574.png  \n",
            " extracting: val_images/image_0602.png  \n",
            " extracting: val_images/image_0561.png  \n",
            " extracting: val_images/image_0613.png  \n",
            " extracting: val_images/image_0584.png  \n",
            " extracting: val_images/image_0573.png  \n",
            " extracting: val_images/image_0571.png  \n",
            " extracting: val_images/image_0629.png  \n",
            " extracting: val_images/image_0586.png  \n",
            " extracting: val_images/image_0619.png  \n",
            " extracting: val_images/image_0552.png  \n",
            " extracting: val_images/image_0611.png  \n",
            " extracting: val_images/image_0598.png  \n",
            " extracting: val_images/image_0601.png  \n",
            " extracting: val_images/image_0593.png  \n",
            " extracting: val_images/image_0558.png  \n",
            " extracting: val_images/image_0569.png  \n",
            " extracting: val_images/image_0616.png  \n",
            " extracting: val_images/image_0600.png  \n",
            " extracting: val_images/image_0628.png  \n",
            " extracting: val_images/image_0627.png  \n",
            " extracting: val_images/image_0624.png  \n",
            " extracting: val_images/image_0585.png  \n",
            " extracting: val_images/image_0562.png  \n",
            " extracting: val_images/image_0568.png  \n",
            " extracting: val_images/image_0575.png  \n",
            " extracting: val_images/image_0595.png  \n",
            " extracting: val_images/image_0608.png  \n",
            " extracting: val_images/image_0621.png  \n",
            " extracting: val_images/image_0606.png  \n",
            " extracting: val_images/image_0620.png  \n",
            " extracting: val_images/image_0603.png  \n",
            " extracting: val_images/image_0582.png  \n",
            " extracting: val_images/image_0580.png  \n",
            " extracting: val_images/image_0623.png  \n",
            " extracting: val_images/image_0592.png  \n",
            " extracting: val_images/image_0612.png  \n",
            " extracting: val_images/image_0559.png  \n",
            " extracting: val_images/image_0626.png  \n",
            " extracting: val_images/image_0615.png  \n",
            " extracting: val_images/image_0618.png  \n",
            " extracting: val_images/image_0554.png  \n",
            " extracting: val_images/image_0581.png  \n",
            " extracting: val_images/image_0570.png  \n",
            " extracting: val_images/image_0564.png  \n",
            " extracting: val_images/image_0565.png  \n",
            " extracting: val_images/image_0587.png  \n",
            " extracting: val_images/image_0566.png  \n",
            " extracting: val_images/image_0590.png  \n",
            " extracting: val_images/image_0622.png  \n",
            " extracting: val_images/image_0567.png  \n",
            " extracting: val_images/image_0597.png  \n",
            " extracting: val_images/image_0560.png  \n",
            " extracting: val_images/image_0555.png  \n",
            " extracting: val_images/image_0579.png  \n",
            " extracting: val_images/image_0578.png  \n",
            " extracting: val_images/image_0596.png  \n",
            " extracting: val_images/image_0553.png  \n",
            " extracting: val_images/image_0551.png  \n",
            " extracting: val_images/image_0617.png  \n",
            " extracting: val_images/image_0614.png  \n",
            " extracting: val_images/image_0609.png  \n",
            " extracting: val_images/image_0557.png  \n",
            " extracting: val_images/image_0588.png  \n",
            " extracting: val_images/image_0563.png  \n",
            " extracting: val_images/image_0625.png  \n",
            " extracting: val_images/image_0583.png  \n",
            " extracting: val_images/image_0607.png  \n",
            " extracting: val_images/image_0594.png  \n",
            "Archive:  drive/MyDrive/Brainhack/val_labels.zip\n",
            " extracting: val_labels/image_0000.txt  \n",
            " extracting: val_labels/image_0020.txt  \n",
            " extracting: val_labels/image_0016.txt  \n",
            " extracting: val_labels/image_0012.txt  \n",
            " extracting: val_labels/image_0011.txt  \n",
            " extracting: val_labels/image_0009.txt  \n",
            " extracting: val_labels/image_0015.txt  \n",
            " extracting: val_labels/image_0010.txt  \n",
            " extracting: val_labels/image_0008.txt  \n",
            " extracting: val_labels/image_0018.txt  \n",
            " extracting: val_labels/image_0013.txt  \n",
            " extracting: val_labels/image_0001.txt  \n",
            " extracting: val_labels/image_0003.txt  \n",
            " extracting: val_labels/image_0007.txt  \n",
            " extracting: val_labels/image_0019.txt  \n",
            " extracting: val_labels/image_0006.txt  \n",
            " extracting: val_labels/image_0014.txt  \n",
            " extracting: val_labels/image_0004.txt  \n",
            " extracting: val_labels/image_0017.txt  \n",
            " extracting: val_labels/image_0005.txt  \n",
            " extracting: val_labels/image_0002.txt  \n",
            " extracting: val_labels/image_0036.txt  \n",
            " extracting: val_labels/image_0025.txt  \n",
            " extracting: val_labels/image_0062.txt  \n",
            " extracting: val_labels/image_0072.txt  \n",
            " extracting: val_labels/image_0047.txt  \n",
            " extracting: val_labels/image_0065.txt  \n",
            " extracting: val_labels/image_0033.txt  \n",
            " extracting: val_labels/image_0064.txt  \n",
            " extracting: val_labels/image_0060.txt  \n",
            " extracting: val_labels/image_0051.txt  \n",
            " extracting: val_labels/image_0092.txt  \n",
            " extracting: val_labels/image_0074.txt  \n",
            " extracting: val_labels/image_0037.txt  \n",
            " extracting: val_labels/image_0054.txt  \n",
            " extracting: val_labels/image_0091.txt  \n",
            " extracting: val_labels/image_0040.txt  \n",
            " extracting: val_labels/image_0057.txt  \n",
            " extracting: val_labels/image_0087.txt  \n",
            " extracting: val_labels/image_0090.txt  \n",
            " extracting: val_labels/image_0061.txt  \n",
            " extracting: val_labels/image_0071.txt  \n",
            " extracting: val_labels/image_0030.txt  \n",
            " extracting: val_labels/image_0088.txt  \n",
            " extracting: val_labels/image_0027.txt  \n",
            " extracting: val_labels/image_0046.txt  \n",
            " extracting: val_labels/image_0089.txt  \n",
            " extracting: val_labels/image_0086.txt  \n",
            " extracting: val_labels/image_0038.txt  \n",
            " extracting: val_labels/image_0032.txt  \n",
            " extracting: val_labels/image_0093.txt  \n",
            " extracting: val_labels/image_0083.txt  \n",
            " extracting: val_labels/image_0084.txt  \n",
            " extracting: val_labels/image_0080.txt  \n",
            " extracting: val_labels/image_0039.txt  \n",
            " extracting: val_labels/image_0022.txt  \n",
            " extracting: val_labels/image_0055.txt  \n",
            " extracting: val_labels/image_0058.txt  \n",
            " extracting: val_labels/image_0048.txt  \n",
            " extracting: val_labels/image_0075.txt  \n",
            " extracting: val_labels/image_0073.txt  \n",
            " extracting: val_labels/image_0079.txt  \n",
            " extracting: val_labels/image_0045.txt  \n",
            " extracting: val_labels/image_0050.txt  \n",
            " extracting: val_labels/image_0021.txt  \n",
            " extracting: val_labels/image_0035.txt  \n",
            " extracting: val_labels/image_0052.txt  \n",
            " extracting: val_labels/image_0076.txt  \n",
            " extracting: val_labels/image_0078.txt  \n",
            " extracting: val_labels/image_0082.txt  \n",
            " extracting: val_labels/image_0081.txt  \n",
            " extracting: val_labels/image_0068.txt  \n",
            " extracting: val_labels/image_0034.txt  \n",
            " extracting: val_labels/image_0069.txt  \n",
            " extracting: val_labels/image_0067.txt  \n",
            " extracting: val_labels/image_0023.txt  \n",
            " extracting: val_labels/image_0042.txt  \n",
            " extracting: val_labels/image_0044.txt  \n",
            " extracting: val_labels/image_0085.txt  \n",
            " extracting: val_labels/image_0063.txt  \n",
            " extracting: val_labels/image_0024.txt  \n",
            " extracting: val_labels/image_0070.txt  \n",
            " extracting: val_labels/image_0059.txt  \n",
            " extracting: val_labels/image_0066.txt  \n",
            " extracting: val_labels/image_0029.txt  \n",
            " extracting: val_labels/image_0041.txt  \n",
            " extracting: val_labels/image_0056.txt  \n",
            " extracting: val_labels/image_0026.txt  \n",
            " extracting: val_labels/image_0094.txt  \n",
            " extracting: val_labels/image_0028.txt  \n",
            " extracting: val_labels/image_0043.txt  \n",
            " extracting: val_labels/image_0031.txt  \n",
            " extracting: val_labels/image_0049.txt  \n",
            " extracting: val_labels/image_0053.txt  \n",
            " extracting: val_labels/image_0077.txt  \n",
            " extracting: val_labels/image_0170.txt  \n",
            " extracting: val_labels/image_0161.txt  \n",
            " extracting: val_labels/image_0155.txt  \n",
            " extracting: val_labels/image_0107.txt  \n",
            " extracting: val_labels/image_0099.txt  \n",
            " extracting: val_labels/image_0123.txt  \n",
            " extracting: val_labels/image_0154.txt  \n",
            " extracting: val_labels/image_0153.txt  \n",
            " extracting: val_labels/image_0149.txt  \n",
            " extracting: val_labels/image_0138.txt  \n",
            " extracting: val_labels/image_0136.txt  \n",
            " extracting: val_labels/image_0129.txt  \n",
            " extracting: val_labels/image_0117.txt  \n",
            " extracting: val_labels/image_0103.txt  \n",
            " extracting: val_labels/image_0164.txt  \n",
            " extracting: val_labels/image_0169.txt  \n",
            " extracting: val_labels/image_0143.txt  \n",
            " extracting: val_labels/image_0112.txt  \n",
            " extracting: val_labels/image_0160.txt  \n",
            " extracting: val_labels/image_0166.txt  \n",
            " extracting: val_labels/image_0114.txt  \n",
            " extracting: val_labels/image_0120.txt  \n",
            " extracting: val_labels/image_0165.txt  \n",
            " extracting: val_labels/image_0157.txt  \n",
            " extracting: val_labels/image_0124.txt  \n",
            " extracting: val_labels/image_0097.txt  \n",
            " extracting: val_labels/image_0104.txt  \n",
            " extracting: val_labels/image_0133.txt  \n",
            " extracting: val_labels/image_0105.txt  \n",
            " extracting: val_labels/image_0139.txt  \n",
            " extracting: val_labels/image_0159.txt  \n",
            " extracting: val_labels/image_0162.txt  \n",
            " extracting: val_labels/image_0131.txt  \n",
            " extracting: val_labels/image_0115.txt  \n",
            " extracting: val_labels/image_0125.txt  \n",
            " extracting: val_labels/image_0119.txt  \n",
            " extracting: val_labels/image_0151.txt  \n",
            " extracting: val_labels/image_0158.txt  \n",
            " extracting: val_labels/image_0095.txt  \n",
            " extracting: val_labels/image_0108.txt  \n",
            " extracting: val_labels/image_0135.txt  \n",
            " extracting: val_labels/image_0116.txt  \n",
            " extracting: val_labels/image_0141.txt  \n",
            " extracting: val_labels/image_0132.txt  \n",
            " extracting: val_labels/image_0101.txt  \n",
            " extracting: val_labels/image_0100.txt  \n",
            " extracting: val_labels/image_0127.txt  \n",
            " extracting: val_labels/image_0118.txt  \n",
            " extracting: val_labels/image_0121.txt  \n",
            " extracting: val_labels/image_0142.txt  \n",
            " extracting: val_labels/image_0134.txt  \n",
            " extracting: val_labels/image_0144.txt  \n",
            " extracting: val_labels/image_0145.txt  \n",
            " extracting: val_labels/image_0167.txt  \n",
            " extracting: val_labels/image_0113.txt  \n",
            " extracting: val_labels/image_0098.txt  \n",
            " extracting: val_labels/image_0137.txt  \n",
            " extracting: val_labels/image_0126.txt  \n",
            " extracting: val_labels/image_0152.txt  \n",
            " extracting: val_labels/image_0140.txt  \n",
            " extracting: val_labels/image_0148.txt  \n",
            " extracting: val_labels/image_0122.txt  \n",
            " extracting: val_labels/image_0111.txt  \n",
            " extracting: val_labels/image_0163.txt  \n",
            " extracting: val_labels/image_0147.txt  \n",
            " extracting: val_labels/image_0109.txt  \n",
            " extracting: val_labels/image_0146.txt  \n",
            " extracting: val_labels/image_0130.txt  \n",
            " extracting: val_labels/image_0150.txt  \n",
            " extracting: val_labels/image_0156.txt  \n",
            " extracting: val_labels/image_0168.txt  \n",
            " extracting: val_labels/image_0128.txt  \n",
            " extracting: val_labels/image_0106.txt  \n",
            " extracting: val_labels/image_0102.txt  \n",
            " extracting: val_labels/image_0096.txt  \n",
            " extracting: val_labels/image_0110.txt  \n",
            " extracting: val_labels/image_0224.txt  \n",
            " extracting: val_labels/image_0212.txt  \n",
            " extracting: val_labels/image_0219.txt  \n",
            " extracting: val_labels/image_0216.txt  \n",
            " extracting: val_labels/image_0201.txt  \n",
            " extracting: val_labels/image_0182.txt  \n",
            " extracting: val_labels/image_0243.txt  \n",
            " extracting: val_labels/image_0200.txt  \n",
            " extracting: val_labels/image_0181.txt  \n",
            " extracting: val_labels/image_0197.txt  \n",
            " extracting: val_labels/image_0204.txt  \n",
            " extracting: val_labels/image_0215.txt  \n",
            " extracting: val_labels/image_0217.txt  \n",
            " extracting: val_labels/image_0187.txt  \n",
            " extracting: val_labels/image_0227.txt  \n",
            " extracting: val_labels/image_0173.txt  \n",
            " extracting: val_labels/image_0245.txt  \n",
            " extracting: val_labels/image_0225.txt  \n",
            " extracting: val_labels/image_0180.txt  \n",
            " extracting: val_labels/image_0192.txt  \n",
            " extracting: val_labels/image_0244.txt  \n",
            " extracting: val_labels/image_0196.txt  \n",
            " extracting: val_labels/image_0179.txt  \n",
            " extracting: val_labels/image_0230.txt  \n",
            " extracting: val_labels/image_0242.txt  \n",
            " extracting: val_labels/image_0184.txt  \n",
            " extracting: val_labels/image_0175.txt  \n",
            " extracting: val_labels/image_0235.txt  \n",
            " extracting: val_labels/image_0205.txt  \n",
            " extracting: val_labels/image_0248.txt  \n",
            " extracting: val_labels/image_0195.txt  \n",
            " extracting: val_labels/image_0220.txt  \n",
            " extracting: val_labels/image_0209.txt  \n",
            " extracting: val_labels/image_0194.txt  \n",
            " extracting: val_labels/image_0202.txt  \n",
            " extracting: val_labels/image_0232.txt  \n",
            " extracting: val_labels/image_0189.txt  \n",
            " extracting: val_labels/image_0190.txt  \n",
            " extracting: val_labels/image_0178.txt  \n",
            " extracting: val_labels/image_0185.txt  \n",
            " extracting: val_labels/image_0207.txt  \n",
            " extracting: val_labels/image_0233.txt  \n",
            " extracting: val_labels/image_0218.txt  \n",
            " extracting: val_labels/image_0241.txt  \n",
            " extracting: val_labels/image_0171.txt  \n",
            " extracting: val_labels/image_0172.txt  \n",
            " extracting: val_labels/image_0193.txt  \n",
            " extracting: val_labels/image_0234.txt  \n",
            " extracting: val_labels/image_0237.txt  \n",
            " extracting: val_labels/image_0199.txt  \n",
            " extracting: val_labels/image_0240.txt  \n",
            " extracting: val_labels/image_0222.txt  \n",
            " extracting: val_labels/image_0206.txt  \n",
            " extracting: val_labels/image_0231.txt  \n",
            " extracting: val_labels/image_0203.txt  \n",
            " extracting: val_labels/image_0236.txt  \n",
            " extracting: val_labels/image_0183.txt  \n",
            " extracting: val_labels/image_0186.txt  \n",
            " extracting: val_labels/image_0176.txt  \n",
            " extracting: val_labels/image_0191.txt  \n",
            " extracting: val_labels/image_0210.txt  \n",
            " extracting: val_labels/image_0221.txt  \n",
            " extracting: val_labels/image_0208.txt  \n",
            " extracting: val_labels/image_0177.txt  \n",
            " extracting: val_labels/image_0198.txt  \n",
            " extracting: val_labels/image_0174.txt  \n",
            " extracting: val_labels/image_0226.txt  \n",
            " extracting: val_labels/image_0239.txt  \n",
            " extracting: val_labels/image_0223.txt  \n",
            " extracting: val_labels/image_0228.txt  \n",
            " extracting: val_labels/image_0213.txt  \n",
            " extracting: val_labels/image_0238.txt  \n",
            " extracting: val_labels/image_0188.txt  \n",
            " extracting: val_labels/image_0214.txt  \n",
            " extracting: val_labels/image_0247.txt  \n",
            " extracting: val_labels/image_0229.txt  \n",
            " extracting: val_labels/image_0211.txt  \n",
            " extracting: val_labels/image_0246.txt  \n",
            " extracting: val_labels/image_0251.txt  \n",
            " extracting: val_labels/image_0305.txt  \n",
            " extracting: val_labels/image_0285.txt  \n",
            " extracting: val_labels/image_0304.txt  \n",
            " extracting: val_labels/image_0302.txt  \n",
            " extracting: val_labels/image_0256.txt  \n",
            " extracting: val_labels/image_0295.txt  \n",
            " extracting: val_labels/image_0312.txt  \n",
            " extracting: val_labels/image_0278.txt  \n",
            " extracting: val_labels/image_0319.txt  \n",
            " extracting: val_labels/image_0306.txt  \n",
            " extracting: val_labels/image_0258.txt  \n",
            " extracting: val_labels/image_0269.txt  \n",
            " extracting: val_labels/image_0296.txt  \n",
            " extracting: val_labels/image_0299.txt  \n",
            " extracting: val_labels/image_0283.txt  \n",
            " extracting: val_labels/image_0308.txt  \n",
            " extracting: val_labels/image_0249.txt  \n",
            " extracting: val_labels/image_0310.txt  \n",
            " extracting: val_labels/image_0264.txt  \n",
            " extracting: val_labels/image_0272.txt  \n",
            " extracting: val_labels/image_0265.txt  \n",
            " extracting: val_labels/image_0315.txt  \n",
            " extracting: val_labels/image_0326.txt  \n",
            " extracting: val_labels/image_0259.txt  \n",
            " extracting: val_labels/image_0250.txt  \n",
            " extracting: val_labels/image_0317.txt  \n",
            " extracting: val_labels/image_0324.txt  \n",
            " extracting: val_labels/image_0316.txt  \n",
            " extracting: val_labels/image_0286.txt  \n",
            " extracting: val_labels/image_0253.txt  \n",
            " extracting: val_labels/image_0284.txt  \n",
            " extracting: val_labels/image_0277.txt  \n",
            " extracting: val_labels/image_0309.txt  \n",
            " extracting: val_labels/image_0314.txt  \n",
            " extracting: val_labels/image_0311.txt  \n",
            " extracting: val_labels/image_0252.txt  \n",
            " extracting: val_labels/image_0254.txt  \n",
            " extracting: val_labels/image_0262.txt  \n",
            " extracting: val_labels/image_0297.txt  \n",
            " extracting: val_labels/image_0323.txt  \n",
            " extracting: val_labels/image_0260.txt  \n",
            " extracting: val_labels/image_0282.txt  \n",
            " extracting: val_labels/image_0298.txt  \n",
            " extracting: val_labels/image_0321.txt  \n",
            " extracting: val_labels/image_0291.txt  \n",
            " extracting: val_labels/image_0318.txt  \n",
            " extracting: val_labels/image_0266.txt  \n",
            " extracting: val_labels/image_0271.txt  \n",
            " extracting: val_labels/image_0289.txt  \n",
            " extracting: val_labels/image_0274.txt  \n",
            " extracting: val_labels/image_0303.txt  \n",
            " extracting: val_labels/image_0322.txt  \n",
            " extracting: val_labels/image_0270.txt  \n",
            " extracting: val_labels/image_0255.txt  \n",
            " extracting: val_labels/image_0279.txt  \n",
            " extracting: val_labels/image_0275.txt  \n",
            " extracting: val_labels/image_0268.txt  \n",
            " extracting: val_labels/image_0280.txt  \n",
            " extracting: val_labels/image_0267.txt  \n",
            " extracting: val_labels/image_0320.txt  \n",
            " extracting: val_labels/image_0257.txt  \n",
            " extracting: val_labels/image_0287.txt  \n",
            " extracting: val_labels/image_0325.txt  \n",
            " extracting: val_labels/image_0292.txt  \n",
            " extracting: val_labels/image_0261.txt  \n",
            " extracting: val_labels/image_0293.txt  \n",
            " extracting: val_labels/image_0290.txt  \n",
            " extracting: val_labels/image_0273.txt  \n",
            " extracting: val_labels/image_0288.txt  \n",
            " extracting: val_labels/image_0276.txt  \n",
            " extracting: val_labels/image_0307.txt  \n",
            " extracting: val_labels/image_0313.txt  \n",
            " extracting: val_labels/image_0294.txt  \n",
            " extracting: val_labels/image_0300.txt  \n",
            " extracting: val_labels/image_0263.txt  \n",
            " extracting: val_labels/image_0281.txt  \n",
            " extracting: val_labels/image_0301.txt  \n",
            " extracting: val_labels/image_0376.txt  \n",
            " extracting: val_labels/image_0345.txt  \n",
            " extracting: val_labels/image_0379.txt  \n",
            " extracting: val_labels/image_0392.txt  \n",
            " extracting: val_labels/image_0371.txt  \n",
            " extracting: val_labels/image_0329.txt  \n",
            " extracting: val_labels/image_0365.txt  \n",
            " extracting: val_labels/image_0369.txt  \n",
            " extracting: val_labels/image_0359.txt  \n",
            " extracting: val_labels/image_0367.txt  \n",
            " extracting: val_labels/image_0333.txt  \n",
            " extracting: val_labels/image_0332.txt  \n",
            " extracting: val_labels/image_0363.txt  \n",
            " extracting: val_labels/image_0331.txt  \n",
            " extracting: val_labels/image_0357.txt  \n",
            " extracting: val_labels/image_0384.txt  \n",
            " extracting: val_labels/image_0398.txt  \n",
            " extracting: val_labels/image_0342.txt  \n",
            " extracting: val_labels/image_0381.txt  \n",
            " extracting: val_labels/image_0339.txt  \n",
            " extracting: val_labels/image_0338.txt  \n",
            " extracting: val_labels/image_0377.txt  \n",
            " extracting: val_labels/image_0391.txt  \n",
            " extracting: val_labels/image_0401.txt  \n",
            " extracting: val_labels/image_0404.txt  \n",
            " extracting: val_labels/image_0388.txt  \n",
            " extracting: val_labels/image_0403.txt  \n",
            " extracting: val_labels/image_0358.txt  \n",
            " extracting: val_labels/image_0340.txt  \n",
            " extracting: val_labels/image_0337.txt  \n",
            " extracting: val_labels/image_0393.txt  \n",
            " extracting: val_labels/image_0372.txt  \n",
            " extracting: val_labels/image_0394.txt  \n",
            " extracting: val_labels/image_0390.txt  \n",
            " extracting: val_labels/image_0353.txt  \n",
            " extracting: val_labels/image_0368.txt  \n",
            " extracting: val_labels/image_0373.txt  \n",
            " extracting: val_labels/image_0389.txt  \n",
            " extracting: val_labels/image_0327.txt  \n",
            " extracting: val_labels/image_0361.txt  \n",
            " extracting: val_labels/image_0386.txt  \n",
            " extracting: val_labels/image_0383.txt  \n",
            " extracting: val_labels/image_0375.txt  \n",
            " extracting: val_labels/image_0330.txt  \n",
            " extracting: val_labels/image_0352.txt  \n",
            " extracting: val_labels/image_0374.txt  \n",
            " extracting: val_labels/image_0341.txt  \n",
            " extracting: val_labels/image_0336.txt  \n",
            " extracting: val_labels/image_0334.txt  \n",
            " extracting: val_labels/image_0350.txt  \n",
            " extracting: val_labels/image_0355.txt  \n",
            " extracting: val_labels/image_0402.txt  \n",
            " extracting: val_labels/image_0385.txt  \n",
            " extracting: val_labels/image_0344.txt  \n",
            " extracting: val_labels/image_0346.txt  \n",
            " extracting: val_labels/image_0395.txt  \n",
            " extracting: val_labels/image_0354.txt  \n",
            " extracting: val_labels/image_0343.txt  \n",
            " extracting: val_labels/image_0328.txt  \n",
            " extracting: val_labels/image_0335.txt  \n",
            " extracting: val_labels/image_0364.txt  \n",
            " extracting: val_labels/image_0378.txt  \n",
            " extracting: val_labels/image_0382.txt  \n",
            " extracting: val_labels/image_0380.txt  \n",
            " extracting: val_labels/image_0348.txt  \n",
            " extracting: val_labels/image_0387.txt  \n",
            " extracting: val_labels/image_0370.txt  \n",
            " extracting: val_labels/image_0397.txt  \n",
            " extracting: val_labels/image_0351.txt  \n",
            " extracting: val_labels/image_0356.txt  \n",
            " extracting: val_labels/image_0399.txt  \n",
            " extracting: val_labels/image_0347.txt  \n",
            " extracting: val_labels/image_0366.txt  \n",
            " extracting: val_labels/image_0400.txt  \n",
            " extracting: val_labels/image_0362.txt  \n",
            " extracting: val_labels/image_0396.txt  \n",
            " extracting: val_labels/image_0349.txt  \n",
            " extracting: val_labels/image_0360.txt  \n",
            " extracting: val_labels/image_0438.txt  \n",
            " extracting: val_labels/image_0419.txt  \n",
            " extracting: val_labels/image_0458.txt  \n",
            " extracting: val_labels/image_0447.txt  \n",
            " extracting: val_labels/image_0407.txt  \n",
            " extracting: val_labels/image_0467.txt  \n",
            " extracting: val_labels/image_0413.txt  \n",
            " extracting: val_labels/image_0454.txt  \n",
            " extracting: val_labels/image_0473.txt  \n",
            " extracting: val_labels/image_0468.txt  \n",
            " extracting: val_labels/image_0420.txt  \n",
            " extracting: val_labels/image_0425.txt  \n",
            " extracting: val_labels/image_0433.txt  \n",
            " extracting: val_labels/image_0437.txt  \n",
            " extracting: val_labels/image_0457.txt  \n",
            " extracting: val_labels/image_0470.txt  \n",
            " extracting: val_labels/image_0462.txt  \n",
            " extracting: val_labels/image_0449.txt  \n",
            " extracting: val_labels/image_0426.txt  \n",
            " extracting: val_labels/image_0450.txt  \n",
            " extracting: val_labels/image_0463.txt  \n",
            " extracting: val_labels/image_0460.txt  \n",
            " extracting: val_labels/image_0432.txt  \n",
            " extracting: val_labels/image_0414.txt  \n",
            " extracting: val_labels/image_0459.txt  \n",
            " extracting: val_labels/image_0442.txt  \n",
            " extracting: val_labels/image_0428.txt  \n",
            " extracting: val_labels/image_0408.txt  \n",
            " extracting: val_labels/image_0430.txt  \n",
            " extracting: val_labels/image_0451.txt  \n",
            " extracting: val_labels/image_0472.txt  \n",
            " extracting: val_labels/image_0441.txt  \n",
            " extracting: val_labels/image_0412.txt  \n",
            " extracting: val_labels/image_0465.txt  \n",
            " extracting: val_labels/image_0417.txt  \n",
            " extracting: val_labels/image_0435.txt  \n",
            " extracting: val_labels/image_0456.txt  \n",
            " extracting: val_labels/image_0448.txt  \n",
            " extracting: val_labels/image_0416.txt  \n",
            " extracting: val_labels/image_0431.txt  \n",
            " extracting: val_labels/image_0427.txt  \n",
            " extracting: val_labels/image_0421.txt  \n",
            " extracting: val_labels/image_0418.txt  \n",
            " extracting: val_labels/image_0429.txt  \n",
            " extracting: val_labels/image_0444.txt  \n",
            " extracting: val_labels/image_0436.txt  \n",
            " extracting: val_labels/image_0443.txt  \n",
            " extracting: val_labels/image_0422.txt  \n",
            " extracting: val_labels/image_0439.txt  \n",
            " extracting: val_labels/image_0446.txt  \n",
            " extracting: val_labels/image_0424.txt  \n",
            " extracting: val_labels/image_0434.txt  \n",
            " extracting: val_labels/image_0406.txt  \n",
            " extracting: val_labels/image_0445.txt  \n",
            " extracting: val_labels/image_0415.txt  \n",
            " extracting: val_labels/image_0440.txt  \n",
            " extracting: val_labels/image_0471.txt  \n",
            " extracting: val_labels/image_0405.txt  \n",
            " extracting: val_labels/image_0409.txt  \n",
            " extracting: val_labels/image_0461.txt  \n",
            " extracting: val_labels/image_0464.txt  \n",
            " extracting: val_labels/image_0423.txt  \n",
            " extracting: val_labels/image_0466.txt  \n",
            " extracting: val_labels/image_0411.txt  \n",
            " extracting: val_labels/image_0453.txt  \n",
            " extracting: val_labels/image_0455.txt  \n",
            " extracting: val_labels/image_0469.txt  \n",
            " extracting: val_labels/image_0452.txt  \n",
            " extracting: val_labels/image_0410.txt  \n",
            " extracting: val_labels/image_0511.txt  \n",
            " extracting: val_labels/image_0488.txt  \n",
            " extracting: val_labels/image_0500.txt  \n",
            " extracting: val_labels/image_0502.txt  \n",
            " extracting: val_labels/image_0483.txt  \n",
            " extracting: val_labels/image_0485.txt  \n",
            " extracting: val_labels/image_0496.txt  \n",
            " extracting: val_labels/image_0544.txt  \n",
            " extracting: val_labels/image_0494.txt  \n",
            " extracting: val_labels/image_0514.txt  \n",
            " extracting: val_labels/image_0507.txt  \n",
            " extracting: val_labels/image_0504.txt  \n",
            " extracting: val_labels/image_0477.txt  \n",
            " extracting: val_labels/image_0495.txt  \n",
            " extracting: val_labels/image_0520.txt  \n",
            " extracting: val_labels/image_0484.txt  \n",
            " extracting: val_labels/image_0475.txt  \n",
            " extracting: val_labels/image_0493.txt  \n",
            " extracting: val_labels/image_0492.txt  \n",
            " extracting: val_labels/image_0474.txt  \n",
            " extracting: val_labels/image_0509.txt  \n",
            " extracting: val_labels/image_0489.txt  \n",
            " extracting: val_labels/image_0491.txt  \n",
            " extracting: val_labels/image_0476.txt  \n",
            " extracting: val_labels/image_0542.txt  \n",
            " extracting: val_labels/image_0479.txt  \n",
            " extracting: val_labels/image_0490.txt  \n",
            " extracting: val_labels/image_0518.txt  \n",
            " extracting: val_labels/image_0548.txt  \n",
            " extracting: val_labels/image_0538.txt  \n",
            " extracting: val_labels/image_0532.txt  \n",
            " extracting: val_labels/image_0543.txt  \n",
            " extracting: val_labels/image_0536.txt  \n",
            " extracting: val_labels/image_0513.txt  \n",
            " extracting: val_labels/image_0522.txt  \n",
            " extracting: val_labels/image_0481.txt  \n",
            " extracting: val_labels/image_0498.txt  \n",
            " extracting: val_labels/image_0525.txt  \n",
            " extracting: val_labels/image_0529.txt  \n",
            " extracting: val_labels/image_0545.txt  \n",
            " extracting: val_labels/image_0499.txt  \n",
            " extracting: val_labels/image_0546.txt  \n",
            " extracting: val_labels/image_0524.txt  \n",
            " extracting: val_labels/image_0528.txt  \n",
            " extracting: val_labels/image_0519.txt  \n",
            " extracting: val_labels/image_0530.txt  \n",
            " extracting: val_labels/image_0526.txt  \n",
            " extracting: val_labels/image_0537.txt  \n",
            " extracting: val_labels/image_0478.txt  \n",
            " extracting: val_labels/image_0487.txt  \n",
            " extracting: val_labels/image_0480.txt  \n",
            " extracting: val_labels/image_0549.txt  \n",
            " extracting: val_labels/image_0527.txt  \n",
            " extracting: val_labels/image_0547.txt  \n",
            " extracting: val_labels/image_0515.txt  \n",
            " extracting: val_labels/image_0539.txt  \n",
            " extracting: val_labels/image_0521.txt  \n",
            " extracting: val_labels/image_0503.txt  \n",
            " extracting: val_labels/image_0550.txt  \n",
            " extracting: val_labels/image_0517.txt  \n",
            " extracting: val_labels/image_0505.txt  \n",
            " extracting: val_labels/image_0508.txt  \n",
            " extracting: val_labels/image_0482.txt  \n",
            " extracting: val_labels/image_0501.txt  \n",
            " extracting: val_labels/image_0541.txt  \n",
            " extracting: val_labels/image_0506.txt  \n",
            " extracting: val_labels/image_0531.txt  \n",
            " extracting: val_labels/image_0510.txt  \n",
            " extracting: val_labels/image_0486.txt  \n",
            " extracting: val_labels/image_0540.txt  \n",
            " extracting: val_labels/image_0535.txt  \n",
            " extracting: val_labels/image_0512.txt  \n",
            " extracting: val_labels/image_0534.txt  \n",
            " extracting: val_labels/image_0497.txt  \n",
            " extracting: val_labels/image_0516.txt  \n",
            " extracting: val_labels/image_0523.txt  \n",
            " extracting: val_labels/image_0533.txt  \n",
            " extracting: val_labels/image_0556.txt  \n",
            " extracting: val_labels/image_0599.txt  \n",
            " extracting: val_labels/image_0597.txt  \n",
            " extracting: val_labels/image_0555.txt  \n",
            " extracting: val_labels/image_0570.txt  \n",
            " extracting: val_labels/image_0595.txt  \n",
            " extracting: val_labels/image_0571.txt  \n",
            " extracting: val_labels/image_0557.txt  \n",
            " extracting: val_labels/image_0575.txt  \n",
            " extracting: val_labels/image_0567.txt  \n",
            " extracting: val_labels/image_0620.txt  \n",
            " extracting: val_labels/image_0581.txt  \n",
            " extracting: val_labels/image_0592.txt  \n",
            " extracting: val_labels/image_0606.txt  \n",
            " extracting: val_labels/image_0586.txt  \n",
            " extracting: val_labels/image_0576.txt  \n",
            " extracting: val_labels/image_0568.txt  \n",
            " extracting: val_labels/image_0578.txt  \n",
            " extracting: val_labels/image_0552.txt  \n",
            " extracting: val_labels/image_0577.txt  \n",
            " extracting: val_labels/image_0614.txt  \n",
            " extracting: val_labels/image_0609.txt  \n",
            " extracting: val_labels/image_0612.txt  \n",
            " extracting: val_labels/image_0605.txt  \n",
            " extracting: val_labels/image_0590.txt  \n",
            " extracting: val_labels/image_0593.txt  \n",
            " extracting: val_labels/image_0608.txt  \n",
            " extracting: val_labels/image_0618.txt  \n",
            " extracting: val_labels/image_0607.txt  \n",
            " extracting: val_labels/image_0625.txt  \n",
            " extracting: val_labels/image_0554.txt  \n",
            " extracting: val_labels/image_0603.txt  \n",
            " extracting: val_labels/image_0624.txt  \n",
            " extracting: val_labels/image_0558.txt  \n",
            " extracting: val_labels/image_0584.txt  \n",
            " extracting: val_labels/image_0560.txt  \n",
            " extracting: val_labels/image_0623.txt  \n",
            " extracting: val_labels/image_0565.txt  \n",
            " extracting: val_labels/image_0619.txt  \n",
            " extracting: val_labels/image_0627.txt  \n",
            " extracting: val_labels/image_0594.txt  \n",
            " extracting: val_labels/image_0563.txt  \n",
            " extracting: val_labels/image_0583.txt  \n",
            " extracting: val_labels/image_0564.txt  \n",
            " extracting: val_labels/image_0589.txt  \n",
            " extracting: val_labels/image_0617.txt  \n",
            " extracting: val_labels/image_0585.txt  \n",
            " extracting: val_labels/image_0602.txt  \n",
            " extracting: val_labels/image_0580.txt  \n",
            " extracting: val_labels/image_0610.txt  \n",
            " extracting: val_labels/image_0553.txt  \n",
            " extracting: val_labels/image_0562.txt  \n",
            " extracting: val_labels/image_0572.txt  \n",
            " extracting: val_labels/image_0626.txt  \n",
            " extracting: val_labels/image_0621.txt  \n",
            " extracting: val_labels/image_0600.txt  \n",
            " extracting: val_labels/image_0604.txt  \n",
            " extracting: val_labels/image_0591.txt  \n",
            " extracting: val_labels/image_0596.txt  \n",
            " extracting: val_labels/image_0622.txt  \n",
            " extracting: val_labels/image_0588.txt  \n",
            " extracting: val_labels/image_0629.txt  \n",
            " extracting: val_labels/image_0566.txt  \n",
            " extracting: val_labels/image_0615.txt  \n",
            " extracting: val_labels/image_0582.txt  \n",
            " extracting: val_labels/image_0613.txt  \n",
            " extracting: val_labels/image_0587.txt  \n",
            " extracting: val_labels/image_0574.txt  \n",
            " extracting: val_labels/image_0598.txt  \n",
            " extracting: val_labels/image_0551.txt  \n",
            " extracting: val_labels/image_0611.txt  \n",
            " extracting: val_labels/image_0559.txt  \n",
            " extracting: val_labels/image_0616.txt  \n",
            " extracting: val_labels/image_0573.txt  \n",
            " extracting: val_labels/image_0561.txt  \n",
            " extracting: val_labels/image_0628.txt  \n",
            " extracting: val_labels/image_0569.txt  \n",
            " extracting: val_labels/image_0601.txt  \n",
            " extracting: val_labels/image_0579.txt  \n",
            " extracting: val_labels/image_0683.txt  \n",
            " extracting: val_labels/image_0705.txt  \n",
            " extracting: val_labels/image_0692.txt  \n",
            " extracting: val_labels/image_0685.txt  \n",
            " extracting: val_labels/image_0673.txt  \n",
            " extracting: val_labels/image_0701.txt  \n",
            " extracting: val_labels/image_0634.txt  \n",
            " extracting: val_labels/image_0637.txt  \n",
            " extracting: val_labels/image_0635.txt  \n",
            " extracting: val_labels/image_0682.txt  \n",
            " extracting: val_labels/image_0645.txt  \n",
            " extracting: val_labels/image_0651.txt  \n",
            " extracting: val_labels/image_0664.txt  \n",
            " extracting: val_labels/image_0691.txt  \n",
            " extracting: val_labels/image_0660.txt  \n",
            " extracting: val_labels/image_0648.txt  \n",
            " extracting: val_labels/image_0704.txt  \n",
            " extracting: val_labels/image_0702.txt  \n",
            " extracting: val_labels/image_0696.txt  \n",
            " extracting: val_labels/image_0680.txt  \n",
            " extracting: val_labels/image_0686.txt  \n",
            " extracting: val_labels/image_0641.txt  \n",
            " extracting: val_labels/image_0699.txt  \n",
            " extracting: val_labels/image_0655.txt  \n",
            " extracting: val_labels/image_0706.txt  \n",
            " extracting: val_labels/image_0639.txt  \n",
            " extracting: val_labels/image_0650.txt  \n",
            " extracting: val_labels/image_0688.txt  \n",
            " extracting: val_labels/image_0677.txt  \n",
            " extracting: val_labels/image_0662.txt  \n",
            " extracting: val_labels/image_0698.txt  \n",
            " extracting: val_labels/image_0666.txt  \n",
            " extracting: val_labels/image_0636.txt  \n",
            " extracting: val_labels/image_0707.txt  \n",
            " extracting: val_labels/image_0703.txt  \n",
            " extracting: val_labels/image_0690.txt  \n",
            " extracting: val_labels/image_0633.txt  \n",
            " extracting: val_labels/image_0681.txt  \n",
            " extracting: val_labels/image_0652.txt  \n",
            " extracting: val_labels/image_0671.txt  \n",
            " extracting: val_labels/image_0679.txt  \n",
            " extracting: val_labels/image_0638.txt  \n",
            " extracting: val_labels/image_0687.txt  \n",
            " extracting: val_labels/image_0668.txt  \n",
            " extracting: val_labels/image_0676.txt  \n",
            " extracting: val_labels/image_0665.txt  \n",
            " extracting: val_labels/image_0631.txt  \n",
            " extracting: val_labels/image_0647.txt  \n",
            " extracting: val_labels/image_0695.txt  \n",
            " extracting: val_labels/image_0630.txt  \n",
            " extracting: val_labels/image_0678.txt  \n",
            " extracting: val_labels/image_0653.txt  \n",
            " extracting: val_labels/image_0643.txt  \n",
            " extracting: val_labels/image_0674.txt  \n",
            " extracting: val_labels/image_0646.txt  \n",
            " extracting: val_labels/image_0649.txt  \n",
            " extracting: val_labels/image_0689.txt  \n",
            " extracting: val_labels/image_0667.txt  \n",
            " extracting: val_labels/image_0642.txt  \n",
            " extracting: val_labels/image_0659.txt  \n",
            " extracting: val_labels/image_0693.txt  \n",
            " extracting: val_labels/image_0644.txt  \n",
            " extracting: val_labels/image_0672.txt  \n",
            " extracting: val_labels/image_0694.txt  \n",
            " extracting: val_labels/image_0658.txt  \n",
            " extracting: val_labels/image_0654.txt  \n",
            " extracting: val_labels/image_0670.txt  \n",
            " extracting: val_labels/image_0675.txt  \n",
            " extracting: val_labels/image_0669.txt  \n",
            " extracting: val_labels/image_0697.txt  \n",
            " extracting: val_labels/image_0684.txt  \n",
            " extracting: val_labels/image_0632.txt  \n",
            " extracting: val_labels/image_0656.txt  \n",
            " extracting: val_labels/image_0661.txt  \n",
            " extracting: val_labels/image_0640.txt  \n",
            " extracting: val_labels/image_0663.txt  \n",
            " extracting: val_labels/image_0700.txt  \n",
            " extracting: val_labels/image_0657.txt  \n",
            " extracting: val_labels/image_0708.txt  \n",
            " extracting: val_labels/image_0747.txt  \n",
            " extracting: val_labels/image_0761.txt  \n",
            " extracting: val_labels/image_0746.txt  \n",
            " extracting: val_labels/image_0737.txt  \n",
            " extracting: val_labels/image_0713.txt  \n",
            " extracting: val_labels/image_0745.txt  \n",
            " extracting: val_labels/image_0740.txt  \n",
            " extracting: val_labels/image_0717.txt  \n",
            " extracting: val_labels/image_0767.txt  \n",
            " extracting: val_labels/image_0777.txt  \n",
            " extracting: val_labels/image_0738.txt  \n",
            " extracting: val_labels/image_0753.txt  \n",
            " extracting: val_labels/image_0774.txt  \n",
            " extracting: val_labels/image_0748.txt  \n",
            " extracting: val_labels/image_0744.txt  \n",
            " extracting: val_labels/image_0709.txt  \n",
            " extracting: val_labels/image_0734.txt  \n",
            " extracting: val_labels/image_0778.txt  \n",
            " extracting: val_labels/image_0725.txt  \n",
            " extracting: val_labels/image_0731.txt  \n",
            " extracting: val_labels/image_0711.txt  \n",
            " extracting: val_labels/image_0733.txt  \n",
            " extracting: val_labels/image_0764.txt  \n",
            " extracting: val_labels/image_0770.txt  \n",
            " extracting: val_labels/image_0757.txt  \n",
            " extracting: val_labels/image_0719.txt  \n",
            " extracting: val_labels/image_0750.txt  \n",
            " extracting: val_labels/image_0763.txt  \n",
            " extracting: val_labels/image_0756.txt  \n",
            " extracting: val_labels/image_0739.txt  \n",
            " extracting: val_labels/image_0760.txt  \n",
            " extracting: val_labels/image_0751.txt  \n",
            " extracting: val_labels/image_0723.txt  \n",
            " extracting: val_labels/image_0749.txt  \n",
            " extracting: val_labels/image_0741.txt  \n",
            " extracting: val_labels/image_0726.txt  \n",
            " extracting: val_labels/image_0775.txt  \n",
            " extracting: val_labels/image_0735.txt  \n",
            " extracting: val_labels/image_0759.txt  \n",
            " extracting: val_labels/image_0776.txt  \n",
            " extracting: val_labels/image_0710.txt  \n",
            " extracting: val_labels/image_0755.txt  \n",
            " extracting: val_labels/image_0769.txt  \n",
            " extracting: val_labels/image_0712.txt  \n",
            " extracting: val_labels/image_0752.txt  \n",
            " extracting: val_labels/image_0765.txt  \n",
            " extracting: val_labels/image_0730.txt  \n",
            " extracting: val_labels/image_0736.txt  \n",
            " extracting: val_labels/image_0754.txt  \n",
            " extracting: val_labels/image_0771.txt  \n",
            " extracting: val_labels/image_0742.txt  \n",
            " extracting: val_labels/image_0780.txt  \n",
            " extracting: val_labels/image_0772.txt  \n",
            " extracting: val_labels/image_0779.txt  \n",
            " extracting: val_labels/image_0729.txt  \n",
            " extracting: val_labels/image_0718.txt  \n",
            " extracting: val_labels/image_0716.txt  \n",
            " extracting: val_labels/image_0721.txt  \n",
            " extracting: val_labels/image_0714.txt  \n",
            " extracting: val_labels/image_0720.txt  \n",
            " extracting: val_labels/image_0762.txt  \n",
            " extracting: val_labels/image_0743.txt  \n",
            " extracting: val_labels/image_0727.txt  \n",
            " extracting: val_labels/image_0722.txt  \n",
            " extracting: val_labels/image_0715.txt  \n",
            " extracting: val_labels/image_0766.txt  \n",
            " extracting: val_labels/image_0732.txt  \n",
            " extracting: val_labels/image_0724.txt  \n",
            " extracting: val_labels/image_0768.txt  \n",
            " extracting: val_labels/image_0773.txt  \n",
            " extracting: val_labels/image_0728.txt  \n",
            " extracting: val_labels/image_0758.txt  \n",
            " extracting: val_labels/image_0781.txt  \n",
            " extracting: val_labels/image_0796.txt  \n",
            " extracting: val_labels/image_0789.txt  \n",
            " extracting: val_labels/image_0797.txt  \n",
            " extracting: val_labels/image_0794.txt  \n",
            " extracting: val_labels/image_0792.txt  \n",
            " extracting: val_labels/image_0784.txt  \n",
            " extracting: val_labels/image_0790.txt  \n",
            " extracting: val_labels/image_0783.txt  \n",
            " extracting: val_labels/image_0788.txt  \n",
            " extracting: val_labels/image_0791.txt  \n",
            " extracting: val_labels/image_0798.txt  \n",
            " extracting: val_labels/image_0799.txt  \n",
            " extracting: val_labels/image_0786.txt  \n",
            " extracting: val_labels/image_0782.txt  \n",
            " extracting: val_labels/image_0793.txt  \n",
            " extracting: val_labels/image_0795.txt  \n",
            " extracting: val_labels/image_0787.txt  \n",
            " extracting: val_labels/image_0785.txt  \n",
            "Archive:  drive/MyDrive/Brainhack/Test.zip\n",
            " extracting: test_images/image_0612.png  \n",
            " extracting: test_images/image_0602.png  \n",
            " extracting: test_images/image_0658.png  \n",
            " extracting: test_images/image_0636.png  \n",
            " extracting: test_images/image_0582.png  \n",
            " extracting: test_images/image_0651.png  \n",
            " extracting: test_images/image_0623.png  \n",
            " extracting: test_images/image_0598.png  \n",
            " extracting: test_images/image_0647.png  \n",
            " extracting: test_images/image_0604.png  \n",
            " extracting: test_images/image_0631.png  \n",
            " extracting: test_images/image_0640.png  \n",
            " extracting: test_images/image_0597.png  \n",
            " extracting: test_images/image_0643.png  \n",
            " extracting: test_images/image_0614.png  \n",
            " extracting: test_images/image_0642.png  \n",
            " extracting: test_images/image_0618.png  \n",
            " extracting: test_images/image_0667.png  \n",
            " extracting: test_images/image_0666.png  \n",
            " extracting: test_images/image_0663.png  \n",
            " extracting: test_images/image_0650.png  \n",
            " extracting: test_images/image_0600.png  \n",
            " extracting: test_images/image_0641.png  \n",
            " extracting: test_images/image_0589.png  \n",
            " extracting: test_images/image_0621.png  \n",
            " extracting: test_images/image_0605.png  \n",
            " extracting: test_images/image_0661.png  \n",
            " extracting: test_images/image_0648.png  \n",
            " extracting: test_images/image_0620.png  \n",
            " extracting: test_images/image_0599.png  \n",
            " extracting: test_images/image_0591.png  \n",
            " extracting: test_images/image_0655.png  \n",
            " extracting: test_images/image_0629.png  \n",
            " extracting: test_images/image_0656.png  \n",
            " extracting: test_images/image_0659.png  \n",
            " extracting: test_images/image_0607.png  \n",
            " extracting: test_images/image_0592.png  \n",
            " extracting: test_images/image_0616.png  \n",
            " extracting: test_images/image_0624.png  \n",
            " extracting: test_images/image_0625.png  \n",
            " extracting: test_images/image_0633.png  \n",
            " extracting: test_images/image_0634.png  \n",
            " extracting: test_images/image_0595.png  \n",
            " extracting: test_images/image_0654.png  \n",
            " extracting: test_images/image_0588.png  \n",
            " extracting: test_images/image_0637.png  \n",
            " extracting: test_images/image_0644.png  \n",
            " extracting: test_images/image_0630.png  \n",
            " extracting: test_images/image_0646.png  \n",
            " extracting: test_images/image_0664.png  \n",
            " extracting: test_images/image_0645.png  \n",
            " extracting: test_images/image_0626.png  \n",
            " extracting: test_images/image_0606.png  \n",
            " extracting: test_images/image_0649.png  \n",
            " extracting: test_images/image_0657.png  \n",
            " extracting: test_images/image_0611.png  \n",
            " extracting: test_images/image_0590.png  \n",
            " extracting: test_images/image_0665.png  \n",
            " extracting: test_images/image_0652.png  \n",
            " extracting: test_images/image_0596.png  \n",
            " extracting: test_images/image_0617.png  \n",
            " extracting: test_images/image_0609.png  \n",
            " extracting: test_images/image_0638.png  \n",
            " extracting: test_images/image_0660.png  \n",
            " extracting: test_images/image_0619.png  \n",
            " extracting: test_images/image_0608.png  \n",
            " extracting: test_images/image_0593.png  \n",
            " extracting: test_images/image_0627.png  \n",
            " extracting: test_images/image_0717.png  \n",
            " extracting: test_images/image_0677.png  \n",
            " extracting: test_images/image_0682.png  \n",
            " extracting: test_images/image_0744.png  \n",
            " extracting: test_images/image_0702.png  \n",
            " extracting: test_images/image_0669.png  \n",
            " extracting: test_images/image_0745.png  \n",
            " extracting: test_images/image_0673.png  \n",
            " extracting: test_images/image_0730.png  \n",
            " extracting: test_images/image_0694.png  \n",
            " extracting: test_images/image_0712.png  \n",
            " extracting: test_images/image_0699.png  \n",
            " extracting: test_images/image_0691.png  \n",
            " extracting: test_images/image_0723.png  \n",
            " extracting: test_images/image_0736.png  \n",
            " extracting: test_images/image_0696.png  \n",
            " extracting: test_images/image_0709.png  \n",
            " extracting: test_images/image_0725.png  \n",
            " extracting: test_images/image_0683.png  \n",
            " extracting: test_images/image_0674.png  \n",
            " extracting: test_images/image_0693.png  \n",
            " extracting: test_images/image_0692.png  \n",
            " extracting: test_images/image_0680.png  \n",
            " extracting: test_images/image_0698.png  \n",
            " extracting: test_images/image_0737.png  \n",
            " extracting: test_images/image_0670.png  \n",
            " extracting: test_images/image_0714.png  \n",
            " extracting: test_images/image_0684.png  \n",
            " extracting: test_images/image_0721.png  \n",
            " extracting: test_images/image_0715.png  \n",
            " extracting: test_images/image_0746.png  \n",
            " extracting: test_images/image_0672.png  \n",
            " extracting: test_images/image_0724.png  \n",
            " extracting: test_images/image_0728.png  \n",
            " extracting: test_images/image_0690.png  \n",
            " extracting: test_images/image_0681.png  \n",
            " extracting: test_images/image_0740.png  \n",
            " extracting: test_images/image_0708.png  \n",
            " extracting: test_images/image_0726.png  \n",
            " extracting: test_images/image_0695.png  \n",
            " extracting: test_images/image_0686.png  \n",
            " extracting: test_images/image_0729.png  \n",
            " extracting: test_images/image_0710.png  \n",
            " extracting: test_images/image_0678.png  \n",
            " extracting: test_images/image_0722.png  \n",
            " extracting: test_images/image_0716.png  \n",
            " extracting: test_images/image_0675.png  \n",
            " extracting: test_images/image_0697.png  \n",
            " extracting: test_images/image_0685.png  \n",
            " extracting: test_images/image_0706.png  \n",
            " extracting: test_images/image_0731.png  \n",
            " extracting: test_images/image_0727.png  \n",
            " extracting: test_images/image_0704.png  \n",
            " extracting: test_images/image_0734.png  \n",
            " extracting: test_images/image_0747.png  \n",
            " extracting: test_images/image_0752.png  \n",
            " extracting: test_images/image_0688.png  \n",
            " extracting: test_images/image_0713.png  \n",
            " extracting: test_images/image_0720.png  \n",
            " extracting: test_images/image_0668.png  \n",
            " extracting: test_images/image_0739.png  \n",
            " extracting: test_images/image_0738.png  \n",
            " extracting: test_images/image_0749.png  \n",
            " extracting: test_images/image_0750.png  \n",
            " extracting: test_images/image_0671.png  \n",
            " extracting: test_images/image_0703.png  \n",
            " extracting: test_images/image_0700.png  \n",
            " extracting: test_images/image_0707.png  \n",
            " extracting: test_images/image_0689.png  \n",
            " extracting: test_images/image_0732.png  \n",
            " extracting: test_images/image_0733.png  \n",
            " extracting: test_images/image_0743.png  \n",
            " extracting: test_images/image_0711.png  \n",
            " extracting: test_images/image_0741.png  \n",
            " extracting: test_images/image_0719.png  \n",
            " extracting: test_images/image_0742.png  \n",
            " extracting: test_images/image_0676.png  \n",
            " extracting: test_images/image_0751.png  \n",
            " extracting: test_images/image_0679.png  \n",
            " extracting: test_images/image_0705.png  \n",
            " extracting: test_images/image_0687.png  \n",
            " extracting: test_images/image_0735.png  \n",
            " extracting: test_images/image_0718.png  \n",
            " extracting: test_images/image_0701.png  \n",
            " extracting: test_images/image_0748.png  \n",
            " extracting: test_images/image_0762.png  \n",
            " extracting: test_images/image_0837.png  \n",
            " extracting: test_images/image_0759.png  \n",
            " extracting: test_images/image_0808.png  \n",
            " extracting: test_images/image_0784.png  \n",
            " extracting: test_images/image_0787.png  \n",
            " extracting: test_images/image_0816.png  \n",
            " extracting: test_images/image_0789.png  \n",
            " extracting: test_images/image_0819.png  \n",
            " extracting: test_images/image_0757.png  \n",
            " extracting: test_images/image_0834.png  \n",
            " extracting: test_images/image_0818.png  \n",
            " extracting: test_images/image_0793.png  \n",
            " extracting: test_images/image_0801.png  \n",
            " extracting: test_images/image_0764.png  \n",
            " extracting: test_images/image_0829.png  \n",
            " extracting: test_images/image_0763.png  \n",
            " extracting: test_images/image_0791.png  \n",
            " extracting: test_images/image_0796.png  \n",
            " extracting: test_images/image_0822.png  \n",
            " extracting: test_images/image_0767.png  \n",
            " extracting: test_images/image_0839.png  \n",
            " extracting: test_images/image_0785.png  \n",
            " extracting: test_images/image_0832.png  \n",
            " extracting: test_images/image_0782.png  \n",
            " extracting: test_images/image_0753.png  \n",
            " extracting: test_images/image_0779.png  \n",
            " extracting: test_images/image_0788.png  \n",
            " extracting: test_images/image_0798.png  \n",
            " extracting: test_images/image_0772.png  \n",
            " extracting: test_images/image_0766.png  \n",
            " extracting: test_images/image_0817.png  \n",
            " extracting: test_images/image_0805.png  \n",
            " extracting: test_images/image_0770.png  \n",
            " extracting: test_images/image_0823.png  \n",
            " extracting: test_images/image_0761.png  \n",
            " extracting: test_images/image_0774.png  \n",
            " extracting: test_images/image_0809.png  \n",
            " extracting: test_images/image_0799.png  \n",
            " extracting: test_images/image_0765.png  \n",
            " extracting: test_images/image_0833.png  \n",
            " extracting: test_images/image_0820.png  \n",
            " extracting: test_images/image_0836.png  \n",
            " extracting: test_images/image_0813.png  \n",
            " extracting: test_images/image_0758.png  \n",
            " extracting: test_images/image_0781.png  \n",
            " extracting: test_images/image_0786.png  \n",
            " extracting: test_images/image_0778.png  \n",
            " extracting: test_images/image_0773.png  \n",
            " extracting: test_images/image_0815.png  \n",
            " extracting: test_images/image_0800.png  \n",
            " extracting: test_images/image_0768.png  \n",
            " extracting: test_images/image_0824.png  \n",
            " extracting: test_images/image_0760.png  \n",
            " extracting: test_images/image_0806.png  \n",
            " extracting: test_images/image_0783.png  \n",
            " extracting: test_images/image_0790.png  \n",
            " extracting: test_images/image_0797.png  \n",
            " extracting: test_images/image_0755.png  \n",
            " extracting: test_images/image_0769.png  \n",
            " extracting: test_images/image_0830.png  \n",
            " extracting: test_images/image_0812.png  \n",
            " extracting: test_images/image_0803.png  \n",
            " extracting: test_images/image_0814.png  \n",
            " extracting: test_images/image_0802.png  \n",
            " extracting: test_images/image_0831.png  \n",
            " extracting: test_images/image_0825.png  \n",
            " extracting: test_images/image_0792.png  \n",
            " extracting: test_images/image_0804.png  \n",
            " extracting: test_images/image_0780.png  \n",
            " extracting: test_images/image_0807.png  \n",
            " extracting: test_images/image_0811.png  \n",
            " extracting: test_images/image_0756.png  \n",
            " extracting: test_images/image_0775.png  \n",
            " extracting: test_images/image_0821.png  \n",
            " extracting: test_images/image_0826.png  \n",
            " extracting: test_images/image_0771.png  \n",
            " extracting: test_images/image_0838.png  \n",
            " extracting: test_images/image_0794.png  \n",
            " extracting: test_images/image_0777.png  \n",
            " extracting: test_images/image_0828.png  \n",
            " extracting: test_images/image_0776.png  \n",
            " extracting: test_images/image_0754.png  \n",
            " extracting: test_images/image_0795.png  \n",
            " extracting: test_images/image_0810.png  \n",
            " extracting: test_images/image_0827.png  \n",
            " extracting: test_images/image_0835.png  \n",
            " extracting: test_images/image_0849.png  \n",
            " extracting: test_images/image_0892.png  \n",
            " extracting: test_images/image_0857.png  \n",
            " extracting: test_images/image_0865.png  \n",
            " extracting: test_images/image_0909.png  \n",
            " extracting: test_images/image_0861.png  \n",
            " extracting: test_images/image_0854.png  \n",
            " extracting: test_images/image_0904.png  \n",
            " extracting: test_images/image_0850.png  \n",
            " extracting: test_images/image_0898.png  \n",
            " extracting: test_images/image_0879.png  \n",
            " extracting: test_images/image_0922.png  \n",
            " extracting: test_images/image_0916.png  \n",
            " extracting: test_images/image_0881.png  \n",
            " extracting: test_images/image_0875.png  \n",
            " extracting: test_images/image_0911.png  \n",
            " extracting: test_images/image_0867.png  \n",
            " extracting: test_images/image_0890.png  \n",
            " extracting: test_images/image_0906.png  \n",
            " extracting: test_images/image_0918.png  \n",
            " extracting: test_images/image_0886.png  \n",
            " extracting: test_images/image_0864.png  \n",
            " extracting: test_images/image_0893.png  \n",
            " extracting: test_images/image_0872.png  \n",
            " extracting: test_images/image_0901.png  \n",
            " extracting: test_images/image_0889.png  \n",
            " extracting: test_images/image_0845.png  \n",
            " extracting: test_images/image_0853.png  \n",
            " extracting: test_images/image_0855.png  \n",
            " extracting: test_images/image_0895.png  \n",
            " extracting: test_images/image_0885.png  \n",
            " extracting: test_images/image_0921.png  \n",
            " extracting: test_images/image_0882.png  \n",
            " extracting: test_images/image_0899.png  \n",
            " extracting: test_images/image_0858.png  \n",
            " extracting: test_images/image_0919.png  \n",
            " extracting: test_images/image_0887.png  \n",
            " extracting: test_images/image_0896.png  \n",
            " extracting: test_images/image_0877.png  \n",
            " extracting: test_images/image_0869.png  \n",
            " extracting: test_images/image_0847.png  \n",
            " extracting: test_images/image_0848.png  \n",
            " extracting: test_images/image_0914.png  \n",
            " extracting: test_images/image_0912.png  \n",
            " extracting: test_images/image_0860.png  \n",
            " extracting: test_images/image_0883.png  \n",
            " extracting: test_images/image_0856.png  \n",
            " extracting: test_images/image_0902.png  \n",
            " extracting: test_images/image_0876.png  \n",
            " extracting: test_images/image_0866.png  \n",
            " extracting: test_images/image_0884.png  \n",
            " extracting: test_images/image_0891.png  \n",
            " extracting: test_images/image_0851.png  \n",
            " extracting: test_images/image_0880.png  \n",
            " extracting: test_images/image_0915.png  \n",
            " extracting: test_images/image_0842.png  \n",
            " extracting: test_images/image_0924.png  \n",
            " extracting: test_images/image_0846.png  \n",
            " extracting: test_images/image_0862.png  \n",
            " extracting: test_images/image_0900.png  \n",
            " extracting: test_images/image_0894.png  \n",
            " extracting: test_images/image_0878.png  \n",
            " extracting: test_images/image_0920.png  \n",
            " extracting: test_images/image_0888.png  \n",
            " extracting: test_images/image_0841.png  \n",
            " extracting: test_images/image_0897.png  \n",
            " extracting: test_images/image_0871.png  \n",
            " extracting: test_images/image_0905.png  \n",
            " extracting: test_images/image_0908.png  \n",
            " extracting: test_images/image_0844.png  \n",
            " extracting: test_images/image_0917.png  \n",
            " extracting: test_images/image_0907.png  \n",
            " extracting: test_images/image_0852.png  \n",
            " extracting: test_images/image_0840.png  \n",
            " extracting: test_images/image_0903.png  \n",
            " extracting: test_images/image_0913.png  \n",
            " extracting: test_images/image_0863.png  \n",
            " extracting: test_images/image_0873.png  \n",
            " extracting: test_images/image_0874.png  \n",
            " extracting: test_images/image_0843.png  \n",
            " extracting: test_images/image_0859.png  \n",
            " extracting: test_images/image_0923.png  \n",
            " extracting: test_images/image_0870.png  \n",
            " extracting: test_images/image_0910.png  \n",
            " extracting: test_images/image_0868.png  \n",
            " extracting: test_images/image_0937.png  \n",
            " extracting: test_images/image_0982.png  \n",
            " extracting: test_images/image_0958.png  \n",
            " extracting: test_images/image_0984.png  \n",
            " extracting: test_images/image_0995.png  \n",
            " extracting: test_images/image_0931.png  \n",
            " extracting: test_images/image_0953.png  \n",
            " extracting: test_images/image_0968.png  \n",
            " extracting: test_images/image_0993.png  \n",
            " extracting: test_images/image_0998.png  \n",
            " extracting: test_images/image_0976.png  \n",
            " extracting: test_images/image_1007.png  \n",
            " extracting: test_images/image_0929.png  \n",
            " extracting: test_images/image_0951.png  \n",
            " extracting: test_images/image_1005.png  \n",
            " extracting: test_images/image_0925.png  \n",
            " extracting: test_images/image_0955.png  \n",
            " extracting: test_images/image_0989.png  \n",
            " extracting: test_images/image_1003.png  \n",
            " extracting: test_images/image_0936.png  \n",
            " extracting: test_images/image_0994.png  \n",
            " extracting: test_images/image_1000.png  \n",
            " extracting: test_images/image_0996.png  \n",
            " extracting: test_images/image_0979.png  \n",
            " extracting: test_images/image_0966.png  \n",
            " extracting: test_images/image_0972.png  \n",
            " extracting: test_images/image_0988.png  \n",
            " extracting: test_images/image_0963.png  \n",
            " extracting: test_images/image_0962.png  \n",
            " extracting: test_images/image_0938.png  \n",
            " extracting: test_images/image_0987.png  \n",
            " extracting: test_images/image_1004.png  \n",
            " extracting: test_images/image_0974.png  \n",
            " extracting: test_images/image_0950.png  \n",
            " extracting: test_images/image_1006.png  \n",
            " extracting: test_images/image_0946.png  \n",
            " extracting: test_images/image_0961.png  \n",
            " extracting: test_images/image_0983.png  \n",
            " extracting: test_images/image_1011.png  \n",
            " extracting: test_images/image_0930.png  \n",
            " extracting: test_images/image_0967.png  \n",
            " extracting: test_images/image_0943.png  \n",
            " extracting: test_images/image_0957.png  \n",
            " extracting: test_images/image_0971.png  \n",
            " extracting: test_images/image_0992.png  \n",
            " extracting: test_images/image_1001.png  \n",
            " extracting: test_images/image_0991.png  \n",
            " extracting: test_images/image_0944.png  \n",
            " extracting: test_images/image_0999.png  \n",
            " extracting: test_images/image_0973.png  \n",
            " extracting: test_images/image_0954.png  \n",
            " extracting: test_images/image_0945.png  \n",
            " extracting: test_images/image_0969.png  \n",
            " extracting: test_images/image_0933.png  \n",
            " extracting: test_images/image_0941.png  \n",
            " extracting: test_images/image_0940.png  \n",
            " extracting: test_images/image_0997.png  \n",
            " extracting: test_images/image_0990.png  \n",
            " extracting: test_images/image_0978.png  \n",
            " extracting: test_images/image_0986.png  \n",
            " extracting: test_images/image_1009.png  \n",
            " extracting: test_images/image_0952.png  \n",
            " extracting: test_images/image_0927.png  \n",
            " extracting: test_images/image_0948.png  \n",
            " extracting: test_images/image_0928.png  \n",
            " extracting: test_images/image_0942.png  \n",
            " extracting: test_images/image_0939.png  \n",
            " extracting: test_images/image_0947.png  \n",
            " extracting: test_images/image_0965.png  \n",
            " extracting: test_images/image_0960.png  \n",
            " extracting: test_images/image_1010.png  \n",
            " extracting: test_images/image_0959.png  \n",
            " extracting: test_images/image_0970.png  \n",
            " extracting: test_images/image_0935.png  \n",
            " extracting: test_images/image_0934.png  \n",
            " extracting: test_images/image_0981.png  \n",
            " extracting: test_images/image_0964.png  \n",
            " extracting: test_images/image_0980.png  \n",
            " extracting: test_images/image_1002.png  \n",
            " extracting: test_images/image_0985.png  \n",
            " extracting: test_images/image_0949.png  \n",
            " extracting: test_images/image_0956.png  \n",
            " extracting: test_images/image_0926.png  \n",
            " extracting: test_images/image_1008.png  \n",
            " extracting: test_images/image_0975.png  \n",
            " extracting: test_images/image_0932.png  \n",
            " extracting: test_images/image_0977.png  \n",
            " extracting: test_images/image_1016.png  \n",
            " extracting: test_images/image_1015.png  \n",
            " extracting: test_images/image_1066.png  \n",
            " extracting: test_images/image_1069.png  \n",
            " extracting: test_images/image_1046.png  \n",
            " extracting: test_images/image_1052.png  \n",
            " extracting: test_images/image_1092.png  \n",
            " extracting: test_images/image_1065.png  \n",
            " extracting: test_images/image_1037.png  \n",
            " extracting: test_images/image_1081.png  \n",
            " extracting: test_images/image_1040.png  \n",
            " extracting: test_images/image_1089.png  \n",
            " extracting: test_images/image_1012.png  \n",
            " extracting: test_images/image_1035.png  \n",
            " extracting: test_images/image_1068.png  \n",
            " extracting: test_images/image_1014.png  \n",
            " extracting: test_images/image_1030.png  \n",
            " extracting: test_images/image_1017.png  \n",
            " extracting: test_images/image_1071.png  \n",
            " extracting: test_images/image_1048.png  \n",
            " extracting: test_images/image_1044.png  \n",
            " extracting: test_images/image_1061.png  \n",
            " extracting: test_images/image_1021.png  \n",
            " extracting: test_images/image_1088.png  \n",
            " extracting: test_images/image_1087.png  \n",
            " extracting: test_images/image_1024.png  \n",
            " extracting: test_images/image_1098.png  \n",
            " extracting: test_images/image_1067.png  \n",
            " extracting: test_images/image_1085.png  \n",
            " extracting: test_images/image_1078.png  \n",
            " extracting: test_images/image_1018.png  \n",
            " extracting: test_images/image_1060.png  \n",
            " extracting: test_images/image_1028.png  \n",
            " extracting: test_images/image_1074.png  \n",
            " extracting: test_images/image_1083.png  \n",
            " extracting: test_images/image_1051.png  \n",
            " extracting: test_images/image_1086.png  \n",
            " extracting: test_images/image_1096.png  \n",
            " extracting: test_images/image_1055.png  \n",
            " extracting: test_images/image_1057.png  \n",
            " extracting: test_images/image_1082.png  \n",
            " extracting: test_images/image_1022.png  \n",
            " extracting: test_images/image_1050.png  \n",
            " extracting: test_images/image_1062.png  \n",
            " extracting: test_images/image_1073.png  \n",
            " extracting: test_images/image_1093.png  \n",
            " extracting: test_images/image_1019.png  \n",
            " extracting: test_images/image_1013.png  \n",
            " extracting: test_images/image_1056.png  \n",
            " extracting: test_images/image_1079.png  \n",
            " extracting: test_images/image_1045.png  \n",
            " extracting: test_images/image_1058.png  \n",
            " extracting: test_images/image_1032.png  \n",
            " extracting: test_images/image_1033.png  \n",
            " extracting: test_images/image_1090.png  \n",
            " extracting: test_images/image_1039.png  \n",
            " extracting: test_images/image_1063.png  \n",
            " extracting: test_images/image_1041.png  \n",
            " extracting: test_images/image_1070.png  \n",
            " extracting: test_images/image_1072.png  \n",
            " extracting: test_images/image_1091.png  \n",
            " extracting: test_images/image_1059.png  \n",
            " extracting: test_images/image_1076.png  \n",
            " extracting: test_images/image_1053.png  \n",
            " extracting: test_images/image_1097.png  \n",
            " extracting: test_images/image_1095.png  \n",
            " extracting: test_images/image_1075.png  \n",
            " extracting: test_images/image_1094.png  \n",
            " extracting: test_images/image_1027.png  \n",
            " extracting: test_images/image_1025.png  \n",
            " extracting: test_images/image_1034.png  \n",
            " extracting: test_images/image_1042.png  \n",
            " extracting: test_images/image_1077.png  \n",
            " extracting: test_images/image_1084.png  \n",
            " extracting: test_images/image_1080.png  \n",
            " extracting: test_images/image_1054.png  \n",
            " extracting: test_images/image_1038.png  \n",
            " extracting: test_images/image_1043.png  \n",
            " extracting: test_images/image_1029.png  \n",
            " extracting: test_images/image_1036.png  \n",
            " extracting: test_images/image_1026.png  \n",
            " extracting: test_images/image_1020.png  \n",
            " extracting: test_images/image_1047.png  \n",
            " extracting: test_images/image_1023.png  \n",
            " extracting: test_images/image_1049.png  \n",
            " extracting: test_images/image_1064.png  \n",
            " extracting: test_images/image_1031.png  \n",
            " extracting: test_images/image_1152.png  \n",
            " extracting: test_images/image_1140.png  \n",
            " extracting: test_images/image_1106.png  \n",
            " extracting: test_images/image_1142.png  \n",
            " extracting: test_images/image_1110.png  \n",
            " extracting: test_images/image_1176.png  \n",
            " extracting: test_images/image_1118.png  \n",
            " extracting: test_images/image_1107.png  \n",
            " extracting: test_images/image_1126.png  \n",
            " extracting: test_images/image_1143.png  \n",
            " extracting: test_images/image_1161.png  \n",
            " extracting: test_images/image_1138.png  \n",
            " extracting: test_images/image_1116.png  \n",
            " extracting: test_images/image_1172.png  \n",
            " extracting: test_images/image_1147.png  \n",
            " extracting: test_images/image_1185.png  \n",
            " extracting: test_images/image_1130.png  \n",
            " extracting: test_images/image_1112.png  \n",
            " extracting: test_images/image_1169.png  \n",
            " extracting: test_images/image_1162.png  \n",
            " extracting: test_images/image_1136.png  \n",
            " extracting: test_images/image_1105.png  \n",
            " extracting: test_images/image_1141.png  \n",
            " extracting: test_images/image_1164.png  \n",
            " extracting: test_images/image_1155.png  \n",
            " extracting: test_images/image_1128.png  \n",
            " extracting: test_images/image_1119.png  \n",
            " extracting: test_images/image_1145.png  \n",
            " extracting: test_images/image_1160.png  \n",
            " extracting: test_images/image_1163.png  \n",
            " extracting: test_images/image_1156.png  \n",
            " extracting: test_images/image_1174.png  \n",
            " extracting: test_images/image_1101.png  \n",
            " extracting: test_images/image_1170.png  \n",
            " extracting: test_images/image_1135.png  \n",
            " extracting: test_images/image_1182.png  \n",
            " extracting: test_images/image_1177.png  \n",
            " extracting: test_images/image_1166.png  \n",
            " extracting: test_images/image_1103.png  \n",
            " extracting: test_images/image_1149.png  \n",
            " extracting: test_images/image_1121.png  \n",
            " extracting: test_images/image_1100.png  \n",
            " extracting: test_images/image_1146.png  \n",
            " extracting: test_images/image_1165.png  \n",
            " extracting: test_images/image_1134.png  \n",
            " extracting: test_images/image_1102.png  \n",
            " extracting: test_images/image_1133.png  \n",
            " extracting: test_images/image_1179.png  \n",
            " extracting: test_images/image_1113.png  \n",
            " extracting: test_images/image_1111.png  \n",
            " extracting: test_images/image_1123.png  \n",
            " extracting: test_images/image_1108.png  \n",
            " extracting: test_images/image_1127.png  \n",
            " extracting: test_images/image_1168.png  \n",
            " extracting: test_images/image_1175.png  \n",
            " extracting: test_images/image_1186.png  \n",
            " extracting: test_images/image_1139.png  \n",
            " extracting: test_images/image_1129.png  \n",
            " extracting: test_images/image_1114.png  \n",
            " extracting: test_images/image_1151.png  \n",
            " extracting: test_images/image_1104.png  \n",
            " extracting: test_images/image_1150.png  \n",
            " extracting: test_images/image_1099.png  \n",
            " extracting: test_images/image_1124.png  \n",
            " extracting: test_images/image_1120.png  \n",
            " extracting: test_images/image_1171.png  \n",
            " extracting: test_images/image_1158.png  \n",
            " extracting: test_images/image_1117.png  \n",
            " extracting: test_images/image_1131.png  \n",
            " extracting: test_images/image_1181.png  \n",
            " extracting: test_images/image_1154.png  \n",
            " extracting: test_images/image_1157.png  \n",
            " extracting: test_images/image_1109.png  \n",
            " extracting: test_images/image_1153.png  \n",
            " extracting: test_images/image_1122.png  \n",
            " extracting: test_images/image_1178.png  \n",
            " extracting: test_images/image_1183.png  \n",
            " extracting: test_images/image_1125.png  \n",
            " extracting: test_images/image_1115.png  \n",
            " extracting: test_images/image_1137.png  \n",
            " extracting: test_images/image_1148.png  \n",
            " extracting: test_images/image_1180.png  \n",
            " extracting: test_images/image_1132.png  \n",
            " extracting: test_images/image_1144.png  \n",
            " extracting: test_images/image_1184.png  \n",
            " extracting: test_images/image_1173.png  \n",
            " extracting: test_images/image_1167.png  \n",
            " extracting: test_images/image_1159.png  \n",
            " extracting: test_images/image_1236.png  \n",
            " extracting: test_images/image_1242.png  \n",
            " extracting: test_images/image_1253.png  \n",
            " extracting: test_images/image_1252.png  \n",
            " extracting: test_images/image_1250.png  \n",
            " extracting: test_images/image_1195.png  \n",
            " extracting: test_images/image_1197.png  \n",
            " extracting: test_images/image_1199.png  \n",
            " extracting: test_images/image_1235.png  \n",
            " extracting: test_images/image_1200.png  \n",
            " extracting: test_images/image_1223.png  \n",
            " extracting: test_images/image_1209.png  \n",
            " extracting: test_images/image_1229.png  \n",
            " extracting: test_images/image_1228.png  \n",
            " extracting: test_images/image_1206.png  \n",
            " extracting: test_images/image_1190.png  \n",
            " extracting: test_images/image_1203.png  \n",
            " extracting: test_images/image_1244.png  \n",
            " extracting: test_images/image_1273.png  \n",
            " extracting: test_images/image_1216.png  \n",
            " extracting: test_images/image_1208.png  \n",
            " extracting: test_images/image_1204.png  \n",
            " extracting: test_images/image_1272.png  \n",
            " extracting: test_images/image_1267.png  \n",
            " extracting: test_images/image_1241.png  \n",
            " extracting: test_images/image_1198.png  \n",
            " extracting: test_images/image_1189.png  \n",
            " extracting: test_images/image_1257.png  \n",
            " extracting: test_images/image_1232.png  \n",
            " extracting: test_images/image_1268.png  \n",
            " extracting: test_images/image_1237.png  \n",
            " extracting: test_images/image_1274.png  \n",
            " extracting: test_images/image_1246.png  \n",
            " extracting: test_images/image_1238.png  \n",
            " extracting: test_images/image_1256.png  \n",
            " extracting: test_images/image_1207.png  \n",
            " extracting: test_images/image_1212.png  \n",
            " extracting: test_images/image_1201.png  \n",
            " extracting: test_images/image_1239.png  \n",
            " extracting: test_images/image_1217.png  \n",
            " extracting: test_images/image_1196.png  \n",
            " extracting: test_images/image_1192.png  \n",
            " extracting: test_images/image_1275.png  \n",
            " extracting: test_images/image_1263.png  \n",
            " extracting: test_images/image_1221.png  \n",
            " extracting: test_images/image_1219.png  \n",
            " extracting: test_images/image_1210.png  \n",
            " extracting: test_images/image_1225.png  \n",
            " extracting: test_images/image_1222.png  \n",
            " extracting: test_images/image_1202.png  \n",
            " extracting: test_images/image_1226.png  \n",
            " extracting: test_images/image_1231.png  \n",
            " extracting: test_images/image_1211.png  \n",
            " extracting: test_images/image_1266.png  \n",
            " extracting: test_images/image_1271.png  \n",
            " extracting: test_images/image_1214.png  \n",
            " extracting: test_images/image_1262.png  \n",
            " extracting: test_images/image_1255.png  \n",
            " extracting: test_images/image_1265.png  \n",
            " extracting: test_images/image_1270.png  \n",
            " extracting: test_images/image_1245.png  \n",
            " extracting: test_images/image_1213.png  \n",
            " extracting: test_images/image_1233.png  \n",
            " extracting: test_images/image_1224.png  \n",
            " extracting: test_images/image_1240.png  \n",
            " extracting: test_images/image_1259.png  \n",
            " extracting: test_images/image_1234.png  \n",
            " extracting: test_images/image_1215.png  \n",
            " extracting: test_images/image_1251.png  \n",
            " extracting: test_images/image_1260.png  \n",
            " extracting: test_images/image_1249.png  \n",
            " extracting: test_images/image_1248.png  \n",
            " extracting: test_images/image_1261.png  \n",
            " extracting: test_images/image_1218.png  \n",
            " extracting: test_images/image_1269.png  \n",
            " extracting: test_images/image_1258.png  \n",
            " extracting: test_images/image_1254.png  \n",
            " extracting: test_images/image_1264.png  \n",
            " extracting: test_images/image_1194.png  \n",
            " extracting: test_images/image_1205.png  \n",
            " extracting: test_images/image_1193.png  \n",
            " extracting: test_images/image_1191.png  \n",
            " extracting: test_images/image_1188.png  \n",
            " extracting: test_images/image_1227.png  \n",
            " extracting: test_images/image_1187.png  \n",
            " extracting: test_images/image_1247.png  \n",
            " extracting: test_images/image_1230.png  \n",
            " extracting: test_images/image_1243.png  \n",
            " extracting: test_images/image_1220.png  \n",
            " extracting: test_images/image_1284.png  \n",
            " extracting: test_images/image_1327.png  \n",
            " extracting: test_images/image_1364.png  \n",
            " extracting: test_images/image_1292.png  \n",
            " extracting: test_images/image_1279.png  \n",
            " extracting: test_images/image_1357.png  \n",
            " extracting: test_images/image_1347.png  \n",
            " extracting: test_images/image_1291.png  \n",
            " extracting: test_images/image_1351.png  \n",
            " extracting: test_images/image_1345.png  \n",
            " extracting: test_images/image_1344.png  \n",
            " extracting: test_images/image_1281.png  \n",
            " extracting: test_images/image_1319.png  \n",
            " extracting: test_images/image_1355.png  \n",
            " extracting: test_images/image_1336.png  \n",
            " extracting: test_images/image_1325.png  \n",
            " extracting: test_images/image_1309.png  \n",
            " extracting: test_images/image_1353.png  \n",
            " extracting: test_images/image_1329.png  \n",
            " extracting: test_images/image_1308.png  \n",
            " extracting: test_images/image_1332.png  \n",
            " extracting: test_images/image_1314.png  \n",
            " extracting: test_images/image_1311.png  \n",
            " extracting: test_images/image_1320.png  \n",
            " extracting: test_images/image_1323.png  \n",
            " extracting: test_images/image_1287.png  \n",
            " extracting: test_images/image_1288.png  \n",
            " extracting: test_images/image_1294.png  \n",
            " extracting: test_images/image_1283.png  \n",
            " extracting: test_images/image_1298.png  \n",
            " extracting: test_images/image_1305.png  \n",
            " extracting: test_images/image_1361.png  \n",
            " extracting: test_images/image_1313.png  \n",
            " extracting: test_images/image_1358.png  \n",
            " extracting: test_images/image_1343.png  \n",
            " extracting: test_images/image_1278.png  \n",
            " extracting: test_images/image_1312.png  \n",
            " extracting: test_images/image_1346.png  \n",
            " extracting: test_images/image_1297.png  \n",
            " extracting: test_images/image_1317.png  \n",
            " extracting: test_images/image_1362.png  \n",
            " extracting: test_images/image_1348.png  \n",
            " extracting: test_images/image_1315.png  \n",
            " extracting: test_images/image_1334.png  \n",
            " extracting: test_images/image_1302.png  \n",
            " extracting: test_images/image_1328.png  \n",
            " extracting: test_images/image_1359.png  \n",
            " extracting: test_images/image_1321.png  \n",
            " extracting: test_images/image_1286.png  \n",
            " extracting: test_images/image_1333.png  \n",
            " extracting: test_images/image_1303.png  \n",
            " extracting: test_images/image_1301.png  \n",
            " extracting: test_images/image_1356.png  \n",
            " extracting: test_images/image_1342.png  \n",
            " extracting: test_images/image_1349.png  \n",
            " extracting: test_images/image_1340.png  \n",
            " extracting: test_images/image_1293.png  \n",
            " extracting: test_images/image_1326.png  \n",
            " extracting: test_images/image_1322.png  \n",
            " extracting: test_images/image_1296.png  \n",
            " extracting: test_images/image_1280.png  \n",
            " extracting: test_images/image_1316.png  \n",
            " extracting: test_images/image_1306.png  \n",
            " extracting: test_images/image_1350.png  \n",
            " extracting: test_images/image_1339.png  \n",
            " extracting: test_images/image_1300.png  \n",
            " extracting: test_images/image_1324.png  \n",
            " extracting: test_images/image_1276.png  \n",
            " extracting: test_images/image_1366.png  \n",
            " extracting: test_images/image_1363.png  \n",
            " extracting: test_images/image_1304.png  \n",
            " extracting: test_images/image_1282.png  \n",
            " extracting: test_images/image_1310.png  \n",
            " extracting: test_images/image_1335.png  \n",
            " extracting: test_images/image_1318.png  \n",
            " extracting: test_images/image_1307.png  \n",
            " extracting: test_images/image_1295.png  \n",
            " extracting: test_images/image_1352.png  \n",
            " extracting: test_images/image_1285.png  \n",
            " extracting: test_images/image_1289.png  \n",
            " extracting: test_images/image_1331.png  \n",
            " extracting: test_images/image_1360.png  \n",
            " extracting: test_images/image_1365.png  \n",
            " extracting: test_images/image_1290.png  \n",
            " extracting: test_images/image_1277.png  \n",
            " extracting: test_images/image_1299.png  \n",
            " extracting: test_images/image_1354.png  \n",
            " extracting: test_images/image_1338.png  \n",
            " extracting: test_images/image_1341.png  \n",
            " extracting: test_images/image_1337.png  \n",
            " extracting: test_images/image_1330.png  \n",
            " extracting: test_images/image_1441.png  \n",
            " extracting: test_images/image_1422.png  \n",
            " extracting: test_images/image_1387.png  \n",
            " extracting: test_images/image_1412.png  \n",
            " extracting: test_images/image_1431.png  \n",
            " extracting: test_images/image_1399.png  \n",
            " extracting: test_images/image_1385.png  \n",
            " extracting: test_images/image_1403.png  \n",
            " extracting: test_images/image_1418.png  \n",
            " extracting: test_images/image_1448.png  \n",
            " extracting: test_images/image_1374.png  \n",
            " extracting: test_images/image_1450.png  \n",
            " extracting: test_images/image_1444.png  \n",
            " extracting: test_images/image_1416.png  \n",
            " extracting: test_images/image_1417.png  \n",
            " extracting: test_images/image_1370.png  \n",
            " extracting: test_images/image_1371.png  \n",
            " extracting: test_images/image_1402.png  \n",
            " extracting: test_images/image_1440.png  \n",
            " extracting: test_images/image_1393.png  \n",
            " extracting: test_images/image_1435.png  \n",
            " extracting: test_images/image_1426.png  \n",
            " extracting: test_images/image_1367.png  \n",
            " extracting: test_images/image_1419.png  \n",
            " extracting: test_images/image_1383.png  \n",
            " extracting: test_images/image_1372.png  \n",
            " extracting: test_images/image_1381.png  \n",
            " extracting: test_images/image_1392.png  \n",
            " extracting: test_images/image_1377.png  \n",
            " extracting: test_images/image_1409.png  \n",
            " extracting: test_images/image_1454.png  \n",
            " extracting: test_images/image_1415.png  \n",
            " extracting: test_images/image_1432.png  \n",
            " extracting: test_images/image_1373.png  \n",
            " extracting: test_images/image_1368.png  \n",
            " extracting: test_images/image_1425.png  \n",
            " extracting: test_images/image_1388.png  \n",
            " extracting: test_images/image_1427.png  \n",
            " extracting: test_images/image_1421.png  \n",
            " extracting: test_images/image_1446.png  \n",
            " extracting: test_images/image_1404.png  \n",
            " extracting: test_images/image_1369.png  \n",
            " extracting: test_images/image_1423.png  \n",
            " extracting: test_images/image_1396.png  \n",
            " extracting: test_images/image_1378.png  \n",
            " extracting: test_images/image_1455.png  \n",
            " extracting: test_images/image_1434.png  \n",
            " extracting: test_images/image_1451.png  \n",
            " extracting: test_images/image_1438.png  \n",
            " extracting: test_images/image_1380.png  \n",
            " extracting: test_images/image_1437.png  \n",
            " extracting: test_images/image_1420.png  \n",
            " extracting: test_images/image_1406.png  \n",
            " extracting: test_images/image_1452.png  \n",
            " extracting: test_images/image_1397.png  \n",
            " extracting: test_images/image_1390.png  \n",
            " extracting: test_images/image_1410.png  \n",
            " extracting: test_images/image_1414.png  \n",
            " extracting: test_images/image_1428.png  \n",
            " extracting: test_images/image_1395.png  \n",
            " extracting: test_images/image_1424.png  \n",
            " extracting: test_images/image_1436.png  \n",
            " extracting: test_images/image_1375.png  \n",
            " extracting: test_images/image_1398.png  \n",
            " extracting: test_images/image_1376.png  \n",
            " extracting: test_images/image_1407.png  \n",
            " extracting: test_images/image_1413.png  \n",
            " extracting: test_images/image_1433.png  \n",
            " extracting: test_images/image_1384.png  \n",
            " extracting: test_images/image_1401.png  \n",
            " extracting: test_images/image_1430.png  \n",
            " extracting: test_images/image_1443.png  \n",
            " extracting: test_images/image_1382.png  \n",
            " extracting: test_images/image_1429.png  \n",
            " extracting: test_images/image_1453.png  \n",
            " extracting: test_images/image_1379.png  \n",
            " extracting: test_images/image_1411.png  \n",
            " extracting: test_images/image_1445.png  \n",
            " extracting: test_images/image_1456.png  \n",
            " extracting: test_images/image_1447.png  \n",
            " extracting: test_images/image_1394.png  \n",
            " extracting: test_images/image_1400.png  \n",
            " extracting: test_images/image_1386.png  \n",
            " extracting: test_images/image_1391.png  \n",
            " extracting: test_images/image_1405.png  \n",
            " extracting: test_images/image_1439.png  \n",
            " extracting: test_images/image_1449.png  \n",
            " extracting: test_images/image_1389.png  \n",
            " extracting: test_images/image_1408.png  \n",
            " extracting: test_images/image_1442.png  \n",
            " extracting: test_images/image_1457.png  \n",
            " extracting: test_images/image_1488.png  \n",
            " extracting: test_images/image_1544.png  \n",
            " extracting: test_images/image_1464.png  \n",
            " extracting: test_images/image_1494.png  \n",
            " extracting: test_images/image_1503.png  \n",
            " extracting: test_images/image_1508.png  \n",
            " extracting: test_images/image_1520.png  \n",
            " extracting: test_images/image_1461.png  \n",
            " extracting: test_images/image_1524.png  \n",
            " extracting: test_images/image_1496.png  \n",
            " extracting: test_images/image_1530.png  \n",
            " extracting: test_images/image_1510.png  \n",
            " extracting: test_images/image_1546.png  \n",
            " extracting: test_images/image_1465.png  \n",
            " extracting: test_images/image_1542.png  \n",
            " extracting: test_images/image_1536.png  \n",
            " extracting: test_images/image_1498.png  \n",
            " extracting: test_images/image_1486.png  \n",
            " extracting: test_images/image_1540.png  \n",
            " extracting: test_images/image_1502.png  \n",
            " extracting: test_images/image_1480.png  \n",
            " extracting: test_images/image_1477.png  \n",
            " extracting: test_images/image_1476.png  \n",
            " extracting: test_images/image_1521.png  \n",
            " extracting: test_images/image_1534.png  \n",
            " extracting: test_images/image_1472.png  \n",
            " extracting: test_images/image_1484.png  \n",
            " extracting: test_images/image_1522.png  \n",
            " extracting: test_images/image_1466.png  \n",
            " extracting: test_images/image_1471.png  \n",
            " extracting: test_images/image_1478.png  \n",
            " extracting: test_images/image_1475.png  \n",
            " extracting: test_images/image_1501.png  \n",
            " extracting: test_images/image_1513.png  \n",
            " extracting: test_images/image_1531.png  \n",
            " extracting: test_images/image_1499.png  \n",
            " extracting: test_images/image_1482.png  \n",
            " extracting: test_images/image_1483.png  \n",
            " extracting: test_images/image_1537.png  \n",
            " extracting: test_images/image_1467.png  \n",
            " extracting: test_images/image_1529.png  \n",
            " extracting: test_images/image_1509.png  \n",
            " extracting: test_images/image_1528.png  \n",
            " extracting: test_images/image_1538.png  \n",
            " extracting: test_images/image_1495.png  \n",
            " extracting: test_images/image_1527.png  \n",
            " extracting: test_images/image_1490.png  \n",
            " extracting: test_images/image_1491.png  \n",
            " extracting: test_images/image_1469.png  \n",
            " extracting: test_images/image_1517.png  \n",
            " extracting: test_images/image_1460.png  \n",
            " extracting: test_images/image_1514.png  \n",
            " extracting: test_images/image_1506.png  \n",
            " extracting: test_images/image_1470.png  \n",
            " extracting: test_images/image_1474.png  \n",
            " extracting: test_images/image_1547.png  \n",
            " extracting: test_images/image_1479.png  \n",
            " extracting: test_images/image_1541.png  \n",
            " extracting: test_images/image_1458.png  \n",
            " extracting: test_images/image_1500.png  \n",
            " extracting: test_images/image_1505.png  \n",
            " extracting: test_images/image_1515.png  \n",
            " extracting: test_images/image_1462.png  \n",
            " extracting: test_images/image_1463.png  \n",
            " extracting: test_images/image_1535.png  \n",
            " extracting: test_images/image_1487.png  \n",
            " extracting: test_images/image_1532.png  \n",
            " extracting: test_images/image_1511.png  \n",
            " extracting: test_images/image_1468.png  \n",
            " extracting: test_images/image_1516.png  \n",
            " extracting: test_images/image_1459.png  \n",
            " extracting: test_images/image_1525.png  \n",
            " extracting: test_images/image_1481.png  \n",
            " extracting: test_images/image_1492.png  \n",
            " extracting: test_images/image_1526.png  \n",
            " extracting: test_images/image_1504.png  \n",
            " extracting: test_images/image_1493.png  \n",
            " extracting: test_images/image_1539.png  \n",
            " extracting: test_images/image_1543.png  \n",
            " extracting: test_images/image_1533.png  \n",
            " extracting: test_images/image_1523.png  \n",
            " extracting: test_images/image_1489.png  \n",
            " extracting: test_images/image_1545.png  \n",
            " extracting: test_images/image_1507.png  \n",
            " extracting: test_images/image_1485.png  \n",
            " extracting: test_images/image_1519.png  \n",
            " extracting: test_images/image_1548.png  \n",
            " extracting: test_images/image_1497.png  \n",
            " extracting: test_images/image_1473.png  \n",
            " extracting: test_images/image_1512.png  \n",
            " extracting: test_images/image_1518.png  \n",
            " extracting: test_images/image_1583.png  \n",
            " extracting: test_images/image_1559.png  \n",
            " extracting: test_images/image_1568.png  \n",
            " extracting: test_images/image_1572.png  \n",
            " extracting: test_images/image_1577.png  \n",
            " extracting: test_images/image_1587.png  \n",
            " extracting: test_images/image_1590.png  \n",
            " extracting: test_images/image_1582.png  \n",
            " extracting: test_images/image_1573.png  \n",
            " extracting: test_images/image_1566.png  \n",
            " extracting: test_images/image_1591.png  \n",
            " extracting: test_images/image_1578.png  \n",
            " extracting: test_images/image_1579.png  \n",
            " extracting: test_images/image_1575.png  \n",
            " extracting: test_images/image_1598.png  \n",
            " extracting: test_images/image_1580.png  \n",
            " extracting: test_images/image_1576.png  \n",
            " extracting: test_images/image_1594.png  \n",
            " extracting: test_images/image_1558.png  \n",
            " extracting: test_images/image_1584.png  \n",
            " extracting: test_images/image_1571.png  \n",
            " extracting: test_images/image_1560.png  \n",
            " extracting: test_images/image_1588.png  \n",
            " extracting: test_images/image_1599.png  \n",
            " extracting: test_images/image_1595.png  \n",
            " extracting: test_images/image_1555.png  \n",
            " extracting: test_images/image_1597.png  \n",
            " extracting: test_images/image_1567.png  \n",
            " extracting: test_images/image_1549.png  \n",
            " extracting: test_images/image_1589.png  \n",
            " extracting: test_images/image_1570.png  \n",
            " extracting: test_images/image_1593.png  \n",
            " extracting: test_images/image_1556.png  \n",
            " extracting: test_images/image_1553.png  \n",
            " extracting: test_images/image_1557.png  \n",
            " extracting: test_images/image_1586.png  \n",
            " extracting: test_images/image_1569.png  \n",
            " extracting: test_images/image_1585.png  \n",
            " extracting: test_images/image_1563.png  \n",
            " extracting: test_images/image_1561.png  \n",
            " extracting: test_images/image_1554.png  \n",
            " extracting: test_images/image_1552.png  \n",
            " extracting: test_images/image_1551.png  \n",
            " extracting: test_images/image_1596.png  \n",
            " extracting: test_images/image_1564.png  \n",
            " extracting: test_images/image_1562.png  \n",
            " extracting: test_images/image_1565.png  \n",
            " extracting: test_images/image_1581.png  \n",
            " extracting: test_images/image_1550.png  \n",
            " extracting: test_images/image_1592.png  \n",
            " extracting: test_images/image_1574.png  \n",
            " extracting: test_images/image_0051.png  \n",
            " extracting: test_images/image_0018.png  \n",
            " extracting: test_images/image_0043.png  \n",
            " extracting: test_images/image_0075.png  \n",
            " extracting: test_images/image_0037.png  \n",
            " extracting: test_images/image_0031.png  \n",
            " extracting: test_images/image_0059.png  \n",
            " extracting: test_images/image_0049.png  \n",
            " extracting: test_images/image_0002.png  \n",
            " extracting: test_images/image_0020.png  \n",
            " extracting: test_images/image_0017.png  \n",
            " extracting: test_images/image_0044.png  \n",
            " extracting: test_images/image_0007.png  \n",
            " extracting: test_images/image_0065.png  \n",
            " extracting: test_images/image_0048.png  \n",
            " extracting: test_images/image_0012.png  \n",
            " extracting: test_images/image_0003.png  \n",
            " extracting: test_images/image_0019.png  \n",
            " extracting: test_images/image_0069.png  \n",
            " extracting: test_images/image_0023.png  \n",
            " extracting: test_images/image_0021.png  \n",
            " extracting: test_images/image_0042.png  \n",
            " extracting: test_images/image_0064.png  \n",
            " extracting: test_images/image_0046.png  \n",
            " extracting: test_images/image_0038.png  \n",
            " extracting: test_images/image_0052.png  \n",
            " extracting: test_images/image_0028.png  \n",
            " extracting: test_images/image_0040.png  \n",
            " extracting: test_images/image_0076.png  \n",
            " extracting: test_images/image_0056.png  \n",
            " extracting: test_images/image_0030.png  \n",
            " extracting: test_images/image_0036.png  \n",
            " extracting: test_images/image_0060.png  \n",
            " extracting: test_images/image_0068.png  \n",
            " extracting: test_images/image_0010.png  \n",
            " extracting: test_images/image_0027.png  \n",
            " extracting: test_images/image_0032.png  \n",
            " extracting: test_images/image_0015.png  \n",
            " extracting: test_images/image_0035.png  \n",
            " extracting: test_images/image_0009.png  \n",
            " extracting: test_images/image_0058.png  \n",
            " extracting: test_images/image_0016.png  \n",
            " extracting: test_images/image_0063.png  \n",
            " extracting: test_images/image_0033.png  \n",
            " extracting: test_images/image_0055.png  \n",
            " extracting: test_images/image_0071.png  \n",
            " extracting: test_images/image_0057.png  \n",
            " extracting: test_images/image_0001.png  \n",
            " extracting: test_images/image_0014.png  \n",
            " extracting: test_images/image_0073.png  \n",
            " extracting: test_images/image_0041.png  \n",
            " extracting: test_images/image_0011.png  \n",
            " extracting: test_images/image_0054.png  \n",
            " extracting: test_images/image_0024.png  \n",
            " extracting: test_images/image_0045.png  \n",
            " extracting: test_images/image_0026.png  \n",
            " extracting: test_images/image_0029.png  \n",
            " extracting: test_images/image_0004.png  \n",
            " extracting: test_images/image_0061.png  \n",
            " extracting: test_images/image_0000.png  \n",
            " extracting: test_images/image_0067.png  \n",
            " extracting: test_images/image_0013.png  \n",
            " extracting: test_images/image_0072.png  \n",
            " extracting: test_images/image_0039.png  \n",
            " extracting: test_images/image_0050.png  \n",
            " extracting: test_images/image_0034.png  \n",
            " extracting: test_images/image_0006.png  \n",
            " extracting: test_images/image_0066.png  \n",
            " extracting: test_images/image_0025.png  \n",
            " extracting: test_images/image_0005.png  \n",
            " extracting: test_images/image_0070.png  \n",
            " extracting: test_images/image_0053.png  \n",
            " extracting: test_images/image_0008.png  \n",
            " extracting: test_images/image_0062.png  \n",
            " extracting: test_images/image_0022.png  \n",
            " extracting: test_images/image_0074.png  \n",
            " extracting: test_images/image_0047.png  \n",
            " extracting: test_images/image_0077.png  \n",
            " extracting: test_images/image_0165.png  \n",
            " extracting: test_images/image_0115.png  \n",
            " extracting: test_images/image_0138.png  \n",
            " extracting: test_images/image_0102.png  \n",
            " extracting: test_images/image_0150.png  \n",
            " extracting: test_images/image_0153.png  \n",
            " extracting: test_images/image_0160.png  \n",
            " extracting: test_images/image_0136.png  \n",
            " extracting: test_images/image_0157.png  \n",
            " extracting: test_images/image_0137.png  \n",
            " extracting: test_images/image_0079.png  \n",
            " extracting: test_images/image_0143.png  \n",
            " extracting: test_images/image_0149.png  \n",
            " extracting: test_images/image_0141.png  \n",
            " extracting: test_images/image_0144.png  \n",
            " extracting: test_images/image_0094.png  \n",
            " extracting: test_images/image_0090.png  \n",
            " extracting: test_images/image_0122.png  \n",
            " extracting: test_images/image_0156.png  \n",
            " extracting: test_images/image_0114.png  \n",
            " extracting: test_images/image_0111.png  \n",
            " extracting: test_images/image_0132.png  \n",
            " extracting: test_images/image_0162.png  \n",
            " extracting: test_images/image_0133.png  \n",
            " extracting: test_images/image_0131.png  \n",
            " extracting: test_images/image_0148.png  \n",
            " extracting: test_images/image_0130.png  \n",
            " extracting: test_images/image_0145.png  \n",
            " extracting: test_images/image_0089.png  \n",
            " extracting: test_images/image_0097.png  \n",
            " extracting: test_images/image_0142.png  \n",
            " extracting: test_images/image_0126.png  \n",
            " extracting: test_images/image_0083.png  \n",
            " extracting: test_images/image_0124.png  \n",
            " extracting: test_images/image_0107.png  \n",
            " extracting: test_images/image_0081.png  \n",
            " extracting: test_images/image_0163.png  \n",
            " extracting: test_images/image_0123.png  \n",
            " extracting: test_images/image_0106.png  \n",
            " extracting: test_images/image_0108.png  \n",
            " extracting: test_images/image_0110.png  \n",
            " extracting: test_images/image_0096.png  \n",
            " extracting: test_images/image_0117.png  \n",
            " extracting: test_images/image_0113.png  \n",
            " extracting: test_images/image_0164.png  \n",
            " extracting: test_images/image_0154.png  \n",
            " extracting: test_images/image_0135.png  \n",
            " extracting: test_images/image_0128.png  \n",
            " extracting: test_images/image_0109.png  \n",
            " extracting: test_images/image_0084.png  \n",
            " extracting: test_images/image_0112.png  \n",
            " extracting: test_images/image_0140.png  \n",
            " extracting: test_images/image_0092.png  \n",
            " extracting: test_images/image_0088.png  \n",
            " extracting: test_images/image_0086.png  \n",
            " extracting: test_images/image_0104.png  \n",
            " extracting: test_images/image_0118.png  \n",
            " extracting: test_images/image_0151.png  \n",
            " extracting: test_images/image_0159.png  \n",
            " extracting: test_images/image_0116.png  \n",
            " extracting: test_images/image_0152.png  \n",
            " extracting: test_images/image_0161.png  \n",
            " extracting: test_images/image_0098.png  \n",
            " extracting: test_images/image_0080.png  \n",
            " extracting: test_images/image_0099.png  \n",
            " extracting: test_images/image_0093.png  \n",
            " extracting: test_images/image_0127.png  \n",
            " extracting: test_images/image_0078.png  \n",
            " extracting: test_images/image_0146.png  \n",
            " extracting: test_images/image_0095.png  \n",
            " extracting: test_images/image_0121.png  \n",
            " extracting: test_images/image_0129.png  \n",
            " extracting: test_images/image_0091.png  \n",
            " extracting: test_images/image_0101.png  \n",
            " extracting: test_images/image_0158.png  \n",
            " extracting: test_images/image_0105.png  \n",
            " extracting: test_images/image_0125.png  \n",
            " extracting: test_images/image_0082.png  \n",
            " extracting: test_images/image_0147.png  \n",
            " extracting: test_images/image_0085.png  \n",
            " extracting: test_images/image_0087.png  \n",
            " extracting: test_images/image_0139.png  \n",
            " extracting: test_images/image_0100.png  \n",
            " extracting: test_images/image_0119.png  \n",
            " extracting: test_images/image_0155.png  \n",
            " extracting: test_images/image_0120.png  \n",
            " extracting: test_images/image_0103.png  \n",
            " extracting: test_images/image_0134.png  \n",
            " extracting: test_images/image_0226.png  \n",
            " extracting: test_images/image_0237.png  \n",
            " extracting: test_images/image_0205.png  \n",
            " extracting: test_images/image_0186.png  \n",
            " extracting: test_images/image_0247.png  \n",
            " extracting: test_images/image_0229.png  \n",
            " extracting: test_images/image_0192.png  \n",
            " extracting: test_images/image_0180.png  \n",
            " extracting: test_images/image_0251.png  \n",
            " extracting: test_images/image_0253.png  \n",
            " extracting: test_images/image_0248.png  \n",
            " extracting: test_images/image_0172.png  \n",
            " extracting: test_images/image_0182.png  \n",
            " extracting: test_images/image_0185.png  \n",
            " extracting: test_images/image_0222.png  \n",
            " extracting: test_images/image_0223.png  \n",
            " extracting: test_images/image_0228.png  \n",
            " extracting: test_images/image_0173.png  \n",
            " extracting: test_images/image_0179.png  \n",
            " extracting: test_images/image_0245.png  \n",
            " extracting: test_images/image_0181.png  \n",
            " extracting: test_images/image_0190.png  \n",
            " extracting: test_images/image_0242.png  \n",
            " extracting: test_images/image_0176.png  \n",
            " extracting: test_images/image_0236.png  \n",
            " extracting: test_images/image_0175.png  \n",
            " extracting: test_images/image_0246.png  \n",
            " extracting: test_images/image_0211.png  \n",
            " extracting: test_images/image_0216.png  \n",
            " extracting: test_images/image_0177.png  \n",
            " extracting: test_images/image_0203.png  \n",
            " extracting: test_images/image_0215.png  \n",
            " extracting: test_images/image_0219.png  \n",
            " extracting: test_images/image_0197.png  \n",
            " extracting: test_images/image_0187.png  \n",
            " extracting: test_images/image_0238.png  \n",
            " extracting: test_images/image_0241.png  \n",
            " extracting: test_images/image_0252.png  \n",
            " extracting: test_images/image_0171.png  \n",
            " extracting: test_images/image_0189.png  \n",
            " extracting: test_images/image_0225.png  \n",
            " extracting: test_images/image_0191.png  \n",
            " extracting: test_images/image_0250.png  \n",
            " extracting: test_images/image_0249.png  \n",
            " extracting: test_images/image_0195.png  \n",
            " extracting: test_images/image_0244.png  \n",
            " extracting: test_images/image_0243.png  \n",
            " extracting: test_images/image_0218.png  \n",
            " extracting: test_images/image_0217.png  \n",
            " extracting: test_images/image_0210.png  \n",
            " extracting: test_images/image_0213.png  \n",
            " extracting: test_images/image_0178.png  \n",
            " extracting: test_images/image_0239.png  \n",
            " extracting: test_images/image_0199.png  \n",
            " extracting: test_images/image_0234.png  \n",
            " extracting: test_images/image_0168.png  \n",
            " extracting: test_images/image_0224.png  \n",
            " extracting: test_images/image_0204.png  \n",
            " extracting: test_images/image_0202.png  \n",
            " extracting: test_images/image_0170.png  \n",
            " extracting: test_images/image_0174.png  \n",
            " extracting: test_images/image_0232.png  \n",
            " extracting: test_images/image_0169.png  \n",
            " extracting: test_images/image_0212.png  \n",
            " extracting: test_images/image_0235.png  \n",
            " extracting: test_images/image_0166.png  \n",
            " extracting: test_images/image_0198.png  \n",
            " extracting: test_images/image_0193.png  \n",
            " extracting: test_images/image_0183.png  \n",
            " extracting: test_images/image_0184.png  \n",
            " extracting: test_images/image_0227.png  \n",
            " extracting: test_images/image_0201.png  \n",
            " extracting: test_images/image_0209.png  \n",
            " extracting: test_images/image_0196.png  \n",
            " extracting: test_images/image_0214.png  \n",
            " extracting: test_images/image_0233.png  \n",
            " extracting: test_images/image_0220.png  \n",
            " extracting: test_images/image_0240.png  \n",
            " extracting: test_images/image_0206.png  \n",
            " extracting: test_images/image_0207.png  \n",
            " extracting: test_images/image_0208.png  \n",
            " extracting: test_images/image_0200.png  \n",
            " extracting: test_images/image_0230.png  \n",
            " extracting: test_images/image_0221.png  \n",
            " extracting: test_images/image_0194.png  \n",
            " extracting: test_images/image_0231.png  \n",
            " extracting: test_images/image_0188.png  \n",
            " extracting: test_images/image_0167.png  \n",
            " extracting: test_images/image_0303.png  \n",
            " extracting: test_images/image_0334.png  \n",
            " extracting: test_images/image_0302.png  \n",
            " extracting: test_images/image_0273.png  \n",
            " extracting: test_images/image_0324.png  \n",
            " extracting: test_images/image_0301.png  \n",
            " extracting: test_images/image_0257.png  \n",
            " extracting: test_images/image_0313.png  \n",
            " extracting: test_images/image_0283.png  \n",
            " extracting: test_images/image_0287.png  \n",
            " extracting: test_images/image_0291.png  \n",
            " extracting: test_images/image_0256.png  \n",
            " extracting: test_images/image_0276.png  \n",
            " extracting: test_images/image_0333.png  \n",
            " extracting: test_images/image_0258.png  \n",
            " extracting: test_images/image_0285.png  \n",
            " extracting: test_images/image_0264.png  \n",
            " extracting: test_images/image_0279.png  \n",
            " extracting: test_images/image_0266.png  \n",
            " extracting: test_images/image_0306.png  \n",
            " extracting: test_images/image_0272.png  \n",
            " extracting: test_images/image_0323.png  \n",
            " extracting: test_images/image_0267.png  \n",
            " extracting: test_images/image_0263.png  \n",
            " extracting: test_images/image_0314.png  \n",
            " extracting: test_images/image_0261.png  \n",
            " extracting: test_images/image_0284.png  \n",
            " extracting: test_images/image_0296.png  \n",
            " extracting: test_images/image_0297.png  \n",
            " extracting: test_images/image_0329.png  \n",
            " extracting: test_images/image_0327.png  \n",
            " extracting: test_images/image_0270.png  \n",
            " extracting: test_images/image_0322.png  \n",
            " extracting: test_images/image_0294.png  \n",
            " extracting: test_images/image_0310.png  \n",
            " extracting: test_images/image_0281.png  \n",
            " extracting: test_images/image_0278.png  \n",
            " extracting: test_images/image_0305.png  \n",
            " extracting: test_images/image_0289.png  \n",
            " extracting: test_images/image_0269.png  \n",
            " extracting: test_images/image_0293.png  \n",
            " extracting: test_images/image_0318.png  \n",
            " extracting: test_images/image_0336.png  \n",
            " extracting: test_images/image_0308.png  \n",
            " extracting: test_images/image_0321.png  \n",
            " extracting: test_images/image_0335.png  \n",
            " extracting: test_images/image_0325.png  \n",
            " extracting: test_images/image_0268.png  \n",
            " extracting: test_images/image_0280.png  \n",
            " extracting: test_images/image_0298.png  \n",
            " extracting: test_images/image_0259.png  \n",
            " extracting: test_images/image_0282.png  \n",
            " extracting: test_images/image_0317.png  \n",
            " extracting: test_images/image_0328.png  \n",
            " extracting: test_images/image_0331.png  \n",
            " extracting: test_images/image_0315.png  \n",
            " extracting: test_images/image_0326.png  \n",
            " extracting: test_images/image_0255.png  \n",
            " extracting: test_images/image_0319.png  \n",
            " extracting: test_images/image_0300.png  \n",
            " extracting: test_images/image_0311.png  \n",
            " extracting: test_images/image_0286.png  \n",
            " extracting: test_images/image_0304.png  \n",
            " extracting: test_images/image_0320.png  \n",
            " extracting: test_images/image_0312.png  \n",
            " extracting: test_images/image_0277.png  \n",
            " extracting: test_images/image_0288.png  \n",
            " extracting: test_images/image_0265.png  \n",
            " extracting: test_images/image_0262.png  \n",
            " extracting: test_images/image_0307.png  \n",
            " extracting: test_images/image_0260.png  \n",
            " extracting: test_images/image_0292.png  \n",
            " extracting: test_images/image_0295.png  \n",
            " extracting: test_images/image_0309.png  \n",
            " extracting: test_images/image_0330.png  \n",
            " extracting: test_images/image_0290.png  \n",
            " extracting: test_images/image_0274.png  \n",
            " extracting: test_images/image_0316.png  \n",
            " extracting: test_images/image_0332.png  \n",
            " extracting: test_images/image_0271.png  \n",
            " extracting: test_images/image_0254.png  \n",
            " extracting: test_images/image_0275.png  \n",
            " extracting: test_images/image_0299.png  \n",
            " extracting: test_images/image_0341.png  \n",
            " extracting: test_images/image_0350.png  \n",
            " extracting: test_images/image_0408.png  \n",
            " extracting: test_images/image_0391.png  \n",
            " extracting: test_images/image_0379.png  \n",
            " extracting: test_images/image_0398.png  \n",
            " extracting: test_images/image_0386.png  \n",
            " extracting: test_images/image_0406.png  \n",
            " extracting: test_images/image_0403.png  \n",
            " extracting: test_images/image_0347.png  \n",
            " extracting: test_images/image_0370.png  \n",
            " extracting: test_images/image_0359.png  \n",
            " extracting: test_images/image_0399.png  \n",
            " extracting: test_images/image_0367.png  \n",
            " extracting: test_images/image_0344.png  \n",
            " extracting: test_images/image_0411.png  \n",
            " extracting: test_images/image_0390.png  \n",
            " extracting: test_images/image_0415.png  \n",
            " extracting: test_images/image_0357.png  \n",
            " extracting: test_images/image_0371.png  \n",
            " extracting: test_images/image_0385.png  \n",
            " extracting: test_images/image_0383.png  \n",
            " extracting: test_images/image_0368.png  \n",
            " extracting: test_images/image_0338.png  \n",
            " extracting: test_images/image_0395.png  \n",
            " extracting: test_images/image_0409.png  \n",
            " extracting: test_images/image_0340.png  \n",
            " extracting: test_images/image_0346.png  \n",
            " extracting: test_images/image_0361.png  \n",
            " extracting: test_images/image_0380.png  \n",
            " extracting: test_images/image_0364.png  \n",
            " extracting: test_images/image_0414.png  \n",
            " extracting: test_images/image_0397.png  \n",
            " extracting: test_images/image_0354.png  \n",
            " extracting: test_images/image_0356.png  \n",
            " extracting: test_images/image_0349.png  \n",
            " extracting: test_images/image_0405.png  \n",
            " extracting: test_images/image_0400.png  \n",
            " extracting: test_images/image_0339.png  \n",
            " extracting: test_images/image_0382.png  \n",
            " extracting: test_images/image_0401.png  \n",
            " extracting: test_images/image_0365.png  \n",
            " extracting: test_images/image_0376.png  \n",
            " extracting: test_images/image_0378.png  \n",
            " extracting: test_images/image_0362.png  \n",
            " extracting: test_images/image_0388.png  \n",
            " extracting: test_images/image_0389.png  \n",
            " extracting: test_images/image_0374.png  \n",
            " extracting: test_images/image_0410.png  \n",
            " extracting: test_images/image_0363.png  \n",
            " extracting: test_images/image_0393.png  \n",
            " extracting: test_images/image_0360.png  \n",
            " extracting: test_images/image_0342.png  \n",
            " extracting: test_images/image_0381.png  \n",
            " extracting: test_images/image_0372.png  \n",
            " extracting: test_images/image_0377.png  \n",
            " extracting: test_images/image_0384.png  \n",
            " extracting: test_images/image_0407.png  \n",
            " extracting: test_images/image_0348.png  \n",
            " extracting: test_images/image_0416.png  \n",
            " extracting: test_images/image_0412.png  \n",
            " extracting: test_images/image_0413.png  \n",
            " extracting: test_images/image_0343.png  \n",
            " extracting: test_images/image_0352.png  \n",
            " extracting: test_images/image_0355.png  \n",
            " extracting: test_images/image_0387.png  \n",
            " extracting: test_images/image_0337.png  \n",
            " extracting: test_images/image_0345.png  \n",
            " extracting: test_images/image_0396.png  \n",
            " extracting: test_images/image_0375.png  \n",
            " extracting: test_images/image_0404.png  \n",
            " extracting: test_images/image_0418.png  \n",
            " extracting: test_images/image_0419.png  \n",
            " extracting: test_images/image_0394.png  \n",
            " extracting: test_images/image_0358.png  \n",
            " extracting: test_images/image_0369.png  \n",
            " extracting: test_images/image_0353.png  \n",
            " extracting: test_images/image_0392.png  \n",
            " extracting: test_images/image_0366.png  \n",
            " extracting: test_images/image_0373.png  \n",
            " extracting: test_images/image_0417.png  \n",
            " extracting: test_images/image_0351.png  \n",
            " extracting: test_images/image_0402.png  \n",
            " extracting: test_images/image_0442.png  \n",
            " extracting: test_images/image_0448.png  \n",
            " extracting: test_images/image_0464.png  \n",
            " extracting: test_images/image_0480.png  \n",
            " extracting: test_images/image_0427.png  \n",
            " extracting: test_images/image_0456.png  \n",
            " extracting: test_images/image_0421.png  \n",
            " extracting: test_images/image_0422.png  \n",
            " extracting: test_images/image_0446.png  \n",
            " extracting: test_images/image_0433.png  \n",
            " extracting: test_images/image_0469.png  \n",
            " extracting: test_images/image_0494.png  \n",
            " extracting: test_images/image_0462.png  \n",
            " extracting: test_images/image_0440.png  \n",
            " extracting: test_images/image_0479.png  \n",
            " extracting: test_images/image_0434.png  \n",
            " extracting: test_images/image_0468.png  \n",
            " extracting: test_images/image_0449.png  \n",
            " extracting: test_images/image_0444.png  \n",
            " extracting: test_images/image_0445.png  \n",
            " extracting: test_images/image_0452.png  \n",
            " extracting: test_images/image_0447.png  \n",
            " extracting: test_images/image_0453.png  \n",
            " extracting: test_images/image_0499.png  \n",
            " extracting: test_images/image_0482.png  \n",
            " extracting: test_images/image_0481.png  \n",
            " extracting: test_images/image_0492.png  \n",
            " extracting: test_images/image_0498.png  \n",
            " extracting: test_images/image_0426.png  \n",
            " extracting: test_images/image_0475.png  \n",
            " extracting: test_images/image_0476.png  \n",
            " extracting: test_images/image_0488.png  \n",
            " extracting: test_images/image_0493.png  \n",
            " extracting: test_images/image_0486.png  \n",
            " extracting: test_images/image_0455.png  \n",
            " extracting: test_images/image_0428.png  \n",
            " extracting: test_images/image_0450.png  \n",
            " extracting: test_images/image_0489.png  \n",
            " extracting: test_images/image_0420.png  \n",
            " extracting: test_images/image_0472.png  \n",
            " extracting: test_images/image_0461.png  \n",
            " extracting: test_images/image_0439.png  \n",
            " extracting: test_images/image_0443.png  \n",
            " extracting: test_images/image_0431.png  \n",
            " extracting: test_images/image_0477.png  \n",
            " extracting: test_images/image_0497.png  \n",
            " extracting: test_images/image_0478.png  \n",
            " extracting: test_images/image_0463.png  \n",
            " extracting: test_images/image_0490.png  \n",
            " extracting: test_images/image_0423.png  \n",
            " extracting: test_images/image_0437.png  \n",
            " extracting: test_images/image_0467.png  \n",
            " extracting: test_images/image_0460.png  \n",
            " extracting: test_images/image_0495.png  \n",
            " extracting: test_images/image_0466.png  \n",
            " extracting: test_images/image_0487.png  \n",
            " extracting: test_images/image_0432.png  \n",
            " extracting: test_images/image_0474.png  \n",
            " extracting: test_images/image_0457.png  \n",
            " extracting: test_images/image_0438.png  \n",
            " extracting: test_images/image_0454.png  \n",
            " extracting: test_images/image_0424.png  \n",
            " extracting: test_images/image_0436.png  \n",
            " extracting: test_images/image_0485.png  \n",
            " extracting: test_images/image_0484.png  \n",
            " extracting: test_images/image_0435.png  \n",
            " extracting: test_images/image_0441.png  \n",
            " extracting: test_images/image_0491.png  \n",
            " extracting: test_images/image_0451.png  \n",
            " extracting: test_images/image_0458.png  \n",
            " extracting: test_images/image_0429.png  \n",
            " extracting: test_images/image_0470.png  \n",
            " extracting: test_images/image_0471.png  \n",
            " extracting: test_images/image_0430.png  \n",
            " extracting: test_images/image_0473.png  \n",
            " extracting: test_images/image_0459.png  \n",
            " extracting: test_images/image_0465.png  \n",
            " extracting: test_images/image_0496.png  \n",
            " extracting: test_images/image_0483.png  \n",
            " extracting: test_images/image_0425.png  \n",
            " extracting: test_images/image_0571.png  \n",
            " extracting: test_images/image_0547.png  \n",
            " extracting: test_images/image_0578.png  \n",
            " extracting: test_images/image_0573.png  \n",
            " extracting: test_images/image_0560.png  \n",
            " extracting: test_images/image_0526.png  \n",
            " extracting: test_images/image_0561.png  \n",
            " extracting: test_images/image_0518.png  \n",
            " extracting: test_images/image_0576.png  \n",
            " extracting: test_images/image_0503.png  \n",
            " extracting: test_images/image_0532.png  \n",
            " extracting: test_images/image_0577.png  \n",
            " extracting: test_images/image_0544.png  \n",
            " extracting: test_images/image_0513.png  \n",
            " extracting: test_images/image_0519.png  \n",
            " extracting: test_images/image_0539.png  \n",
            " extracting: test_images/image_0579.png  \n",
            " extracting: test_images/image_0558.png  \n",
            " extracting: test_images/image_0564.png  \n",
            " extracting: test_images/image_0548.png  \n",
            " extracting: test_images/image_0566.png  \n",
            " extracting: test_images/image_0502.png  \n",
            " extracting: test_images/image_0534.png  \n",
            " extracting: test_images/image_0543.png  \n",
            " extracting: test_images/image_0575.png  \n",
            " extracting: test_images/image_0530.png  \n",
            " extracting: test_images/image_0563.png  \n",
            " extracting: test_images/image_0500.png  \n",
            " extracting: test_images/image_0528.png  \n",
            " extracting: test_images/image_0515.png  \n",
            " extracting: test_images/image_0505.png  \n",
            " extracting: test_images/image_0533.png  \n",
            " extracting: test_images/image_0550.png  \n",
            " extracting: test_images/image_0553.png  \n",
            " extracting: test_images/image_0554.png  \n",
            " extracting: test_images/image_0567.png  \n",
            " extracting: test_images/image_0531.png  \n",
            " extracting: test_images/image_0512.png  \n",
            " extracting: test_images/image_0535.png  \n",
            " extracting: test_images/image_0569.png  \n",
            " extracting: test_images/image_0565.png  \n",
            " extracting: test_images/image_0523.png  \n",
            " extracting: test_images/image_0524.png  \n",
            " extracting: test_images/image_0520.png  \n",
            " extracting: test_images/image_0572.png  \n",
            " extracting: test_images/image_0581.png  \n",
            " extracting: test_images/image_0540.png  \n",
            " extracting: test_images/image_0538.png  \n",
            " extracting: test_images/image_0551.png  \n",
            " extracting: test_images/image_0574.png  \n",
            " extracting: test_images/image_0507.png  \n",
            " extracting: test_images/image_0508.png  \n",
            " extracting: test_images/image_0568.png  \n",
            " extracting: test_images/image_0514.png  \n",
            " extracting: test_images/image_0545.png  \n",
            " extracting: test_images/image_0516.png  \n",
            " extracting: test_images/image_0536.png  \n",
            " extracting: test_images/image_0552.png  \n",
            " extracting: test_images/image_0570.png  \n",
            " extracting: test_images/image_0510.png  \n",
            " extracting: test_images/image_0580.png  \n",
            " extracting: test_images/image_0549.png  \n",
            " extracting: test_images/image_0525.png  \n",
            " extracting: test_images/image_0542.png  \n",
            " extracting: test_images/image_0511.png  \n",
            " extracting: test_images/image_0541.png  \n",
            " extracting: test_images/image_0546.png  \n",
            " extracting: test_images/image_0506.png  \n",
            " extracting: test_images/image_0559.png  \n",
            " extracting: test_images/image_0555.png  \n",
            " extracting: test_images/image_0537.png  \n",
            " extracting: test_images/image_0557.png  \n",
            " extracting: test_images/image_0522.png  \n",
            " extracting: test_images/image_0556.png  \n",
            " extracting: test_images/image_0521.png  \n",
            " extracting: test_images/image_0509.png  \n",
            " extracting: test_images/image_0527.png  \n",
            " extracting: test_images/image_0517.png  \n",
            " extracting: test_images/image_0562.png  \n",
            " extracting: test_images/image_0529.png  \n",
            " extracting: test_images/image_0504.png  \n",
            " extracting: test_images/image_0501.png  \n",
            " extracting: test_images/image_0639.png  \n",
            " extracting: test_images/image_0583.png  \n",
            " extracting: test_images/image_0613.png  \n",
            " extracting: test_images/image_0584.png  \n",
            " extracting: test_images/image_0622.png  \n",
            " extracting: test_images/image_0662.png  \n",
            " extracting: test_images/image_0635.png  \n",
            " extracting: test_images/image_0586.png  \n",
            " extracting: test_images/image_0610.png  \n",
            " extracting: test_images/image_0628.png  \n",
            " extracting: test_images/image_0601.png  \n",
            " extracting: test_images/image_0603.png  \n",
            " extracting: test_images/image_0594.png  \n",
            " extracting: test_images/image_0653.png  \n",
            " extracting: test_images/image_0632.png  \n",
            " extracting: test_images/image_0615.png  \n",
            " extracting: test_images/image_0585.png  \n",
            " extracting: test_images/image_0587.png  \n",
            "Archive:  drive/MyDrive/Brainhack/suspects.zip\n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0609.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0610.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0615.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0635.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0634.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0631.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0651.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0648.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0627.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0636.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0658.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0640.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0601.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0666.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0606.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0639.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0591.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0595.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0623.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0626.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0597.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0589.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0638.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0643.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0590.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0625.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0605.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0621.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0664.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0616.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0584.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0644.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0645.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0596.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0662.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0602.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0592.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0611.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0585.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0632.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0622.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0661.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0613.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0583.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0656.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0649.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0655.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0608.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0646.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0614.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0587.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0594.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0665.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0599.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0593.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0642.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0581.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0660.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0618.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0588.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0633.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0582.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0617.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0624.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0604.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0653.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0663.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0714.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0676.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0744.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0739.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0673.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0750.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0736.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0715.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0696.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0677.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0718.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0724.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0747.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0699.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0694.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0707.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0716.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0713.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0688.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0698.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0675.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0687.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0672.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0735.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0705.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0704.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0689.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0751.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0727.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0746.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0711.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0685.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0680.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0690.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0725.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0721.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0745.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0742.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0684.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0710.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0692.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0740.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0726.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0733.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0706.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0743.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0693.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0683.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0700.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0691.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0697.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0723.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0720.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0741.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0671.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0748.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0737.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0682.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0701.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0670.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0668.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0712.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0678.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0728.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0695.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0719.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0708.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0702.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0730.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0674.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0669.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0679.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0686.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0717.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0681.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0738.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0709.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0703.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0729.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0749.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0667.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0722.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0734.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0732.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0731.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0759.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0804.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0788.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0765.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0762.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0814.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0810.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0830.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0819.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0779.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0758.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0803.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0755.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0770.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0834.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0822.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0785.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0753.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0769.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0821.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0761.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0818.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0808.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0771.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0772.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0817.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0837.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0826.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0777.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0794.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0789.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0836.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0809.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0766.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0798.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0831.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0775.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0767.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0757.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0823.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0782.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0813.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0827.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0784.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0787.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0754.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0838.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0807.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0812.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0774.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0791.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0816.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0802.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0786.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0805.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0800.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0790.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0801.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0768.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0824.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0760.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0835.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0764.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0783.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0811.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0799.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0832.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0833.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0795.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0793.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0778.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0773.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0825.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0815.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0828.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0780.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0806.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0763.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0776.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0796.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0781.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0752.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0756.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0829.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0797.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0792.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0820.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0923.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0859.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0874.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0915.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0858.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0840.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0918.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0867.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0889.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0909.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0847.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0892.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0871.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0884.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0878.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0890.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0862.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0907.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0911.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0903.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0885.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0888.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0916.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0873.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0899.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0853.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0866.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0860.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0856.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0900.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0851.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0880.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0891.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0883.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0839.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0881.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0901.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0876.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0912.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0906.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0846.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0921.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0865.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0863.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0872.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0896.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0917.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0848.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0905.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0898.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0904.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0852.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0850.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0845.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0902.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0879.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0861.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0855.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0869.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0843.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0857.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0841.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0910.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0919.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0908.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0897.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0920.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0842.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0844.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0913.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0870.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0864.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0868.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0877.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0894.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0886.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0914.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0893.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0875.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0895.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0922.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0849.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0854.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0882.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0887.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0927.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0994.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0942.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0971.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0940.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0950.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0972.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0995.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0978.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0984.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0947.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0931.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0979.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0986.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0939.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0996.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0967.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0966.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0988.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0936.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0962.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0987.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0970.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0974.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0933.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0965.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0937.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0954.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0985.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0960.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0926.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0982.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1009.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0951.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0961.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0976.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0945.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1010.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0934.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0938.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1001.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1006.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0952.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0963.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0948.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1003.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0955.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0969.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0956.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0946.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0989.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0944.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0999.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1002.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1007.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0929.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0953.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0993.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0983.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0968.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0958.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0928.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0949.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0992.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0959.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1004.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0997.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0943.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0991.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0981.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0935.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0990.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0975.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0925.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1005.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0998.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0964.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1000.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1008.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0973.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0957.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0980.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0941.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0932.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0930.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0924.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0977.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1089.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1032.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1015.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1055.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1083.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1036.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1034.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1054.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1085.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1056.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1068.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1096.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1073.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1029.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1037.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1017.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1087.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1095.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1019.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1077.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1069.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1092.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1022.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1048.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1014.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1040.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1059.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1064.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1093.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1044.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1094.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1012.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1062.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1051.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1046.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1057.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1052.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1072.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1038.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1035.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1061.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1021.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1030.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1060.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1063.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1070.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1091.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1049.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1080.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1020.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1045.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1071.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1065.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1090.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1031.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1028.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1081.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1043.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1078.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1084.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1053.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1047.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1097.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1024.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1025.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1066.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1026.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1033.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1016.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1041.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1011.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1018.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1039.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1027.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1058.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1079.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1086.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1082.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1013.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1067.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1088.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1050.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1023.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1076.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1042.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1074.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1075.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1149.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1166.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1153.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1184.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1145.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1138.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1173.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1137.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1178.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1161.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1119.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1131.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1120.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1104.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1118.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1128.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1162.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1134.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1121.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1106.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1170.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1160.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1139.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1142.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1144.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1125.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1127.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1133.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1108.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1126.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1114.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1113.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1107.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1099.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1152.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1167.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1102.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1141.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1115.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1168.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1116.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1180.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1140.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1148.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1129.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1117.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1109.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1172.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1103.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1179.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1177.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1143.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1185.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1130.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1112.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1155.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1175.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1124.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1132.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1158.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1159.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1174.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1163.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1183.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1105.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1154.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1164.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1171.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1156.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1146.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1110.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1182.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1135.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1181.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1098.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1150.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1100.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1123.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1157.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1111.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1176.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1151.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1101.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1122.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1169.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1165.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1147.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1136.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1215.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1250.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1246.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1235.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1205.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1226.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1196.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1200.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1210.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1190.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1197.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1188.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1230.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1259.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1267.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1217.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1249.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1224.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1186.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1222.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1206.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1221.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1251.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1201.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1240.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1261.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1199.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1191.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1202.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1220.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1241.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1253.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1252.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1218.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1219.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1257.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1243.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1213.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1265.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1229.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1239.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1273.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1189.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1262.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1216.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1238.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1271.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1266.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1194.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1242.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1255.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1193.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1212.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1269.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1225.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1187.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1203.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1198.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1234.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1270.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1254.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1233.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1258.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1207.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1264.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1245.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1209.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1244.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1211.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1237.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1231.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1223.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1256.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1192.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1228.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1248.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1214.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1272.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1232.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1236.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1208.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1204.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1195.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1227.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1274.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1260.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1268.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1263.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1247.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1305.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1301.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1364.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1327.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1282.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1346.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1361.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1315.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1340.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1310.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1358.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1365.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1311.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1353.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1281.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1287.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1330.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1352.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1360.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1341.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1350.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1337.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1298.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1307.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1283.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1295.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1359.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1312.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1306.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1349.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1304.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1280.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1297.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1326.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1357.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1338.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1284.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1313.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1354.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1322.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1363.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1323.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1320.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1344.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1286.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1290.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1275.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1288.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1317.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1355.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1328.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1279.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1336.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1339.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1292.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1302.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1335.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1299.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1300.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1278.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1277.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1347.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1324.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1343.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1303.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1342.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1321.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1356.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1276.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1329.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1319.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1294.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1314.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1289.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1334.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1325.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1316.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1331.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1291.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1309.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1332.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1293.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1296.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1333.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1362.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1308.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1351.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1345.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1348.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1285.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1318.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1450.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1379.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1401.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1400.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1388.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1422.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1418.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1392.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1432.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1402.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1397.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1393.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1406.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1387.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1398.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1411.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1428.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1417.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1399.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1380.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1394.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1434.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1442.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1419.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1421.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1369.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1446.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1440.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1415.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1381.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1367.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1452.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1389.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1385.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1390.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1435.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1437.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1454.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1416.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1436.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1423.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1405.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1409.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1448.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1368.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1443.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1396.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1371.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1425.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1410.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1395.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1412.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1404.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1370.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1429.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1377.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1439.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1383.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1376.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1420.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1408.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1386.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1449.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1403.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1431.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1391.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1424.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1455.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1366.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1444.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1374.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1372.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1414.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1384.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1378.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1433.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1427.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1373.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1430.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1426.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1445.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1447.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1453.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1451.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1413.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1382.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1441.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1407.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1375.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1438.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1474.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1503.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1535.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1522.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1481.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1512.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1459.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1493.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1518.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1472.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1538.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1516.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1521.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1517.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1492.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1502.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1546.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1515.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1544.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1482.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1514.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1509.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1483.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1532.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1530.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1465.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1462.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1525.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1499.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1488.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1460.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1476.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1540.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1500.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1524.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1471.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1501.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1480.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1523.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1463.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1520.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1534.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1529.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1473.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1467.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1533.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1485.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1491.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1496.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1542.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1477.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1545.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1487.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1504.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1541.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1497.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1494.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1470.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1486.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1531.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1468.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1495.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1539.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1458.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1475.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1519.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1456.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1526.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1479.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1527.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1537.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1513.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1489.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1536.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1547.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1484.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1469.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1461.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1511.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1510.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1506.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1507.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1466.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1457.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1528.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1505.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1508.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1490.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1464.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1498.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1543.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1478.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1576.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1556.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1589.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1566.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1593.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1552.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1599.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1551.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1550.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1587.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1555.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1563.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1597.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1570.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1559.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1573.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1592.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1561.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1581.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1574.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1569.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1598.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1565.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1579.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1575.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1577.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1572.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1586.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1591.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1596.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1590.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1571.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1567.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1560.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1553.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1564.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1548.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1582.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1580.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1585.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1557.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1578.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1568.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1583.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1554.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1588.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1595.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1558.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1549.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1594.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1584.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_1562.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0066.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0046.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0014.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0004.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0050.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0070.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0013.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0055.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0060.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0028.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0048.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0052.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0024.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0017.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0062.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0034.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0069.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0065.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0037.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0057.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0006.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0074.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0030.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0009.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0000.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0021.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0056.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0033.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0040.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0029.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0003.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0064.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0071.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0019.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0038.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0067.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0043.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0061.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0036.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0026.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0025.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0058.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0054.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0035.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0049.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0041.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0020.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0012.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0051.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0015.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0053.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0045.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0022.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0063.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0008.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0073.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0001.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0018.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0005.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0039.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0075.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0068.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0059.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0011.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0032.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0023.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0007.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0076.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0010.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0047.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0072.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0042.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0044.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0016.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0031.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0002.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0027.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0081.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0155.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0110.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0107.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0141.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0082.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0111.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0122.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0089.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0152.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0083.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0119.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0084.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0147.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0142.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0163.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0099.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0080.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0149.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0097.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0112.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0130.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0144.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0123.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0156.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0115.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0114.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0164.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0087.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0145.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0128.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0160.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0103.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0134.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0146.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0132.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0121.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0125.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0135.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0093.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0105.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0108.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0140.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0127.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0104.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0101.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0077.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0139.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0154.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0117.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0100.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0161.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0118.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0079.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0109.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0133.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0113.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0129.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0137.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0136.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0157.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0148.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0162.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0138.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0078.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0106.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0131.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0090.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0153.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0116.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0143.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0120.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0091.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0150.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0151.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0096.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0098.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0086.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0088.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0085.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0159.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0095.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0094.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0102.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0126.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0124.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0092.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0158.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0206.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0165.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0177.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0243.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0212.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0187.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0169.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0222.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0234.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0195.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0200.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0240.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0233.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0189.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0219.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0174.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0185.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0220.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0175.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0190.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0227.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0218.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0252.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0193.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0250.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0204.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0246.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0214.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0191.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0172.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0170.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0183.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0181.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0238.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0216.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0248.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0230.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0239.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0202.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0236.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0241.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0217.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0211.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0198.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0237.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0242.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0180.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0166.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0229.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0225.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0226.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0205.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0197.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0223.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0203.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0199.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0249.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0179.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0245.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0232.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0213.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0247.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0221.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0251.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0231.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0173.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0188.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0192.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0228.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0182.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0178.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0224.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0194.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0196.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0184.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0171.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0168.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0244.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0201.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0176.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0207.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0235.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0167.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0208.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0209.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0215.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0210.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0186.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0289.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0329.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0325.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0303.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0266.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0271.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0328.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0293.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0265.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0295.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0313.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0310.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0254.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0330.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0301.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0272.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0274.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0297.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0311.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0263.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0264.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0270.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0323.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0308.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0312.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0282.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0260.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0273.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0257.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0284.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0317.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0316.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0290.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0291.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0262.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0280.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0300.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0268.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0319.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0305.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0267.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0256.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0277.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0287.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0298.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0285.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0321.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0326.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0306.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0275.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0253.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0296.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0334.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0261.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0269.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0332.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0327.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0259.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0302.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0283.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0307.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0279.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0276.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0292.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0255.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0294.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0288.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0309.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0278.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0335.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0318.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0324.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0258.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0281.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0299.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0320.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0314.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0333.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0315.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0322.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0331.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0304.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0286.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0344.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0393.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0340.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0342.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0388.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0387.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0385.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0336.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0351.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0367.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0400.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0411.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0417.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0375.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0349.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0380.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0372.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0379.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0359.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0353.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0398.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0384.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0338.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0390.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0389.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0415.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0358.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0381.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0368.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0412.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0343.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0356.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0392.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0391.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0364.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0346.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0376.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0365.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0363.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0374.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0408.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0405.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0395.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0361.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0413.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0345.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0402.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0407.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0348.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0403.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0352.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0416.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0410.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0339.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0369.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0406.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0409.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0382.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0347.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0370.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0414.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0377.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0373.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0354.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0362.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0394.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0366.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0360.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0341.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0337.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0418.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0357.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0371.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0350.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0386.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0383.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0397.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0399.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0355.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0401.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0404.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0396.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0378.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0435.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0430.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0424.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0437.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0474.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0463.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0491.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0445.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0448.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0464.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0472.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0454.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0486.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0440.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0451.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0476.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0422.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0436.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0477.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0428.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0421.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0443.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0419.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0485.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0498.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0431.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0441.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0458.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0462.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0495.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0490.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0434.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0487.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0461.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0439.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0468.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0483.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0426.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0447.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0469.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0484.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0481.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0470.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0420.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0457.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0453.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0456.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0429.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0467.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0450.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0444.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0449.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0475.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0494.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0432.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0496.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0473.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0452.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0446.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0488.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0455.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0465.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0492.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0489.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0471.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0482.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0423.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0442.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0497.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0478.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0493.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0438.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0425.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0480.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0479.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0427.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0459.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0460.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0466.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0433.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0569.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0535.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0532.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0575.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0501.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0523.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0562.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0555.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0519.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0541.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0556.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0534.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0580.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0515.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0533.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0529.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0514.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0563.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0571.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0554.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0510.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0509.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0516.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0573.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0543.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0508.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0559.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0530.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0528.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0538.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0561.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0504.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0577.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0576.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0578.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0542.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0565.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0521.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0560.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0570.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0568.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0537.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0525.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0567.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0566.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0502.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0526.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0548.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0503.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0564.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0522.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0552.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0507.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0505.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0550.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0506.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0545.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0512.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0513.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0579.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0547.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0511.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0524.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0500.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0553.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0499.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0558.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0518.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0539.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0520.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0540.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0517.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0546.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0549.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0527.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0551.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0531.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0536.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0574.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0544.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0557.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0572.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0620.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0647.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0619.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0600.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0657.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0607.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0659.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0630.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0641.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0650.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0654.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0612.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0603.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0637.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0586.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0628.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0598.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0652.png  \n",
            " extracting: suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops/image_0629.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4242442f",
      "metadata": {
        "scrolled": true,
        "id": "4242442f"
      },
      "outputs": [],
      "source": [
        "train_images_path = '/content/train_images'\n",
        "train_labels_path = '/content/train_labels'\n",
        "val_images_path = '/content/val_images'\n",
        "val_labels_path = '/content/val_labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "447ef3d3-5633-4e42-8338-d5548b9a2be8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:32:23.742953+00:00",
          "start_time": "2023-05-27T06:32:21.720327+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "447ef3d3-5633-4e42-8338-d5548b9a2be8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3e61e4b7-b6b2-4c6b-9410-be08d359d9e2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:32:24.746973+00:00",
          "start_time": "2023-05-27T06:32:24.588152+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "3e61e4b7-b6b2-4c6b-9410-be08d359d9e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_crops_path = \"train_crops\"\n",
        "num_plushies = 200\n",
        "os.mkdir(train_crops_path)\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    os.mkdir(os.path.join(train_crops_path, str(i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4f20bf6c-08d8-49f9-802d-caa2ae0a1c1f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:32:24.906286+00:00",
          "start_time": "2023-05-27T06:32:24.751827+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "4f20bf6c-08d8-49f9-802d-caa2ae0a1c1f"
      },
      "outputs": [],
      "source": [
        "val_crops_path = \"val_crops\"\n",
        "num_plushies = 10\n",
        "os.mkdir(val_crops_path)\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    os.mkdir(os.path.join(val_crops_path, str(i)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crop the plushie from images using bounding boxes\n"
      ],
      "metadata": {
        "id": "xxWYyUjSpGPO"
      },
      "id": "xxWYyUjSpGPO"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7b9cbf99-f1cb-4e41-8c0c-09d325ce58c3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:34:41.764256+00:00",
          "start_time": "2023-05-27T06:32:24.910936+00:00"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "7b9cbf99-f1cb-4e41-8c0c-09d325ce58c3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "images_path = train_images_path\n",
        "labels_path = train_labels_path\n",
        "annotated_images_path = train_crops_path\n",
        "\n",
        "\n",
        "for label_name in os.listdir(labels_path):\n",
        "    if label_name[-4:] != \".txt\":\n",
        "        continue\n",
        "    image_name = label_name[:-4] + \".png\"\n",
        "    # print(\"Checking\", image_name)\n",
        "\n",
        "    image_path = os.path.join(images_path, image_name)\n",
        "    label_path = os.path.join(labels_path, label_name)\n",
        "\n",
        "    df = pd.read_csv(label_path, delim_whitespace=True, header=None)\n",
        "    df.columns = [\"cat\", \"xc\", \"yc\", \"w\", \"h\"]\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        bb = df.iloc[i]\n",
        "        cat = str(int(bb[\"cat\"]))\n",
        "        tl = (int((bb[\"xc\"] - bb[\"w\"]/2) * img_w), int((bb[\"yc\"] - bb[\"h\"]/2) * img_h))\n",
        "        br = (int((bb[\"xc\"] + bb[\"w\"]/2) * img_w), int((bb[\"yc\"] + bb[\"h\"]/2) * img_h))\n",
        "\n",
        "        cropped_img = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "        annotated_img_name = f\"{cat}_{len(os.listdir(os.path.join(annotated_images_path, cat)))}.png\"\n",
        "        cv2.imwrite(os.path.join(annotated_images_path, cat, annotated_img_name), cropped_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "36c1f6c3-f5fc-4007-aa30-36af6bb15aa4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:35:00.615721+00:00",
          "start_time": "2023-05-27T06:34:41.773843+00:00"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "36c1f6c3-f5fc-4007-aa30-36af6bb15aa4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "images_path = val_images_path\n",
        "labels_path = val_labels_path\n",
        "annotated_images_path = val_crops_path\n",
        "\n",
        "\n",
        "for label_name in os.listdir(labels_path):\n",
        "    if label_name[-4:] != \".txt\":\n",
        "        continue\n",
        "    image_name = label_name[:-4] + \".png\"\n",
        "#     print(\"Checking\", image_name)\n",
        "\n",
        "    image_path = os.path.join(images_path, image_name)\n",
        "    label_path = os.path.join(labels_path, label_name)\n",
        "\n",
        "    df = pd.read_csv(label_path, delim_whitespace=True, header=None)\n",
        "    df.columns = [\"cat\", \"xc\", \"yc\", \"w\", \"h\"]\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "        bb = df.iloc[i]\n",
        "        cat = str(int(bb[\"cat\"]))\n",
        "        tl = (int((bb[\"xc\"] - bb[\"w\"]/2) * img_w), int((bb[\"yc\"] - bb[\"h\"]/2) * img_h))\n",
        "        br = (int((bb[\"xc\"] + bb[\"w\"]/2) * img_w), int((bb[\"yc\"] + bb[\"h\"]/2) * img_h))\n",
        "\n",
        "        cropped_img = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "        annotated_img_name = f\"{cat}_{len(os.listdir(os.path.join(annotated_images_path, cat)))}.png\"\n",
        "        cv2.imwrite(os.path.join(annotated_images_path, cat, annotated_img_name), cropped_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3f9101f9-54ac-466f-828e-c6e86b122834",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:35:01.038225+00:00",
          "start_time": "2023-05-27T06:35:00.621233+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "3f9101f9-54ac-466f-828e-c6e86b122834",
        "outputId": "11a74dc6-a39c-4e53-c153-f6f6f91b31f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa521d7ba60>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "image = cv2.imread(f'{train_crops_path}/0/0_22.png')\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating LFW file format for labelling matches and mismatches"
      ],
      "metadata": {
        "id": "hSLq4chzpcfU"
      },
      "id": "hSLq4chzpcfU"
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')"
      ],
      "metadata": {
        "id": "h7qAJ_tDJ3Eg"
      },
      "id": "h7qAJ_tDJ3Eg",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8bb56f3d-5b20-4dd7-8b81-0804600ac5ae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:45:59.971639+00:00",
          "start_time": "2023-05-27T06:45:59.646716+00:00"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": false,
        "id": "8bb56f3d-5b20-4dd7-8b81-0804600ac5ae",
        "outputId": "e3c8d011-ba96-4261-af2f-18ac5a10b07c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 67, 1: 65, 2: 66, 3: 65, 4: 65, 5: 65, 6: 61, 7: 66, 8: 66, 9: 64, 10: 66, 11: 65, 12: 65, 13: 64, 14: 66, 15: 65, 16: 66, 17: 65, 18: 66, 19: 65, 20: 65, 21: 66, 22: 65, 23: 66, 24: 65, 25: 65, 26: 65, 27: 65, 28: 64, 29: 65, 30: 65, 31: 65, 32: 65, 33: 66, 34: 66, 35: 65, 36: 65, 37: 65, 38: 65, 39: 65, 40: 65, 41: 64, 42: 65, 43: 65, 44: 66, 45: 65, 46: 66, 47: 63, 48: 66, 49: 65, 50: 65, 51: 65, 52: 64, 53: 66, 54: 65, 55: 66, 56: 66, 57: 65, 58: 65, 59: 65, 60: 65, 61: 63, 62: 65, 63: 64, 64: 65, 65: 65, 66: 66, 67: 66, 68: 65, 69: 65, 70: 66, 71: 66, 72: 66, 73: 65, 74: 63, 75: 64, 76: 65, 77: 65, 78: 65, 79: 63, 80: 63, 81: 64, 82: 64, 83: 63, 84: 64, 85: 64, 86: 64, 87: 56, 88: 56, 89: 56, 90: 58, 91: 62, 92: 62, 93: 58, 94: 65, 95: 63, 96: 57, 97: 61, 98: 61, 99: 56, 100: 60, 101: 56, 102: 61, 103: 60, 104: 57, 105: 61, 106: 60, 107: 54, 108: 57, 109: 59, 110: 60, 111: 56, 112: 57, 113: 60, 114: 55, 115: 56, 116: 56, 117: 61, 118: 57, 119: 57, 120: 57, 121: 56, 122: 56, 123: 55, 124: 59, 125: 59, 126: 59, 127: 56, 128: 60, 129: 67, 130: 58, 131: 62, 132: 59, 133: 58, 134: 56, 135: 58, 136: 59, 137: 64, 138: 58, 139: 57, 140: 56, 141: 59, 142: 57, 143: 62, 144: 60, 145: 60, 146: 60, 147: 61, 148: 63, 149: 61, 150: 60, 151: 59, 152: 59, 153: 60, 154: 61, 155: 59, 156: 56, 157: 57, 158: 61, 159: 59, 160: 60, 161: 59, 162: 63, 163: 59, 164: 54, 165: 59, 166: 62, 167: 57, 168: 58, 169: 59, 170: 59, 171: 61, 172: 60, 173: 56, 174: 58, 175: 61, 176: 61, 177: 60, 178: 62, 179: 59, 180: 60, 181: 58, 182: 58, 183: 58, 184: 59, 185: 59, 186: 60, 187: 59, 188: 59, 189: 59, 190: 61, 191: 61, 192: 59, 193: 59, 194: 61, 195: 57, 196: 63, 197: 62, 198: 59, 199: 58}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "counts = {}\n",
        "\n",
        "crops_path = train_crops_path\n",
        "num_plushies = 200\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    counts[i] = len(os.listdir(os.path.join(crops_path, str(i))))\n",
        "print(counts)\n",
        "\n",
        "lines = []\n",
        "\n",
        "def add_match(plushie, num1, num2):\n",
        "    line = f\"{plushie} {num1} {num2}\\n\"\n",
        "    lines.append(line)\n",
        "\n",
        "def add_mismatch(plushie1, num1, plushie2, num2):\n",
        "    line = f\"{plushie1} {num1} {plushie2} {num2}\\n\"\n",
        "    lines.append(line)\n",
        "\n",
        "#hyperparameter\n",
        "len_data = 100000\n",
        "\n",
        "for i in range(len_data):\n",
        "    # print(i)\n",
        "    plushie = random.choice(list(counts.keys()))\n",
        "\n",
        "    num1, num2 = random.randrange(counts[plushie]), random.randrange(counts[plushie])\n",
        "\n",
        "    while not (os.path.exists(f\"{crops_path}/{plushie}/{plushie}_{num1}.png\") and os.path.exists(f\"{crops_path}/{plushie}/{plushie}_{num2}.png\")):\n",
        "        print(num1, num2, plushie)\n",
        "        num1, num2 = random.randrange(counts[plushie]), random.randrange(counts[plushie])\n",
        "    \n",
        "    add_match(plushie, num1, num2)\n",
        "\n",
        "for i in range(len_data):\n",
        "    # print(i)\n",
        "    plushie1, plushie2 = random.choice(list(counts.keys())), random.choice(list(counts.keys()))\n",
        "    while plushie1 == plushie2:\n",
        "        plushie1, plushie2 = random.choice(list(counts.keys())), random.choice(list(counts.keys()))\n",
        "\n",
        "    num1, num2 = random.randrange(counts[plushie1]), random.randrange(counts[plushie2])\n",
        "                              \n",
        "                              \n",
        "    while not (os.path.exists(f\"{crops_path}/{plushie1}/{plushie1}_{num1}.png\") and os.path.exists(f\"{crops_path}/{plushie2}/{plushie2}_{num2}.png\")):\n",
        "        num1, num2 = random.randrange(counts[plushie1]), random.randrange(counts[plushie2])\n",
        "\n",
        "    add_mismatch(plushie1, num1, plushie2, num2)\n",
        "\n",
        "\n",
        "f = open(\"plushie_pairs_train.txt\", \"a\")\n",
        "f.writelines(lines)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0c96ee6a-4912-408c-b4bc-a2541a874049",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:46:00.382694+00:00",
          "start_time": "2023-05-27T06:46:00.207054+00:00"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": false,
        "id": "0c96ee6a-4912-408c-b4bc-a2541a874049",
        "outputId": "0d4efe51-5263-465b-d1df-93d506f90029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 179, 1: 177, 2: 169, 3: 163, 4: 163, 5: 163, 6: 166, 7: 169, 8: 173, 9: 177}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "counts = {}\n",
        "\n",
        "crops_path = val_crops_path\n",
        "num_plushies = 10\n",
        "\n",
        "for i in range(num_plushies):\n",
        "    counts[i] = len(os.listdir(os.path.join(crops_path, str(i))))\n",
        "print(counts)\n",
        "\n",
        "lines = []\n",
        "\n",
        "def add_match(plushie, num1, num2):\n",
        "    line = f\"{plushie} {num1} {num2}\\n\"\n",
        "    lines.append(line)\n",
        "\n",
        "def add_mismatch(plushie1, num1, plushie2, num2):\n",
        "    line = f\"{plushie1} {num1} {plushie2} {num2}\\n\"\n",
        "    lines.append(line)\n",
        "\n",
        "len_data = 4000\n",
        "\n",
        "for i in range(len_data):\n",
        "    # print(i)\n",
        "    plushie = random.choice(list(counts.keys()))\n",
        "\n",
        "    num1, num2 = random.randrange(counts[plushie]), random.randrange(counts[plushie])\n",
        "\n",
        "    while not (os.path.exists(f\"{crops_path}/{plushie}/{plushie}_{num1}.png\") and os.path.exists(f\"{crops_path}/{plushie}/{plushie}_{num2}.png\")):\n",
        "        print(num1, num2, plushie)\n",
        "        num1, num2 = random.randrange(counts[plushie]), random.randrange(counts[plushie])\n",
        "    \n",
        "    add_match(plushie, num1, num2)\n",
        "\n",
        "for i in range(len_data):\n",
        "    # print(i)\n",
        "    plushie1, plushie2 = random.choice(list(counts.keys())), random.choice(list(counts.keys()))\n",
        "    while plushie1 == plushie2:\n",
        "        plushie1, plushie2 = random.choice(list(counts.keys())), random.choice(list(counts.keys()))\n",
        "\n",
        "    num1, num2 = random.randrange(counts[plushie1]), random.randrange(counts[plushie2])\n",
        "                              \n",
        "                              \n",
        "    while not (os.path.exists(f\"{crops_path}/{plushie1}/{plushie1}_{num1}.png\") and os.path.exists(f\"{crops_path}/{plushie2}/{plushie2}_{num2}.png\")):\n",
        "        num1, num2 = random.randrange(counts[plushie1]), random.randrange(counts[plushie2])\n",
        "\n",
        "    add_mismatch(plushie1, num1, plushie2, num2)\n",
        "\n",
        "\n",
        "f = open(\"plushie_pairs_val.txt\", \"a\")\n",
        "f.writelines(lines)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Function"
      ],
      "metadata": {
        "id": "OPzk5PVzpuId"
      },
      "id": "OPzk5PVzpuId"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "41a3a7f1-5ad9-435d-82c3-6c45a4f8b2b3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:35:09.330471+00:00",
          "start_time": "2023-05-27T06:35:05.236864+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "41a3a7f1-5ad9-435d-82c3-6c45a4f8b2b3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "    \n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "def show_img(img1, img2):\n",
        "    axs = plt.figure(figsize=(9, 9)).subplots(1, 2)\n",
        "    axs[0].imshow(img1)\n",
        "    axs[1].imshow(img2)\n",
        "\n",
        "\n",
        "def accuracy(preds, labels):\n",
        "    preds = torch.flatten(preds)\n",
        "    return torch.sum(preds == labels).item() / len(labels)\n",
        "\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch, self.device)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforming the Data\n",
        "Resizing the images and preprocessing"
      ],
      "metadata": {
        "id": "3lgwxv8Kp2YF"
      },
      "id": "3lgwxv8Kp2YF"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "71d1f11c-1224-4adc-8e80-34cc168a6d66",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:35:09.808349+00:00",
          "start_time": "2023-05-27T06:35:09.342982+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "71d1f11c-1224-4adc-8e80-34cc168a6d66"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as tt\n",
        "import cv2\n",
        "\n",
        "class BGR2RGB:\n",
        "    def __call__(self, image):\n",
        "        #image = image.numpy()\n",
        "        #print(f'type of image {type(image)}')\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #image = torch.from_numpy(image)\n",
        "        return image\n",
        "\n",
        "class SquarePad:\n",
        "    def __call__(self, image):\n",
        "        max_wh = max(image.shape[:2])\n",
        "        p_left, p_top = [(max_wh - s) // 2 for s in image.shape[:2]]\n",
        "        p_right, p_bottom = [max_wh - (s+pad) for s, pad in zip(image.shape[:2], [p_left, p_top])]\n",
        "        return cv2.copyMakeBorder(image, p_top, p_bottom, p_left, p_right, cv2.BORDER_CONSTANT, None, value = 0)\n",
        "\n",
        "\n",
        "class Resize():\n",
        "    def __init__(self, output_size=(128, 128)):\n",
        "        assert isinstance(output_size, (tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return cv2.resize(image, self.output_size, interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "class Transforms:\n",
        "    def __init__(self):\n",
        "        self.transform = tt.Compose([BGR2RGB(), \n",
        "                        SquarePad(),\n",
        "                        Resize((128, 128)),\n",
        "                        tt.ToTensor(),\n",
        "                        tt.Normalize(0, 0.5)])\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return self.transform(image)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "90d6e29e-d2b0-4459-83ae-1d253943b995",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:35:10.177037+00:00",
          "start_time": "2023-05-27T06:35:10.011603+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "90d6e29e-d2b0-4459-83ae-1d253943b995"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch import cat\n",
        "import torch.nn as nn\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "        https://github.com/pytorch/examples/tree/main/siamese_network\n",
        "\n",
        "        BCE Loss\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.resnet = resnet50(ResNet50_Weights.DEFAULT)\n",
        "\n",
        "        for ct, child in enumerate(self.resnet.children()):\n",
        "            if ct < 6:\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "\n",
        "        self.fc_in_features = self.resnet.fc.in_features\n",
        "        \n",
        "        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n",
        "        self.resnet = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
        "\n",
        "        # add linear layers to compare between the features of the two images\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.fc_in_features, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(256, 1) #MIGHT WANT A MORE COMPLEX VECTOR OUTPUT\n",
        "        )\n",
        "\n",
        "\n",
        "    def get_embeddings(self, x):\n",
        "        output = self.resnet(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.get_embeddings(input1)\n",
        "        output1 = self.fc(output1)\n",
        "        output2 = self.get_embeddings(input2)\n",
        "        output2 = self.fc(output2)\n",
        "        #output = cat((output1, output2), 1)\n",
        "        #output = self.fc(output) #the output of the Siamese Network is a number;\n",
        "        \n",
        "        #return output\n",
        "        return output1, output2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b1e7ab9c-014b-4549-80fe-a93ed7a4d9e3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T06:37:42.923396+00:00",
          "start_time": "2023-05-27T06:37:42.762780+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "b1e7ab9c-014b-4549-80fe-a93ed7a4d9e3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PlushieTrainDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, filepath, img_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(filepath, 'r') as f:\n",
        "            self.samples = [line.strip() for line in f]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        line = self.samples[i].split()\n",
        "        if len(line) == 3:\n",
        "            anchor_name, anchor_num, img_num = line\n",
        "            img_name = anchor_name\n",
        "            is_same = 1\n",
        "        elif len(line) == 4:\n",
        "            anchor_name, anchor_num, img_name, img_num = line\n",
        "            is_same = 0\n",
        "        else:\n",
        "            print(len(line), line)\n",
        "            raise Exception(\"Shouldn't be here\")\n",
        "        \n",
        "        anchor = cv2.imread(os.path.join(self.img_dir, str(anchor_name), f\"{anchor_name}_{anchor_num}.png\"))\n",
        "        img = cv2.imread(os.path.join(self.img_dir, img_name, f\"{img_name}_{img_num}.png\"))\n",
        "        \n",
        "        if self.transform:\n",
        "            anchor = self.transform(anchor)\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return anchor, img, is_same\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803bc3dd-8e08-443e-b84a-29d326589a06",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-27T07:04:05.796053+00:00",
          "start_time": "2023-05-27T06:46:09.283083+00:00"
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "803bc3dd-8e08-443e-b84a-29d326589a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96acee76-3032-4748-b964-20f731ed7493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of Train set is 220000\n",
            "The length of Valid set is 8800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss1.0208708047866821\n",
            "train loss0.8026964068412781\n",
            "train loss0.9821345806121826\n",
            "train loss0.9910008907318115\n",
            "train loss0.8615889549255371\n",
            "train loss0.8358803987503052\n",
            "train loss0.9298862814903259\n",
            "train loss0.8257873058319092\n",
            "train loss0.8619333505630493\n",
            "train loss0.8269936442375183\n",
            "train loss0.7334035634994507\n",
            "train loss0.7972760796546936\n",
            "train loss0.7761545181274414\n",
            "train loss0.6960749626159668\n",
            "train loss0.7498217225074768\n",
            "train loss0.7066737413406372\n",
            "train loss0.7191591858863831\n",
            "train loss0.7246407866477966\n",
            "train loss0.7108304500579834\n",
            "train loss0.688705563545227\n",
            "train loss0.6758736371994019\n",
            "train loss0.6634073257446289\n",
            "train loss0.692176342010498\n",
            "train loss0.6477144956588745\n",
            "train loss0.6821483373641968\n",
            "train loss0.6726230382919312\n",
            "train loss0.6829608678817749\n",
            "train loss0.6514483690261841\n",
            "train loss0.700623631477356\n",
            "train loss0.7228531837463379\n",
            "train loss0.6941549777984619\n",
            "train loss0.730628252029419\n",
            "train loss0.6358623504638672\n",
            "train loss0.7182101607322693\n",
            "train loss0.678227424621582\n",
            "train loss0.6545014381408691\n",
            "train loss0.6559913754463196\n",
            "train loss0.6888755559921265\n",
            "train loss0.6669049263000488\n",
            "train loss0.6377002000808716\n",
            "train loss0.6885745525360107\n",
            "train loss0.6905288100242615\n",
            "train loss0.7043030261993408\n",
            "train loss0.6876640319824219\n",
            "train loss0.727664589881897\n",
            "train loss0.6865637302398682\n",
            "train loss0.7253341674804688\n",
            "train loss0.6581087708473206\n",
            "train loss0.6518378257751465\n",
            "train loss0.6788269877433777\n",
            "train loss0.6756571531295776\n",
            "train loss0.6853662729263306\n",
            "train loss0.6440463066101074\n",
            "train loss0.678491473197937\n",
            "train loss0.709080696105957\n",
            "train loss0.6732473969459534\n",
            "train loss0.6796095967292786\n",
            "train loss0.6396540999412537\n",
            "train loss0.7144246101379395\n",
            "train loss0.705096960067749\n",
            "train loss0.7107243537902832\n",
            "train loss0.7203325033187866\n",
            "train loss0.6977783441543579\n",
            "train loss0.666394054889679\n",
            "train loss0.7109187841415405\n",
            "train loss0.653224527835846\n",
            "train loss0.6885114908218384\n",
            "train loss0.6874598264694214\n",
            "train loss0.6525617837905884\n",
            "train loss0.6846017241477966\n",
            "train loss0.7098662853240967\n",
            "train loss0.6592023968696594\n",
            "train loss0.7006697058677673\n",
            "train loss0.683012843132019\n",
            "train loss0.6929339170455933\n",
            "train loss0.6545772552490234\n",
            "train loss0.6975952386856079\n",
            "train loss0.6562516689300537\n",
            "train loss0.7145350575447083\n",
            "train loss0.655656635761261\n",
            "train loss0.6580808162689209\n",
            "train loss0.7062062621116638\n",
            "train loss0.683732271194458\n",
            "train loss0.6585603952407837\n",
            "train loss0.660457968711853\n",
            "train loss0.6588360071182251\n",
            "train loss0.7009388208389282\n",
            "train loss0.6914055347442627\n",
            "train loss0.6919880509376526\n",
            "train loss0.6309454441070557\n",
            "train loss0.6862508654594421\n",
            "train loss0.6914077401161194\n",
            "train loss0.667662501335144\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def infer(model, img, target, transform = None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    #print(f'type of img: {type(img)}')\n",
        "    #print(f'shape of output1 {img.shape} and output2 {target.shape}')\n",
        "    if transform is not None:\n",
        "      output1, output2 = transform(img).unsqueeze(0), transform(target).unsqueeze(0)\n",
        "    else:\n",
        "      output1, output2 = img, target\n",
        "    #generate the embedding vectors using loaded model\n",
        "    #print(f'after transform: shape of output1 {output1.shape} and output2 {output2.shape}') #SHOULD GET (256,3,128,128)\n",
        "    output1,output2 = model(output1.to(device),output2.to(device)) \n",
        "    #print(f'after model: shape of output1 {output1.shape} and output2 {output2.shape}')\n",
        "    #calculating euclidean distance and determining if match\n",
        "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "    #print(f'euclidean disatnce {euclidean_distance}')\n",
        "    pred = torch.Tensor(np.array([1 if dist < 1 else 0 for dist in euclidean_distance]))\n",
        "    #pred = (1 if abs(euclidean_distance) < 1 else 0) #1 for suspect, 0 for non-suspect\n",
        "    #print(f'prediciton {pred}')\n",
        "    return pred, euclidean_distance\n",
        "\n",
        "\n",
        "\n",
        "def loss_batch(model, loss_func, anchor, image, label, opt=None, metric=None): # Update model weights and return metrics given xb, yb, model\n",
        "    #ANCHOR SHAPE IS (256,3,128,128)\n",
        "    preds = model(anchor, image) #RETURNS (2, 256) -> EACH DATA HAS ONE INTEGER OUTPUT\n",
        "    #print(f'model prediction {preds[0].shape} and {preds[1].shape}')\n",
        "    loss = loss_func(preds[0], preds[1], label.unsqueeze(1).float()) #the loss function compares the output number of the network to the label #made a change here\n",
        "    # loss = loss_func(preds, label.unsqueeze(1).float())\n",
        "    #print(f'anchor cpu{anchor.cpu().numpy()}')\n",
        "    result, _ = infer(model, anchor, image, None) #ISSUE -> RESULT IS AN INTEGER, MIGHT BE DUE TO NUMPY CONVERSION\n",
        "    result = result.cuda()\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        \n",
        "    metric_result = None\n",
        "    if metric is not None:\n",
        "        #print(f'results {result}') #ISSUE WITH RESULT -> RESULT IS AN INTEGER\n",
        "        metric_result = metric(result, label)\n",
        "        \n",
        "    return loss.item(), len(anchor), metric_result\n",
        "\n",
        "\n",
        "def fit(epochs, model, loss_func, train_dl, val_dl, opt_func=torch.optim.SGD, lr=0.01, metric=None):\n",
        "    train_losses, val_losses, val_metrics = [] , [], []\n",
        "    \n",
        "    opt = opt_func(model.parameters(), lr=lr)\n",
        "    \n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train() # Setting for pytorch - training mode\n",
        "        for anchor,image,label in train_dl:\n",
        "            #print(f'anchor type {type(anchor)}')\n",
        "            #print(f'train_dl label shape {label.shape}') # Checking the label shape\n",
        "            #print(f'anchor shape {anchor.shape}')\n",
        "            train_loss, _, _ = loss_batch(model, loss_func, anchor, image, label, opt) # update weights\n",
        "            train_losses.append(train_loss)\n",
        "            print(f'train loss{train_loss}')\n",
        "            \n",
        "        model.eval() # Setting - eval mode\n",
        "        val_loss, total, val_metric = evaluate(model, loss_func, val_dl, metric)\n",
        "        \n",
        "        \n",
        "        val_losses.append(val_loss)\n",
        "        val_metrics.append(val_metric)\n",
        "        \n",
        "        if metric is None:\n",
        "            print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(\n",
        "            epoch, train_loss, val_loss))\n",
        "        else:\n",
        "            print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_{}: {:.4f}\".format(\n",
        "            epoch, train_loss, val_loss, metric.__name__, val_metric))\n",
        "            \n",
        "    return train_losses, val_losses, val_metrics\n",
        "\n",
        "\n",
        "def evaluate(model, loss_func, val_dl, metric=None):\n",
        "    with torch.no_grad():\n",
        "        results = [loss_batch(model, loss_func, anchor, image, label, metric=metric) for anchor, image, label in val_dl]\n",
        "        \n",
        "        losses, nums, metrics = zip(*results)\n",
        "        total = np.sum(nums)\n",
        "        \n",
        "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
        "        \n",
        "        avg_metric = None\n",
        "        if metric is not None:\n",
        "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
        "            \n",
        "        print(f'validation loss {avg_loss}')\n",
        "        \n",
        "        return avg_loss, total, avg_metric\n",
        "\n",
        "\n",
        "\n",
        "train_filepath = \"plushie_pairs_train.txt\"\n",
        "train_img_dir = train_crops_path\n",
        "val_filepath = \"plushie_pairs_val.txt\"\n",
        "val_img_dir = val_crops_path\n",
        "train_bs = 256\n",
        "test_bs = 8\n",
        "num_epochs = 5\n",
        "lr = 0.0001\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "transform = Transforms()\n",
        "train_dataset = PlushieTrainDataset(filepath=train_filepath, img_dir=train_img_dir, transform=transform)\n",
        "valid_dataset = PlushieTrainDataset(filepath=val_filepath, img_dir=val_img_dir, transform=transform)\n",
        "network = SiameseNetwork()\n",
        "\n",
        "\n",
        "print(\"The length of Train set is {}\".format(len(train_dataset)))\n",
        "print(\"The length of Valid set is {}\".format(len(valid_dataset)))\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=train_bs, shuffle=True, num_workers=4)\n",
        "val_dl = torch.utils.data.DataLoader(valid_dataset, batch_size=test_bs, shuffle=True, num_workers=4)\n",
        "\n",
        "device = get_default_device()\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(network, device)\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        #print(f'euclidean dist shape {euclidean_distance.shape}')\n",
        "        loss_contrastive = torch.mean((label) * 0.5 * torch.pow(euclidean_distance, 2) +\n",
        "                                      (1 - label) * 0.5 * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        #print(f'cont loss shape {loss_contrastive.shape}')\n",
        "        return loss_contrastive\n",
        "\n",
        "#criterion = torch.nn.BCEWithLogitsLoss()\n",
        "criterion = ContrastiveLoss()\n",
        "optimizer = torch.optim.Adam\n",
        "\n",
        "\n",
        "train_losses, val_losses, val_metrics = fit(num_epochs, network, criterion, \n",
        "                                        train_dl, val_dl, optimizer, lr, accuracy)\n",
        "\n",
        "torch.save(network.state_dict(), '/content/drive/MyDrive/Brainhack/reid2_model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(len(train_losses))\n",
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "qIqBIoxhHgk-",
        "outputId": "6c100963-d9a0-4b3a-fc0a-f6862690c731"
      },
      "id": "qIqBIoxhHgk-",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa18b897190>]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating on Test Set"
      ],
      "metadata": {
        "id": "jtQVMIDpcHDQ"
      },
      "id": "jtQVMIDpcHDQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Brainhack')"
      ],
      "metadata": {
        "id": "pGnS12mXcSaR"
      },
      "id": "pGnS12mXcSaR",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "Ywo14zYFcdBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea05ebe-df2b-4c21-d33a-faf10ee1c566"
      },
      "id": "Ywo14zYFcdBu",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.111-py3-none-any.whl (592 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m592.5/592.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: ultralytics\n",
            "Successfully installed ultralytics-8.0.111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import csv\n",
        "import pandas as pd\n",
        "import gdown\n",
        "#from reID.model import SiameseNetwork\n",
        "#from reID.inference import infer\n",
        "#from reID.transforms import Transforms\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "yolo_url = \"https://drive.google.com/file/d/1-YNxQ1EORYLcKVnKC1V5GZSB6aov0Ivn/view?usp=sharing\"\n",
        "yolo_output = \"best.pt\"\n",
        "#gdown.download( yolo_url, yolo_output, quiet=False)\n",
        "yolo_model = YOLO('/content/drive/MyDrive/Brainhack/OD_model2.pt') #loading trained YOLO\n",
        "\n",
        "reid_model = network\n",
        "\n",
        "''' if loading from local\n",
        "reid_model = SiameseNetwork()\n",
        "reid_url = \"https://drive.google.com/file/d/1MSUtLHjFWsUU6KIoI59C1fl-DmpSRU27/view?usp=sharing\"\n",
        "reid_output = \"/content/drive/MyDrive/Brainhack/reid_model.pt\" #loading trained reID\n",
        "#gdown.download(reid_url, reid_output, quiet=False)\n",
        "reid_model.load_state_dict(torch.load(reid_output))\n",
        "reid_model.cuda()\n",
        "'''\n",
        "submission_list = []\n",
        "test_dir = \"/content/test_images\"\n",
        "suspect_dir = \"/content/suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops\"\n",
        "\n",
        "def detect(image_name):\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    #print(image_name)\n",
        "    image_path = os.path.join(test_dir, image_name)\n",
        "    suspect_path = os.path.join(suspect_dir, image_name)\n",
        "    objects_detected = []\n",
        "    #print(suspect_path)\n",
        "    img = cv2.imread(image_path)\n",
        "    #print(f'hi {type(img)}')\n",
        "    suspect = cv2.imread(suspect_path)\n",
        "    #print(img)\n",
        "    #suspect = Image.fromarray(suspect)\n",
        "    results = yolo_model(img)\n",
        "    #print(f'results {results[0]}')\n",
        "    boxes = results[0].boxes\n",
        "    \n",
        "\n",
        "    for box in boxes:\n",
        "      #t = Transforms()\n",
        "      confidence = box.conf.tolist() #confidence level\n",
        "      x1n,y1n,x2n,y2n = torch.squeeze(box.xyxyn).tolist()\n",
        "      x1,y1,x2,y2 = torch.squeeze(box.xyxy).tolist()\n",
        "      # [[1,2], [2,3]] -> (2,2)\n",
        "      #print(int(x1),int(y1),int(x2),y2)\n",
        "      plushie = img[int(y1):int(y2), int(x1):int(x2)] \n",
        "      \n",
        "      #plushie = Image.fromarray(plushie)\n",
        "      \n",
        "      #print(type(suspect))\n",
        "      \n",
        "      #print(plushie.shape())           \n",
        "      classification, _ = infer(reid_model, plushie, suspect, transform)\n",
        "      objects_detected.append({'Image_ID': image_name[:-4], 'class': classification.item(), 'confidence': confidence[0], 'ymin':y1n, 'xmin':x1n, 'ymax':y2n, 'xmax':x2n })\n",
        "    return objects_detected\n",
        "\n",
        "\n",
        "for image in os.listdir(test_dir):\n",
        "        submit = detect(image)\n",
        "        for obj in submit:\n",
        "            submission_list.append(obj)\n",
        "\n",
        "submission_df = pd.DataFrame(submission_list)\n",
        "submission_df.to_csv('submission2.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "# with open('', 'w', newline='') as f:\n",
        "#     writer = csv.writer(f)"
      ],
      "metadata": {
        "id": "F0NFp8quch_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edea8984-b230-4816-91b6-780c65b0623a"
      },
      "id": "F0NFp8quch_D",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 384x640 3 toys, 27.1ms\n",
            "Speed: 1.7ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 2.3ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.3ms\n",
            "Speed: 2.0ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.6ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.8ms\n",
            "Speed: 1.8ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.6ms\n",
            "Speed: 1.8ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.6ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.0ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.7ms\n",
            "Speed: 2.6ms preprocess, 26.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.7ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.5ms\n",
            "Speed: 1.9ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 3.0ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.8ms\n",
            "Speed: 2.0ms preprocess, 26.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.9ms\n",
            "Speed: 2.2ms preprocess, 26.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.3ms\n",
            "Speed: 2.8ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.3ms\n",
            "Speed: 2.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.5ms\n",
            "Speed: 1.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 2.4ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.8ms\n",
            "Speed: 2.1ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.4ms\n",
            "Speed: 1.9ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.3ms\n",
            "Speed: 2.2ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 3.7ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.7ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 2.1ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.6ms\n",
            "Speed: 2.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.5ms preprocess, 26.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.6ms\n",
            "Speed: 2.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.8ms\n",
            "Speed: 1.8ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 5.7ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 2.8ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 29.2ms\n",
            "Speed: 1.9ms preprocess, 29.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.3ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 3.5ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.6ms\n",
            "Speed: 1.9ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.7ms\n",
            "Speed: 3.9ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.7ms\n",
            "Speed: 2.3ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.7ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.1ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 6.3ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.9ms\n",
            "Speed: 1.8ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.9ms\n",
            "Speed: 1.8ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 4.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.7ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 1.7ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.9ms\n",
            "Speed: 2.0ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 3.2ms preprocess, 26.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.0ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.7ms\n",
            "Speed: 2.3ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 2.9ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.2ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.6ms\n",
            "Speed: 1.9ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.8ms\n",
            "Speed: 2.3ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.8ms\n",
            "Speed: 2.1ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 29.9ms\n",
            "Speed: 1.9ms preprocess, 29.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.6ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.7ms\n",
            "Speed: 1.9ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 30.6ms\n",
            "Speed: 5.6ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.4ms\n",
            "Speed: 1.9ms preprocess, 26.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 3.2ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.5ms\n",
            "Speed: 2.9ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.3ms\n",
            "Speed: 1.9ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 2.0ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 7.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 3.2ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 2.7ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 27.6ms\n",
            "Speed: 1.9ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.2ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.5ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.3ms\n",
            "Speed: 1.9ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 2.1ms preprocess, 26.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 3.3ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.6ms\n",
            "Speed: 1.7ms preprocess, 26.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 4.0ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 3.7ms preprocess, 25.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.7ms\n",
            "Speed: 2.6ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 5.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.7ms\n",
            "Speed: 2.6ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 2.3ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.9ms\n",
            "Speed: 1.8ms preprocess, 26.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.7ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.3ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 4.5ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.1ms\n",
            "Speed: 1.9ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.8ms\n",
            "Speed: 2.0ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.5ms preprocess, 25.8ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 3.8ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.8ms\n",
            "Speed: 3.1ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.5ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 2.0ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.0ms\n",
            "Speed: 2.2ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.4ms\n",
            "Speed: 1.9ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.7ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.4ms\n",
            "Speed: 1.9ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.8ms\n",
            "Speed: 1.9ms preprocess, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 2.1ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.6ms\n",
            "Speed: 2.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 6.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.5ms\n",
            "Speed: 1.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.5ms\n",
            "Speed: 2.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 5.2ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.1ms\n",
            "Speed: 2.0ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.7ms\n",
            "Speed: 2.1ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.9ms\n",
            "Speed: 2.6ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.4ms\n",
            "Speed: 2.1ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.0ms\n",
            "Speed: 2.6ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 5.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 3.1ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 4 toys, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.8ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.3ms\n",
            "Speed: 1.9ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 2.2ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 5.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 3.3ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 3.0ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.7ms\n",
            "Speed: 2.5ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.5ms\n",
            "Speed: 1.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.9ms\n",
            "Speed: 2.0ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.7ms\n",
            "Speed: 2.1ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.4ms\n",
            "Speed: 2.2ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.3ms\n",
            "Speed: 2.3ms preprocess, 27.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.9ms\n",
            "Speed: 1.8ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.7ms\n",
            "Speed: 2.0ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.9ms\n",
            "Speed: 2.5ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 4.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.2ms\n",
            "Speed: 2.0ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 1.7ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.3ms\n",
            "Speed: 1.9ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 5.2ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.6ms\n",
            "Speed: 2.1ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.3ms\n",
            "Speed: 1.8ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.3ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 5.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 4.7ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 3.0ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.6ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.9ms\n",
            "Speed: 2.5ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 5.5ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 27.4ms\n",
            "Speed: 1.9ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.7ms\n",
            "Speed: 2.0ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 27.8ms\n",
            "Speed: 1.8ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.0ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.4ms\n",
            "Speed: 2.5ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 32.5ms\n",
            "Speed: 2.0ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 3.0ms preprocess, 26.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.5ms\n",
            "Speed: 2.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 27.2ms\n",
            "Speed: 2.1ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.7ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.3ms preprocess, 25.8ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 2.4ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 4.5ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 46.8ms\n",
            "Speed: 3.0ms preprocess, 46.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.7ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 29.8ms\n",
            "Speed: 1.9ms preprocess, 29.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 1.8ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 5.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.6ms\n",
            "Speed: 2.0ms preprocess, 27.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.5ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 1.9ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.5ms\n",
            "Speed: 2.0ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.1ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.1ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.3ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 5.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 5.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 9.0ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.4ms\n",
            "Speed: 2.5ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.8ms\n",
            "Speed: 2.1ms preprocess, 26.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.4ms\n",
            "Speed: 2.2ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 2.2ms preprocess, 26.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 2.5ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 3.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.3ms\n",
            "Speed: 2.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 29.4ms\n",
            "Speed: 2.2ms preprocess, 29.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.8ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 2.5ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 3.6ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.5ms\n",
            "Speed: 1.8ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 27.0ms\n",
            "Speed: 1.9ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 3.7ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 4.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.7ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.9ms\n",
            "Speed: 2.3ms preprocess, 26.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 6.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 3.1ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.9ms\n",
            "Speed: 2.4ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 6.8ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.7ms\n",
            "Speed: 1.9ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.2ms\n",
            "Speed: 2.3ms preprocess, 26.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.7ms\n",
            "Speed: 2.4ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.6ms\n",
            "Speed: 1.9ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.7ms\n",
            "Speed: 7.2ms preprocess, 25.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.7ms\n",
            "Speed: 2.0ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 28.7ms\n",
            "Speed: 2.0ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 1.9ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 28.2ms\n",
            "Speed: 1.9ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.9ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.3ms\n",
            "Speed: 2.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.7ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.4ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.2ms\n",
            "Speed: 2.3ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 4.7ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.4ms\n",
            "Speed: 2.1ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 27.3ms\n",
            "Speed: 2.2ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 6.5ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 27.1ms\n",
            "Speed: 1.9ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.7ms\n",
            "Speed: 1.8ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.5ms\n",
            "Speed: 2.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.5ms\n",
            "Speed: 2.0ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.5ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 26.6ms\n",
            "Speed: 1.9ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 6.6ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.2ms\n",
            "Speed: 2.5ms preprocess, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.0ms\n",
            "Speed: 2.5ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.4ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.7ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 26.0ms\n",
            "Speed: 2.2ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.0ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.6ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 2.4ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 26.1ms\n",
            "Speed: 2.0ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 2.8ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 1 toy, 25.8ms\n",
            "Speed: 3.0ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 2 toys, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.9ms\n",
            "Speed: 2.8ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 384x640 3 toys, 25.8ms\n",
            "Speed: 2.5ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BOILERPLATE CODE"
      ],
      "metadata": {
        "id": "oR7zAYGQcipe"
      },
      "id": "oR7zAYGQcipe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27186b6f",
      "metadata": {
        "scrolled": true,
        "id": "27186b6f"
      },
      "outputs": [],
      "source": [
        "def predict_image(model, target, img, transform=None, device=torch.device('cpu')):\n",
        "    xb, xb2 = transform(target).unsqueeze(0), transform(img).unsqueeze(0) # Convert to batch of 1\n",
        "    model.eval()\n",
        "    yb = model(xb.to(device), xb2.to(device))\n",
        "    return yb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "jygWMymfp_oY"
      },
      "id": "jygWMymfp_oY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "ixn2vqEWqEMH"
      },
      "id": "ixn2vqEWqEMH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec1ddc4-5262-4f7d-bb46-0b1a98dd13e0",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        },
        "scrolled": true,
        "id": "3ec1ddc4-5262-4f7d-bb46-0b1a98dd13e0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "bb_ann = {\"Image_ID\": [], \"class\": [], \"confidence\": [], \"ymin\": [], \"xmin\": [], \n",
        "          \"ymax\": [], \"xmax\": []}\n",
        "\n",
        "\n",
        "yolo_repo_path = 'yolov5'\n",
        "yolo_model_path = '/content/drive/MyDrive/BH/best.pt'\n",
        "reid_model_path = \"/content/drive/MyDrive/BH/model.pth\"\n",
        "\n",
        "yolo_model = torch.hub.load(yolo_repo_path, 'custom', path=yolo_model_path, source='local')\n",
        "\n",
        "reid_model = SiameseNetwork()\n",
        "reid_model.load_state_dict(torch.load(reid_model_path, map_location=torch.device('cuda')))\n",
        "\n",
        "test_dir = \"test_images\"\n",
        "suspect_dir = \"suspects/content/drive/Shareddrives/ZINDI Data Science/ADPL/Competition Data/CV/Data Prep/Test (0-1599)/merged/crops\"\n",
        "\n",
        "reid_transforms = Transforms()\n",
        "\n",
        "def detect_objects(image_name):\n",
        "    image_path = os.path.join(test_dir, image_name)\n",
        "    suspect_path = os.path.join(suspect_dir, image_name)\n",
        "\n",
        "    img = cv2.imread(image_path)\n",
        "    suspect = cv2.imread(suspect_path)\n",
        "    \n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    # Perform object detection\n",
        "    results = yolo_model(img)\n",
        "\n",
        "    # Print the detected objects with their classes, confidence scores, and bounding box coordinates\n",
        "    for result in results.xyxy[0].tolist():\n",
        "        class_id = int(result[5])\n",
        "        confidence = result[4]\n",
        "        x1, y1, x2, y2 = result[:4]\n",
        "        plushie = img[int(y1):int(y2), int(x1):int(x2)]\n",
        "        match_confidence = float(predict_image(reid_model, suspect, plushie, transform=reid_transforms))\n",
        "        plushie_class = 1 if match_confidence > 0 else 0\n",
        "\n",
        "        bb_ann[\"Image_ID\"].append(image_name[:-4])\n",
        "        bb_ann[\"class\"].append(plushie_class) \n",
        "        bb_ann[\"confidence\"].append(confidence)\n",
        "        bb_ann[\"ymin\"].append(y1 / img_h)\n",
        "        bb_ann[\"xmin\"].append(x1 / img_w)\n",
        "        bb_ann[\"ymax\"].append(y2 / img_h)\n",
        "        bb_ann[\"xmax\"].append(x2 / img_w)\n",
        "        \n",
        "    if not results.xyxy[0].tolist():\n",
        "        bb_ann[\"Image_ID\"].append(image_name[:-4])\n",
        "        bb_ann[\"class\"].append(0) \n",
        "        bb_ann[\"confidence\"].append(0)\n",
        "        bb_ann[\"ymin\"].append(0)\n",
        "        bb_ann[\"xmin\"].append(0)\n",
        "        bb_ann[\"ymax\"].append(0)\n",
        "        bb_ann[\"xmax\"].append(0)\n",
        "\n",
        "\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(test_dir)[:10]):\n",
        "    detect_objects(image_name)\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame.from_dict(bb_ann)\n",
        "df.to_csv(\"results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "Q6zrWe0iYHMx"
      },
      "id": "Q6zrWe0iYHMx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff5049ce",
      "metadata": {
        "id": "ff5049ce"
      },
      "outputs": [],
      "source": [
        "print(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CCxJoZXy_fJ4"
      },
      "id": "CCxJoZXy_fJ4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "noteable": {
      "last_delta_id": "894f1459-6f7b-4e3f-9cf2-f2067924492b",
      "last_transaction_id": "894f1459-6f7b-4e3f-9cf2-f2067924492b"
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "medium-gpu",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}